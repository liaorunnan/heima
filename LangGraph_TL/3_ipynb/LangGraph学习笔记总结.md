# LangGraph å­¦ä¹ ç¬”è®°æ€»ç»“

æœ¬æ–‡æ¡£æ€»ç»“äº† `3_ipynb` æ–‡ä»¶å¤¹ä¸­çš„ 14 ä¸ªè„šæœ¬ï¼ˆtest_15.py ~ test_28.pyï¼‰çš„æ ¸å¿ƒçŸ¥è¯†ç‚¹ï¼Œå¸®åŠ©æ‚¨å¿«é€ŸæŒæ¡ LangGraph çš„å…³é”®æ¦‚å¿µå’Œå®è·µæ–¹æ³•ã€‚

---

## ğŸ“š ç›®å½•

1. [æ¡ä»¶è¾¹ï¼ˆConditional Edgesï¼‰](#1-æ¡ä»¶è¾¹conditional-edges)
2. [æç¤ºå·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰](#2-æç¤ºå·¥ç¨‹prompt-engineering)
3. [ç»“æ„åŒ–è¾“å‡ºï¼ˆStructured Outputï¼‰](#3-ç»“æ„åŒ–è¾“å‡ºstructured-output)
4. [å·¥å…·èŠ‚ç‚¹ï¼ˆTool Nodeï¼‰](#4-å·¥å…·èŠ‚ç‚¹tool-node)
5. [å®Œæ•´Agentå®ç°](#5-å®Œæ•´agentå®ç°)

---

## 1. æ¡ä»¶è¾¹ï¼ˆConditional Edgesï¼‰

### 1.1 ç®€å•æ¡ä»¶è¾¹ï¼ˆtest_15.pyï¼‰

æ¡ä»¶è¾¹å…è®¸æ ¹æ®çŠ¶æ€åŠ¨æ€å†³å®šä¸‹ä¸€æ­¥æ‰§è¡Œå“ªä¸ªèŠ‚ç‚¹ã€‚

```python
from langgraph.graph import START, StateGraph, END

# å®šä¹‰è·¯ç”±å‡½æ•°ï¼Œæ ¹æ®çŠ¶æ€è¿”å›ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°
def routing_function(state):
    if state["x"] == 10:
        return "node_b"
    else:
        return "node_c"

builder = StateGraph(dict)
builder.add_node("node_a", node_a)
builder.add_node("node_b", node_b)
builder.add_node("node_c", node_c)

# æ·»åŠ æ¡ä»¶è¾¹
builder.add_conditional_edges("node_a", routing_function)

graph = builder.compile()
```

**æ ¸å¿ƒè¦ç‚¹ï¼š**
- è·¯ç”±å‡½æ•°æ¥æ”¶ `state` å‚æ•°
- è¿”å›å€¼æ˜¯**ç›®æ ‡èŠ‚ç‚¹çš„åç§°å­—ç¬¦ä¸²**

### 1.2 ä½¿ç”¨ path_map çš„æ¡ä»¶è¾¹ï¼ˆtest_16.pyï¼‰

å½“è·¯ç”±å‡½æ•°è¿”å›çš„ä¸æ˜¯èŠ‚ç‚¹åç§°æ—¶ï¼Œä½¿ç”¨ `path_map` è¿›è¡Œæ˜ å°„ã€‚

```python
def routing_function(state):
    if state["x"] == 10:
        return True  # è¿”å›å¸ƒå°”å€¼
    else:
        return False

# path_map å°†è¿”å›å€¼æ˜ å°„åˆ°èŠ‚ç‚¹åç§°
builder.add_conditional_edges(
    "node_a", 
    routing_function, 
    path_map={True: "node_b", False: "node_c"}
)

builder.add_edge("node_b", END)
builder.add_edge("node_c", END)
```

**æ ¸å¿ƒè¦ç‚¹ï¼š**
- `path_map` æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå°†è·¯ç”±å‡½æ•°è¿”å›å€¼æ˜ å°„åˆ°èŠ‚ç‚¹åç§°
- é€‚ç”¨äºè¿”å›å¸ƒå°”å€¼ã€æšä¸¾å€¼ç­‰éå­—ç¬¦ä¸²çš„æƒ…å†µ

---

## 2. æç¤ºå·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰

### 2.1 ChatPromptTemplate åŸºç¡€ç”¨æ³•ï¼ˆtest_17.pyï¼‰

ä½¿ç”¨ LangChain çš„ `ChatPromptTemplate` åˆ›å»ºæç¤ºè¯æ¨¡æ¿ï¼š

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain.chat_models import init_chat_model

llm = init_chat_model(
    model="deepseek-chat",
    model_provider="deepseek",
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url=os.getenv("DEEPSEEK_URL"),
    temperature=0,
)

prompt = ChatPromptTemplate.from_messages([
    ("system", "Answer the user query. Wrap the output in `json`"),
    ("human", "{query}"),
])

# ä½¿ç”¨ç®¡é“ç¬¦è¿æ¥
chain = prompt | llm
ans = chain.invoke({"query": "ç”¨æˆ·è¾“å…¥..."})
print(ans.content)
```

### 2.2 ä» LLM è¾“å‡ºä¸­æå– JSONï¼ˆtest_18.pyï¼‰

ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä» LLM è¿”å›çš„ Markdown JSON å—ä¸­æå–æ•°æ®ï¼š

```python
import re
import json
from langchain_core.messages import AIMessage

def extract_json(message: AIMessage) -> list[dict]:
    """ä» ```json ``` æ ‡ç­¾ä¸­æå– JSON"""
    text = message.content
    pattern = r"```json(.*?)```"
    matches = re.findall(pattern, text, re.DOTALL)
    
    return [json.loads(match.strip()) for match in matches]

# åœ¨é“¾ä¸­ä½¿ç”¨
chain = prompt | llm | extract_json
```

---

## 3. ç»“æ„åŒ–è¾“å‡ºï¼ˆStructured Outputï¼‰

LangChain æä¾›äº†ä¸‰ç§æ–¹å¼å®ç°ç»“æ„åŒ–è¾“å‡ºï¼Œéƒ½ä½¿ç”¨ `with_structured_output()` æ–¹æ³•ã€‚

### 3.1 ä½¿ç”¨ Pydanticï¼ˆtest_19.pyï¼‰â­æ¨è

```python
from pydantic import BaseModel, Field
from typing import Optional

class UserInfo(BaseModel):
    """æå–ç”¨æˆ·ä¿¡æ¯çš„æ¨¡å‹"""
    name: str = Field(description="ç”¨æˆ·å§“å")
    age: Optional[int] = Field(description="ç”¨æˆ·å¹´é¾„")
    email: str = Field(description="é‚®ç®±åœ°å€")
    phone: Optional[str] = Field(description="ç”µè¯å·ç ")

structured_llm = llm.with_structured_output(UserInfo)
result = structured_llm.invoke("æˆ‘å«æœ¨ç¾½ï¼Œä»Šå¹´28å²...")

# å¯ä»¥ä½¿ç”¨ isinstance è¿›è¡Œç±»å‹æ£€æŸ¥
if isinstance(result, UserInfo):
    print("æˆåŠŸæå–ç”¨æˆ·ä¿¡æ¯")
```

**ä¼˜ç‚¹ï¼š**
- æ”¯æŒç±»å‹éªŒè¯å’Œæ•°æ®æ ¡éªŒ
- å¯ä»¥ä½¿ç”¨ `isinstance()` è¿›è¡Œç±»å‹æ£€æŸ¥
- IDE å‹å¥½ï¼Œæœ‰ä»£ç æç¤º

### 3.2 ä½¿ç”¨ TypedDictï¼ˆtest_20.pyï¼‰

```python
from typing import Optional
from typing_extensions import Annotated, TypedDict

class UserInfo(TypedDict):
    """æå–ç”¨æˆ·ä¿¡æ¯"""
    name: Annotated[str, ..., "ç”¨æˆ·å§“å"]
    age: Annotated[Optional[int], None, "ç”¨æˆ·å¹´é¾„"]
    email: Annotated[str, ..., "é‚®ç®±åœ°å€"]
    phone: Annotated[Optional[str], None, "ç”µè¯å·ç "]

structured_llm = llm.with_structured_output(UserInfo)
```

**æ³¨æ„ï¼š** TypedDict ä¸æ”¯æŒ `isinstance()` æ£€æŸ¥

### 3.3 ä½¿ç”¨ JSON Schemaï¼ˆtest_21.pyï¼‰

```python
json_schema = {
    "title": "user_info",
    "description": "Extracted user information",
    "type": "object",
    "properties": {
        "name": {"type": "string", "description": "ç”¨æˆ·å§“å"},
        "age": {"type": "integer", "description": "ç”¨æˆ·å¹´é¾„", "default": None},
        "email": {"type": "string", "description": "é‚®ç®±åœ°å€"},
        "phone": {"type": "string", "description": "ç”µè¯å·ç ", "default": None},
    },
    "required": ["name", "email"],
}

structured_llm = llm.with_structured_output(json_schema)
```

### 3.4 è”åˆç±»å‹è¾“å‡º - Unionï¼ˆtest_22.pyï¼‰

æ ¹æ®è¾“å…¥å†…å®¹æ™ºèƒ½é€‰æ‹©ä¸åŒçš„è¾“å‡ºæ ¼å¼ï¼š

```python
from typing import Union

class UserInfo(BaseModel):
    """ç”¨æˆ·ä¿¡æ¯ï¼Œç”¨äºæ•°æ®åº“å­˜å‚¨"""
    name: str = Field(description="ç”¨æˆ·å§“å")
    age: Optional[int] = Field(description="ç”¨æˆ·å¹´é¾„")
    email: str = Field(description="é‚®ç®±åœ°å€")
    phone: Optional[str] = Field(description="ç”µè¯å·ç ")

class ConversationalResponse(BaseModel):
    """å¯¹è¯å“åº”ï¼Œç”¨äºæ™®é€šèŠå¤©"""
    response: str = Field(description="å›å¤å†…å®¹")

class FinalResponse(BaseModel):
    """æœ€ç»ˆå“åº”ï¼Œå¯ä»¥æ˜¯ç”¨æˆ·ä¿¡æ¯æˆ–æ™®é€šå¯¹è¯"""
    final_output: Union[UserInfo, ConversationalResponse]

structured_llm = llm.with_structured_output(FinalResponse)

# æµ‹è¯•ï¼šæ™®é€šå¯¹è¯
result1 = structured_llm.invoke("ä½ å¥½")  # â†’ ConversationalResponse

# æµ‹è¯•ï¼šæå–ç”¨æˆ·ä¿¡æ¯
result2 = structured_llm.invoke("æˆ‘å«æœ¨ç¾½ï¼Œä»Šå¹´28å²...")  # â†’ UserInfo
```

---

## 4. å·¥å…·èŠ‚ç‚¹ï¼ˆTool Nodeï¼‰

### 4.1 å®šä¹‰å·¥å…·ï¼ˆtest_24.pyï¼‰

ä½¿ç”¨ `@tool` è£…é¥°å™¨å®šä¹‰å·¥å…·ï¼š

```python
from langchain_core.tools import tool

@tool
def fetch_real_time_info(query):
    """Get real-time Internet information"""
    # å®ç°ç½‘ç»œæœç´¢é€»è¾‘
    url = "https://google.serper.dev/search"
    # ... è¯·æ±‚ä»£ç  ...
    return result

# æŸ¥çœ‹å·¥å…·ä¿¡æ¯
print(f"å·¥å…·åç§°: {fetch_real_time_info.name}")
print(f"å·¥å…·æè¿°: {fetch_real_time_info.description}")
print(f"å·¥å…·å‚æ•°: {fetch_real_time_info.args}")
```

### 4.2 ToolNode å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ï¼ˆtest_24.py, test_25.pyï¼‰

`ToolNode` è´Ÿè´£æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼š

```python
from langgraph.prebuilt import ToolNode
from langchain_core.messages import AIMessage

# åˆ›å»ºå·¥å…·èŠ‚ç‚¹
tools = [fetch_real_time_info, get_weather]
tool_node = ToolNode(tools)

# æ„é€ å·¥å…·è°ƒç”¨æ¶ˆæ¯
message = AIMessage(
    content="",
    tool_calls=[
        {
            "name": "fetch_real_time_info",
            "args": {"query": "æœ€æ–°æ–°é—»"},
            "id": "tool_call_id",
            "type": "tool_call",
        }
    ],
)

# æ‰§è¡Œå·¥å…·
result = tool_node.invoke({"messages": [message]})
```

**æ ¸å¿ƒæ¦‚å¿µï¼š**
- `ToolNode` åªè´Ÿè´£**æ‰§è¡Œ**å·¥å…·ï¼Œä¸è´Ÿè´£å†³å®šè°ƒç”¨å“ªä¸ªå·¥å…·
- è¾“å…¥æ˜¯åŒ…å« `tool_calls` çš„ AIMessage
- è¾“å‡ºæ˜¯å·¥å…·æ‰§è¡Œç»“æœ

### 4.3 LLM ç»‘å®šå·¥å…·ï¼ˆtest_26.pyï¼‰

ä½¿ç”¨ `bind_tools()` è®© LLM è‡ªåŠ¨å†³å®šè°ƒç”¨å“ªä¸ªå·¥å…·ï¼š

```python
from langgraph.prebuilt import ToolNode

tools = [fetch_real_time_info, get_weather]
tool_node = ToolNode(tools)

# å°†å·¥å…·ç»‘å®šåˆ°æ¨¡å‹
model_with_tools = llm.bind_tools(tools)

# LLM ä¼šè‡ªåŠ¨åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
result = model_with_tools.invoke("åŒ—äº¬ç°åœ¨å¤šå°‘åº¦ï¼Ÿ")
print(result.tool_calls)  # åŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯

# ä½¿ç”¨ ToolNode æ‰§è¡Œå·¥å…·
tool_result = tool_node.invoke({"messages": [result]})
```

### 4.4 ä½¿ç”¨ args_schema å®šä¹‰å·¥å…·å‚æ•°ï¼ˆtest_27.py, test_28.pyï¼‰

ä¸ºå·¥å…·å®šä¹‰æ›´ç²¾ç¡®çš„å‚æ•° Schemaï¼š

```python
from pydantic import BaseModel, Field

class SearchQuery(BaseModel):
    query: str = Field(description="æœç´¢æŸ¥è¯¢è¯­å¥")

class WeatherLoc(BaseModel):
    location: str = Field(description="åŸå¸‚åç§°")

@tool(args_schema=SearchQuery)
def fetch_real_time_info(query):
    """è·å–å®æ—¶ç½‘ç»œä¿¡æ¯"""
    # ...

@tool(args_schema=WeatherLoc)
def get_weather(location):
    """è·å–å¤©æ°”ä¿¡æ¯"""
    # ...
```

---

## 5. å®Œæ•´ Agent å®ç°

### 5.1 ç»“æ„åŒ–è¾“å‡º + æ¡ä»¶åˆ†æ”¯ï¼ˆtest_23.pyï¼‰

å®ç°æ ¹æ®è¾“å‡ºç±»å‹æ‰§è¡Œä¸åŒæ“ä½œï¼ˆæ•°æ®åº“æ’å…¥ vs æ™®é€šå›ç­”ï¼‰ï¼š

```python
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated
import operator
from langchain_core.messages import AnyMessage, HumanMessage

# å®šä¹‰çŠ¶æ€ç±»å‹
class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], operator.add]

# èŠ‚ç‚¹å‡½æ•°
def chat_with_model(state):
    """ç”Ÿæˆç»“æ„åŒ–è¾“å‡º"""
    messages = state['messages']
    structured_llm = llm.with_structured_output(FinalResponse)
    response = structured_llm.invoke(messages)
    return {"messages": [response]}

def final_answer(state):
    """æ™®é€šå›ç­”èŠ‚ç‚¹"""
    response = state['messages'][-1].final_output.response
    return {"messages": [response]}

def insert_db(state):
    """æ•°æ®åº“æ’å…¥èŠ‚ç‚¹"""
    output = state['messages'][-1].final_output
    # æ‰§è¡Œæ•°æ®åº“æ’å…¥...
    return {"messages": ["æ•°æ®å·²å­˜å‚¨"]}

# è·¯ç”±å‡½æ•°
def generate_branch(state: AgentState):
    output = state['messages'][-1].final_output
    if isinstance(output, UserInfo):
        return True  # èµ°æ•°æ®åº“åˆ†æ”¯
    elif isinstance(output, ConversationalResponse):
        return False  # èµ°æ™®é€šå›ç­”åˆ†æ”¯

# æ„å»ºå›¾
graph = StateGraph(AgentState)
graph.add_node("chat_with_model", chat_with_model)
graph.add_node("final_answer", final_answer)
graph.add_node("insert_db", insert_db)

graph.set_entry_point("chat_with_model")
graph.add_conditional_edges(
    "chat_with_model",
    generate_branch,
    {True: "insert_db", False: "final_answer"}
)
graph.set_finish_point("final_answer")
graph.set_finish_point("insert_db")

graph = graph.compile()
```

**æ¶æ„å›¾ï¼š**
```
START â†’ chat_with_model â†’ [æ¡ä»¶åˆ¤æ–­] â†’ insert_db â†’ END
                              â†“
                       final_answer â†’ END
```

### 5.2 Tool Calling Agent - å·¥å…·è°ƒç”¨ç»“æŸå³å®Œæˆï¼ˆtest_27.pyï¼‰

æ”¯æŒå¤šç§å·¥å…·ï¼ˆæœç´¢ã€å¤©æ°”ã€æ•°æ®åº“æ’å…¥ï¼‰+ æ™®é€šå¯¹è¯ï¼š

```python
# å®šä¹‰è¾“å‡ºç±»å‹çš„è”åˆ
class FinalResponse(BaseModel):
    final_output: Union[ConversationalResponse, SearchQuery, WeatherLoc, UserInfo]

def execute_function(state):
    """æ ¹æ®ç»“æ„åŒ–è¾“å‡ºæ‰§è¡Œå¯¹åº”å·¥å…·"""
    final_output = state['messages'][-1].final_output
    
    # @tool è£…é¥°çš„å‡½æ•°ä½¿ç”¨ .invoke(dict) æ–¹æ³•è°ƒç”¨
    if isinstance(final_output, SearchQuery):
        result = fetch_real_time_info.invoke({"query": final_output.query})
        return {"messages": [result]}
    
    elif isinstance(final_output, WeatherLoc):
        result = get_weather.invoke({"location": final_output.location})
        return {"messages": [result]}
    
    elif isinstance(final_output, UserInfo):
        result = insert_db.invoke({
            "name": final_output.name,
            "age": final_output.age,
            "email": final_output.email,
            "phone": final_output.phone
        })
        return result
```

**æ¶æ„å›¾ï¼š**
```
START â†’ chat_with_model â†’ [æ¡ä»¶åˆ¤æ–­] â†’ execute_function â†’ END
                              â†“
                       final_answer â†’ END
```

### 5.3 Tool Calling Agent - å¸¦è‡ªç„¶è¯­è¨€æ€»ç»“ï¼ˆtest_28.pyï¼‰â­æœ€ä½³å®è·µ

å·¥å…·æ‰§è¡Œåï¼Œå†ç”¨ LLM ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤ï¼š

```python
from langchain_core.messages import SystemMessage, ToolMessage

# ä½¿ç”¨ bind_tools æ–¹å¼
tools = [insert_db, fetch_real_time_info, get_weather]
llm = llm.bind_tools(tools)

def execute_function(state: AgentState):
    """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
    tool_calls = state['messages'][-1].tool_calls
    results = []
    tools_dict = {t.name: t for t in tools}
    
    for t in tool_calls:
        if t['name'] not in tools_dict:
            result = "bad tool name, retry"
        else:
            result = tools_dict[t['name']].invoke(t['args'])
        results.append(ToolMessage(
            tool_call_id=t['id'], 
            name=t['name'], 
            content=str(result)
        ))
    return {'messages': results}

SYSTEM_PROMPT = """
è¯·æ ¹æ®è·å–çš„ä¿¡æ¯ï¼Œç”Ÿæˆä¸“ä¸šçš„ä¸­æ–‡å›å¤ã€‚
"""

def natural_response(state):
    """å°†å·¥å…·ç»“æœè½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€"""
    messages = state['messages'][-1]
    messages = [SystemMessage(content=SYSTEM_PROMPT)] + [HumanMessage(content=messages.content)]
    response = llm.invoke(messages)
    return {"messages": [response]}

def exists_function_calling(state: AgentState):
    """åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·"""
    result = state['messages'][-1]
    return len(result.tool_calls) > 0

# æ„å»ºå›¾
graph = StateGraph(AgentState)
graph.add_node("chat_with_model", chat_with_model)
graph.add_node("execute_function", execute_function)
graph.add_node("final_answer", final_answer)
graph.add_node("natural_response", natural_response)

graph.set_entry_point("chat_with_model")
graph.add_conditional_edges(
    "chat_with_model",
    exists_function_calling,
    {True: "execute_function", False: "final_answer"}
)
graph.add_edge("execute_function", "natural_response")
graph.add_edge("final_answer", "natural_response")
graph.set_finish_point("natural_response")

graph = graph.compile()
```

**æ¶æ„å›¾ï¼š**
```
START â†’ chat_with_model â†’ [æ˜¯å¦è°ƒç”¨å·¥å…·?] â†’ execute_function â†’ natural_response â†’ END
                              â†“
                       final_answer â†’ natural_response â†’ END
```

---

## ğŸ“‹ æ ¸å¿ƒæ¦‚å¿µé€ŸæŸ¥è¡¨

| æ¦‚å¿µ | è¯´æ˜ | ç›¸å…³æ–‡ä»¶ |
|------|------|----------|
| `StateGraph` | çŠ¶æ€å›¾æ„å»ºå™¨ | æ‰€æœ‰æ–‡ä»¶ |
| `add_conditional_edges` | æ·»åŠ æ¡ä»¶è¾¹ | test_15, test_16 |
| `path_map` | æ¡ä»¶è¾¹è¿”å›å€¼æ˜ å°„ | test_16 |
| `ChatPromptTemplate` | æç¤ºè¯æ¨¡æ¿ | test_17, test_18 |
| `with_structured_output` | ç»“æ„åŒ–è¾“å‡º | test_19-22 |
| `Pydantic BaseModel` | å®šä¹‰è¾“å‡ºç»“æ„ | test_19, test_22-28 |
| `TypedDict` | å®šä¹‰è¾“å‡ºç»“æ„ï¼ˆå¤‡é€‰ï¼‰ | test_20 |
| `Union` | è”åˆç±»å‹è¾“å‡º | test_22, test_23, test_27 |
| `@tool` | å·¥å…·è£…é¥°å™¨ | test_24-28 |
| `ToolNode` | å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ | test_24-26 |
| `bind_tools` | ç»‘å®šå·¥å…·åˆ°LLM | test_26, test_28 |
| `args_schema` | å·¥å…·å‚æ•°Schema | test_27, test_28 |
| `ToolMessage` | å·¥å…·è°ƒç”¨ç»“æœæ¶ˆæ¯ | test_28 |
| `set_entry_point` | è®¾ç½®å…¥å£èŠ‚ç‚¹ | æ‰€æœ‰å›¾æ–‡ä»¶ |
| `set_finish_point` | è®¾ç½®ç»ˆæ­¢èŠ‚ç‚¹ | test_23, test_27, test_28 |

---

## ğŸ”§ å¸¸ç”¨ä»£ç æ¨¡æ¿

### åˆå§‹åŒ– LLM

```python
import os
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model

load_dotenv(override=True)

llm = init_chat_model(
    model="deepseek-chat",
    model_provider="deepseek",
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url=os.getenv("DEEPSEEK_URL"),
    temperature=0,
)
```

### å®šä¹‰çŠ¶æ€ç±»å‹

```python
from typing import TypedDict, Annotated
from langchain_core.messages import AnyMessage
import operator

class AgentState(TypedDict):
    messages: Annotated[list[AnyMessage], operator.add]
```

### å¯è§†åŒ–å›¾

```python
png_bytes = graph.get_graph(xray=True).draw_mermaid_png()
with open("graph.png", "wb") as f:
    f.write(png_bytes)
```

### è°ƒç”¨å›¾

```python
from langchain_core.messages import HumanMessage

query = "ç”¨æˆ·è¾“å…¥"
input_message = {"messages": [HumanMessage(content=query)]}
result = graph.invoke(input_message)
print(result["messages"][-1])
```

---

## ğŸ“ˆ å­¦ä¹ è·¯å¾„å»ºè®®

1. **åŸºç¡€é˜¶æ®µ**ï¼štest_15 â†’ test_16ï¼ˆç†è§£æ¡ä»¶è¾¹ï¼‰
2. **æç¤ºå·¥ç¨‹**ï¼štest_17 â†’ test_18ï¼ˆLLM è¾“å‡ºå¤„ç†ï¼‰
3. **ç»“æ„åŒ–è¾“å‡º**ï¼štest_19 â†’ test_20 â†’ test_21 â†’ test_22ï¼ˆæŒæ¡ä¸‰ç§æ–¹å¼ï¼‰
4. **å·¥å…·è°ƒç”¨**ï¼štest_24 â†’ test_25 â†’ test_26ï¼ˆç†è§£ ToolNodeï¼‰
5. **å®æˆ˜æ•´åˆ**ï¼štest_23 â†’ test_27 â†’ test_28ï¼ˆå®Œæ•´ Agent å®ç°ï¼‰

---

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **ç¯å¢ƒå˜é‡**ï¼šç¡®ä¿ `.env` æ–‡ä»¶ä¸­é…ç½®äº† `DEEPSEEK_API_KEY`ã€`DEEPSEEK_URL`ã€`google_serper_KEY` ç­‰
2. **æ•°æ®åº“**ï¼štest_23ã€test_27ã€test_28 éœ€è¦é…ç½® MySQL è¿æ¥
3. **@tool å‡½æ•°è°ƒç”¨**ï¼šä½¿ç”¨ `.invoke(dict)` æ–¹æ³•ï¼Œä¸èƒ½ç›´æ¥ä¼ å…³é”®å­—å‚æ•°
4. **TypedDict vs Pydantic**ï¼šæ¨èä½¿ç”¨ Pydanticï¼Œæ”¯æŒç±»å‹æ£€æŸ¥å’Œæ›´å¥½çš„ IDE æç¤º

---

*æ—¶é—´ï¼š2025å¹´11æœˆ28æ—¥*

