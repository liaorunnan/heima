# 发音评分



调用 **Azure Speech API (Pronunciation Assessment)** 是实现你英语发音 App **“发音评分”** 功能最快、最稳健的方式。

不需要自己训练模型，微软已经帮你训练好了。它能提供：
1.  **全局评分**：流利度、完整度、准确度、韵律（语调）。
2.  **单词级评分**：哪个词读错了。
3.  **音素级评分**：哪个音标（如 `/r/` vs `/l/`）读错了。

以下是使用 **Python** 调用的完整步骤和代码演示。

---

### 第一步：准备工作

1.  **注册 Azure 账号**：去 [Azure Portal](https://portal.azure.com/)。
2.  **创建资源**：搜索并创建一个 **"Speech" (语音服务)** 资源。
    *   *注意：可以使用免费层 (F0)，每月有 5 小时免费音频额度，开发测试足够了。*
3.  **获取密钥**：在资源页面的 "Keys and Endpoint" 里找到：
    *   **Key** (密钥)
    *   **Region** (区域，例如 `eastus`, `japaneast`)

### 第二步：安装 SDK

在你的 Python 环境中安装微软官方 SDK：

```bash
pip install azure-cognitiveservices-speech
```

---

### 第三步：编写调用代码 (Python)

这段代码展示了如何评估一段音频，并获取**单词级**和**音素级**的详细错误报告。

假设你有一个音频文件 `my_voice.wav`，参考文本是 `"Hello world"`。

```python
import azure.cognitiveservices.speech as speechsdk
import time
import json

# ================= 配置区域 =================
# 替换为你的 Azure Key 和 Region
SPEECH_KEY = "你的_AZURE_SPEECH_KEY"
SPEECH_REGION = "你的_AZURE_REGION" # 例如 "eastus"

# 要评估的参考文本（用户应该读什么）
REFERENCE_TEXT = "I would like to book a flight to London."
# 你的录音文件路径 (必须是 WAV 格式，建议 16kHz)
AUDIO_FILE = "my_voice.wav" 
# ===========================================

def assess_pronunciation():
    # 1. 创建语音配置
    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)
    
    # 2. 配置音频输入 (如果要用麦克风，改用 use_default_microphone=True)
    audio_config = speechsdk.audio.AudioConfig(filename=AUDIO_FILE)
    # audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True) # 使用麦克风

    # 3. 创建发音评估配置 (核心部分)
    pronunciation_config = speechsdk.PronunciationAssessmentConfig(
        reference_text=REFERENCE_TEXT,
        grading_system=speechsdk.PronunciationAssessmentGradingSystem.HundredMark, # 100分制
        granularity=speechsdk.PronunciationAssessmentGranularity.Phoneme,          # 细粒度到音素
        enable_miscue=True # 开启错误诊断 (检测漏读、多读)
    )
    # 开启韵律评估 (语调、重音等)
    pronunciation_config.enable_prosody_assessment()

    # 4. 初始化识别器
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
    
    # 5. 将评估配置应用到识别器上
    pronunciation_config.apply_to(recognizer)

    print(f"正在评估音频，参考文本: '{REFERENCE_TEXT}'...")
    
    # 6. 开始识别 (recognize_once_async 适合短句子)
    # 对于长段落，需要使用 continuous_recognition
    result = recognizer.recognize_once_async().get()

    # 7. 解析结果
    if result.reason == speechsdk.ResultReason.RecognizedSpeech:
        # 获取评估结果对象
        pronunciation_result = speechsdk.PronunciationAssessmentResult.from_result(result)
        
        print("-" * 30)
        print("【全局评分】")
        print(f"准确度 (Accuracy): {pronunciation_result.accuracy_score}")
        print(f"流利度 (Fluency): {pronunciation_result.fluency_score}")
        print(f"完整度 (Completeness): {pronunciation_result.completeness_score}")
        print(f"韵律/语调 (Prosody): {pronunciation_result.prosody_score}")
        print(f"综合评分 (PronScore): {pronunciation_result.pronunciation_score}")
        print("-" * 30)

        # 8. 获取详细的单词和音素详情
        # Azure 返回的是一个复杂的对象，为了方便看，我们通常解析它的 JSON 结构
        json_result = result.properties.get(speechsdk.PropertyId.SpeechServiceResponse_JsonResult)
        parsed_json = json.loads(json_result)
        
        # 提取 NBest 里的第一个结果
        nbest = parsed_json['NBest'][0]
        words = nbest.get('Words', [])

        print("【单词级详细诊断】")
        for word in words:
            word_text = word['Word']
            accuracy = word['PronunciationAssessment']['AccuracyScore']
            error_type = word['PronunciationAssessment'].get('ErrorType', 'None')
            
            # ErrorType 常见值: None(正确), Omission(漏读), Insertion(多读), Mispronunciation(读错)
            status_icon = "✅" if error_type == "None" else "❌"
            
            print(f"{status_icon} 单词: {word_text:<15} 分数: {accuracy:<5} 状态: {error_type}")
            
            # 如果需要音素级详情 (比如 hello 读成了 h-e-l-l-ow)
            if 'Phonemes' in word:
                phoneme_details = []
                for ph in word['Phonemes']:
                    ph_text = ph['Phoneme']
                    ph_score = ph['PronunciationAssessment']['AccuracyScore']
                    phoneme_details.append(f"/{ph_text}/({ph_score})")
                print(f"   └── 音素详情: {' '.join(phoneme_details)}")

    elif result.reason == speechsdk.ResultReason.NoMatch:
        print("无法识别语音，请检查麦克风或音频文件是否清晰。")
    elif result.reason == speechsdk.ResultReason.Canceled:
        cancellation_details = result.cancellation_details
        print(f"任务取消: {cancellation_details.reason}")
        if cancellation_details.reason == speechsdk.CancellationReason.Error:
            print(f"错误详情: {cancellation_details.error_details}")
            print("请检查 Key 和 Region 是否正确。")

if __name__ == "__main__":
    assess_pronunciation()
```

### 关键参数解释

1.  **`reference_text` (参考文本)**：
    这是你 APP 界面上显示给用户看的那句话。Azure 会拿用户的录音和这句话对比。

2.  **`grading_system`**:
    *   `FivePoint`: 5分制。
    *   `HundredMark`: 100分制（推荐，适合直接展示给用户）。

3.  **`granularity`**:
    *   `Phoneme`: **最强模式**。它不仅告诉你单词错了，还能告诉你单词里的哪个音错了。做纠音 APP 必须开这个。

4.  **`ErrorType` (在结果 JSON 中)**：
    这是你反馈给用户的核心依据：
    *   `None`: 读对了。
    *   `Omission`: 漏读了这个词。
    *   `Insertion`: 加了不该有的词。
    *   `Mispronunciation`: 这个词读错了（分数低）。

### 给你的 APP 开发建议

1.  **关于音频格式**：
    Azure 对音频格式比较敏感。如果你在手机端（iOS/Android）录音，传给 Python 后端时，最好统一转码为 **WAV (PCM, 16-bit, 16kHz, 单声道)**。使用 `ffmpeg` 可以轻松转换。

2.  **流式处理 (Streaming)**：
    上面的代码是“一次性”识别（上传整个文件）。如果你的句子很长（比如雅思口语的一段话），建议使用 **Continuous Recognition** 模式，或者让用户读完一句就调一次 API，体验更好。

3.  **关于费用**：
    *   F0 (免费层)：每月 5 小时音频。
    *   S0 (标准层)：大约 **$1 / 小时**。
    *   如果你的用户量上来，这个成本是可以接受的，比自己雇人或者租几张 A100 显卡训练模型要划算得多且稳定。