from mcp.server.fastmcp import FastMCP
from typing import Dict, Any, Optional, Union, List, Callable, Tuple
# import porstgreDB_server as db
import src.tools.porstgreDB_tools as db
import json
from datetime import datetime, timezone, timedelta
import prompts.prompts as prompts
import re
import uuid
from bot_mcp import call_tool, get_bot_config, get_products_with_cache
from dify_mcp import retrieve_dataset, extract_dataset_snippets
import router_server as router
from Responder import llm_generic
# from core.redis_client import redis_get, redis_set
from config.settings import DEFAULT_BOT_LLM_CONFIG
import logging
from cors_handler import add_cors_support
from concurrent.futures import ThreadPoolExecutor, Future
from scorer import generate_conversation_scores
from src.tools.redis_tools import redis_get, redis_set

# é…ç½® logger
logger = logging.getLogger(__name__)
if not logger.handlers:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

mcp = FastMCP("Main Response Server", host="0.0.0.0", port=3003)
# æ·»åŠ  CORS æ”¯æŒï¼šå¤„ç† OPTIONS é¢„æ£€è¯·æ±‚
add_cors_support(mcp)

# çº¿ç¨‹æ± æ‰§è¡Œå™¨ï¼Œç”¨äºå¼‚æ­¥ç”Ÿæˆ info
_INFO_EXECUTOR = ThreadPoolExecutor(max_workers=4)
# çº¿ç¨‹æ± æ‰§è¡Œå™¨ï¼Œç”¨äºå¼‚æ­¥è®¡ç®—æˆäº¤æ„æ„¿åˆ†
_SCORE_EXECUTOR = ThreadPoolExecutor(max_workers=2)


def stage_switch(conversation_id: str, session_id: str, user_id: str, state_order: list[str]) -> str:
    """æ ¹æ®æœ€æ–°ä¸€æ¡ session_states å†³å®šæ˜¯å¦åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªé˜¶æ®µã€‚

    é€»è¾‘ï¼š
    - å–æœ€æ–°è®°å½•çš„ current_state ä»¥åŠå¯¹åº”åˆ—ï¼ˆlower(current_state)ï¼‰çš„ payloadã€‚
    - è‹¥è¯¥ payload å·²å­˜åœ¨ä¸”éç©ºï¼Œåˆ™æŒ‰ state_order ä¸­çš„é¡ºåºåˆ‡æ¢åˆ°ä¸‹ä¸€é˜¶æ®µï¼›
      - å½“å‰é˜¶æ®µåœ¨åˆ—è¡¨ä¸­ï¼šè¿”å›ä¸‹ä¸€ä¸ªï¼›è‹¥å·²æ˜¯æœ€åä¸€ä¸ªåˆ™è¿”å›å½“å‰é˜¶æ®µï¼›
      - å½“å‰é˜¶æ®µä¸åœ¨åˆ—è¡¨ä¸­ï¼šè¿”å›åˆ—è¡¨ç¬¬ä¸€ä¸ªï¼›
    - è‹¥ payload ä¸ºç©ºæˆ–ä¸å­˜åœ¨ï¼šè¿”å›å½“å‰é˜¶æ®µï¼ˆä¸åˆ‡ï¼‰ã€‚
    """
    latest = json.loads(db.get_latest_session_state_payload(
        conversation_id=conversation_id,
        session_id=session_id,
        user_id=user_id,
    ))
    cur_state = latest.get("current_state")
    payload = latest.get("stage_payload")

    has_target = payload is not None and payload != "" and payload != {}
    if not has_target:
        return cur_state

    if not state_order:
        return cur_state

    if cur_state in state_order:
        idx = state_order.index(cur_state)
        return state_order[idx + 1] if idx + 1 < len(state_order) else cur_state

    return state_order[0]

def _ensure_prompt_text(segment) -> str:
    """å°† prompts æ®µè½æ ‡å‡†åŒ–ä¸ºå­—ç¬¦ä¸²ã€‚
    - è‹¥ä¸º set/list/tupleï¼Œæ‹¼æ¥ä¸ºå•ä¸€å­—ç¬¦ä¸²ï¼›
    - å…¶ä½™ç±»å‹è½¬ä¸º strã€‚
    """
    if isinstance(segment, set):
        return "".join(segment)
    if isinstance(segment, (list, tuple)):
        return "\n\n".join([str(x) for x in segment])
    return str(segment)


def _cleanup_llm_json_str(raw: str) -> str:
    """ç§»é™¤ LLM è¿”å›ç»“æœä¸­çš„ ```json ``` æ ·å¼åŒ…è£¹ã€‚"""
    if not isinstance(raw, str):
        return raw
    text = raw.strip()
    if text.startswith("```"):
        lines = text.splitlines()
        if lines:
            first = lines[0].strip()
            if first.startswith("```"):
                lines = lines[1:]
        if lines and lines[-1].strip().startswith("```"):
            lines = lines[:-1]
        text = "\n".join(lines).strip()
    return text


def _normalize_to_single_id(raw_value: Any) -> str:
    """å°†å•†å“IDæˆ–æƒç›ŠIDè§„èŒƒåŒ–ä¸ºå•ä¸ªIDå­—ç¬¦ä¸²ã€‚
    
    å¦‚æœè¾“å…¥æ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼›å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå…ˆå°è¯•è§£æä¸º JSON æ•°ç»„ã€‚
    å¦‚æœæ˜¯ JSON å­—ç¬¦ä¸²å½¢å¼çš„æ•°ç»„ï¼ˆå¦‚ '["289","290","291"]'ï¼‰ï¼Œè§£æåå–ç¬¬ä¸€ä¸ªå…ƒç´ ã€‚
    å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚
    
    å‚æ•°:
        raw_value: åŸå§‹å€¼ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²ã€åˆ—è¡¨æˆ–å…¶ä»–ç±»å‹ï¼‰
    
    è¿”å›:
        å•ä¸ªIDå­—ç¬¦ä¸²ï¼ˆå¦‚æœä¸ºç©ºæˆ–æ— æ•ˆï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰
    """
    if raw_value is None:
        return ""
    
    if isinstance(raw_value, list):
        # å¦‚æœæ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªéç©ºå…ƒç´ 
        for item in raw_value:
            if item is not None:
                return str(item).strip()
        return ""
    
    if isinstance(raw_value, str):
        stripped = raw_value.strip()
        # å¦‚æœå­—ç¬¦ä¸²çœ‹èµ·æ¥åƒ JSON æ•°ç»„ï¼ˆä»¥ [ å¼€å¤´ï¼Œä»¥ ] ç»“å°¾ï¼‰ï¼Œå°è¯•è§£æ
        if stripped.startswith("[") and stripped.endswith("]"):
            try:
                parsed = json.loads(stripped)
                if isinstance(parsed, list):
                    # è§£ææˆåŠŸä¸”æ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªéç©ºå…ƒç´ 
                    for item in parsed:
                        if item is not None:
                            return str(item).strip()
                    return ""
            except (json.JSONDecodeError, ValueError, TypeError):
                # JSON è§£æå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²
                pass
        return stripped
    
    # å…¶ä»–ç±»å‹ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    return str(raw_value).strip()


def parse_exit_keywords(structured_content: Any) -> List[str]:
    """ä» bot é…ç½®ä¸­æå– exitKeyword åˆ—è¡¨ï¼ˆå…¼å®¹å­—ç¬¦ä¸²ä¸åˆ—è¡¨ï¼‰ã€‚"""
    keywords = structured_content.get('exitKeyword')
    return keywords


def detect_handoff_intent(
    *,
    exit_keywords: List[str],
    user_input: str,
    history_context: Any,
    session_state: Dict[str, Any],
    bot_llm_config: Dict[str, Any],
) -> Dict[str, Any]:
    """è°ƒç”¨ LLM åˆ¤æ–­æ˜¯å¦æ»¡è¶³è½¬äººå·¥æ¡ä»¶ã€‚"""
    if not exit_keywords:
        return {"handoff": False, "reason": "no keywords"}

    system_prompt = (
        "ä½ æ˜¯å®¢æœè´¨æ£€åŠ©æ‰‹ï¼Œè¯·åˆ¤æ–­ç”¨æˆ·æ˜¯å¦éœ€è¦è½¬äººå·¥å®¢æœã€‚"
        "å¦‚æœå½“å‰ç”¨æˆ·è¾“å…¥æ»¡è¶³exitKeywordä¸­çš„æ¡ä»¶ï¼Œåˆ™è¿”å›handoff=trueï¼Œå¦åˆ™è¿”å›handoff=falseã€‚"
        f"exitKeyword: {exit_keywords}"
        "è¯·ä»…è¾“å‡º JSONï¼š{\"handoff\": true|false}ã€‚"
    )
    system_prompt = f"{system_prompt}"

    #keywords_text = ", ".join(exit_keywords)

    llm_result = llm_generic(
        full_prompt=system_prompt,
        user_input=user_input,
        history_context=history_context,
        session_state=session_state,
        botLLMConfig=bot_llm_config,
        prompt_without_character=system_prompt,
        input_label="ç”¨æˆ·æœ€æ–°è¾“å…¥",
    )

    raw_text: str
    if isinstance(llm_result, dict):
        raw_text = llm_result.get("response") or llm_result.get("text") or json.dumps(llm_result, ensure_ascii=False)
    else:
        raw_text = str(llm_result)
    cleaned = _cleanup_llm_json_str(raw_text)
    try:
        parsed = json.loads(cleaned)
        if isinstance(parsed, dict):
            return parsed
    except json.JSONDecodeError:
        pass
    return {"handoff": False, "raw": cleaned}


def judge_after_sales_intent(
    *,
    user_input: str,
    history_context: Any,
    bot_llm_config: Dict[str, Any],
) -> bool:
    """åˆ¤æ–­ç”¨æˆ·æ„å›¾æ˜¯å¦ä¸ºå”®åã€‚"""
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªç”µå•†å®¢æœåŠ©æ‰‹ã€‚è¯·åˆ¤æ–­ç”¨æˆ·çš„æœ€æ–°è¾“å…¥æ˜¯å¦æ¶‰åŠå”®åæœåŠ¡ï¼ˆå¦‚ï¼šé€€æ¬¾ã€é€€è´§ã€æ¢è´§ã€ç‰©æµæŸ¥è¯¢ã€æŠ•è¯‰ã€è®¢å•çŠ¶æ€ã€å‘ç¥¨é—®é¢˜ç­‰ï¼‰ã€‚"
        "å¦‚æœæ˜¯å”®åç›¸å…³é—®é¢˜ï¼Œè¯·è¿”å› trueï¼Œå¦åˆ™è¿”å› falseã€‚"
        "è¯·ä»…è¾“å‡º JSONï¼š{\"is_after_sales\": true|false}ã€‚"
    )

    llm_result = llm_generic(
        full_prompt=system_prompt,
        user_input=user_input,
        history_context=history_context,
        session_state={},
        botLLMConfig=bot_llm_config,
        prompt_without_character=system_prompt,
        input_label="ç”¨æˆ·æœ€æ–°è¾“å…¥",
    )

    raw_text: str
    if isinstance(llm_result, dict):
        raw_text = llm_result.get("response") or llm_result.get("text") or json.dumps(llm_result, ensure_ascii=False)
    else:
        raw_text = str(llm_result)
    cleaned = _cleanup_llm_json_str(raw_text)
    try:
        parsed = json.loads(cleaned)
        if isinstance(parsed, dict):
            return parsed.get("is_after_sales", False)
    except json.JSONDecodeError:
        pass
    return False


def process_handoff_detection(
    *,
    conversation_id: str,
    turn_uuid: str,
    fn: Optional[Callable[[Dict[str, Any]], None]],
    threshold: int,
    reply_text: str,
    ttl_seconds: int,
) -> bool:
    """è®°å½•è½¬äººå·¥è§¦å‘æ¬¡æ•°ï¼Œè¾¾åˆ°é˜ˆå€¼åæ¨é€æç¤ºå¹¶æ¸…é›¶è®¡æ•°ã€‚"""
    redis_key = f"handoff:{conversation_id}"
    count = 0
    cached = redis_get(redis_key)
    if cached:
        try:
            cached_data = json.loads(cached)
            count = int(cached_data.get("count", 0))
        except Exception:
            count = 0

    count += 1
    timestamp = datetime.now(timezone.utc).isoformat()
    redis_set(
        redis_key,
        json.dumps({"count": count, "latest_ts": timestamp}, ensure_ascii=False),
        expired=ttl_seconds,
    )

    if count >= threshold:
        logger.info(
            "========== [handoff] è¾¾åˆ°è½¬äººå·¥é˜ˆå€¼ (%d) ==========",
            threshold,
        )
        redis_set(
            redis_key,
            json.dumps({"count": 0, "latest_ts": timestamp}, ensure_ascii=False),
            expired=ttl_seconds,
        )
        if fn:
            try:
                fn(
                    {
                        "event": "reply",
                        "data": {
                            "info": {"customer_service": True},
                            "response": reply_text,
                            "turn_uuid": turn_uuid,
                        },
                    }
                )
            except Exception as exc:  # noqa: BLE001
                logger.warning("[handoff] æ¨é€è½¬äººå·¥æç¤ºå¤±è´¥: %s", exc)
        return True

    logger.info(
        "========== [handoff] å½“å‰ conversation=%s è½¬äººå·¥ç´¯è®¡æ¬¡æ•°: %d ==========",
        conversation_id,
        count,
    )
    return False


def build_stage_prompt(current_state: str, current_sub_stage: Optional[str] = None) -> str:
    """æ ¹æ® current_state + current_sub_stage å–å¯¹åº”æ¨¡å— promptï¼Œå¹¶ä¸è§’è‰² prompt ç»„è£…ã€‚

    è§„åˆ™ï¼š
    - è§’è‰² prompt ä½¿ç”¨ prompts.Character_Prompts
    - æ¨¡å—åè§£æï¼š
      - è‹¥æä¾› substageï¼Œåˆ™å±æ€§å = f"{current_state}_{current_sub_stage}_Prompts"
      - å¦åˆ™å±æ€§å = f"{current_state}_Prompts"
    - ä¸åšå…œåº•ï¼šè‹¥å±æ€§ä¸å­˜åœ¨å°†æŠ›å‡º AttributeErrorï¼ˆç¬¦åˆ"è®©é”™è¯¯ç›´æ¥æš´éœ²"çš„çº¦å®šï¼‰ã€‚
    """
    role_seg = _ensure_prompt_text(prompts.Character_Prompts)
    attr_name = f"{current_state}_{current_sub_stage}_Prompts" if current_sub_stage else f"{current_state}_Prompts"
    module_seg = getattr(prompts, attr_name)  # è‹¥ä¸å­˜åœ¨ï¼Œç›´æ¥æŠ›å¼‚å¸¸
    module_text = _ensure_prompt_text(module_seg)
    return "\n\n".join([role_seg, module_text])


def extract_conversational_content_from_info(results: dict) -> dict:
    """ä» results çš„ info å­—æ®µä¸­æå–å¯¹è¯å†…å®¹ï¼Œåˆå¹¶åˆ° response ä¸­ã€‚

    åˆ¤æ–­æ ‡å‡†ï¼š
    - å­—æ®µå€¼é•¿åº¦ > 30 å­—ç¬¦
    - åŒ…å«ä¸­æ–‡æ ‡ç‚¹ç¬¦å·ï¼ˆã€‚ï¼Œï¼ï¼Ÿã€ç­‰ï¼‰
    - ä¸æ˜¯çº¯æ•°å­—æˆ–çº¯ID
    - å¯èƒ½åŒ…å«è¡¨æƒ…ç¬¦å·æˆ–å¯¹è¯è¯­æ°”è¯

    å‚æ•°:
        results: LLM è¿”å›çš„ç»“æœå­—å…¸ï¼ŒåŒ…å« info å’Œ response å­—æ®µ

    è¿”å›:
        ä¿®æ”¹åçš„ results å­—å…¸
    """
    if not isinstance(results, dict) or "info" not in results:
        return results

    info = results.get("info", {})
    if not isinstance(info, dict):
        return results

    # ä¸­æ–‡æ ‡ç‚¹ç¬¦å·
    chinese_punctuation = "ã€‚ï¼Œï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹"
    # å¯¹è¯è¯­æ°”è¯/è¡¨æƒ…ç¬¦å·å¸¸è§å­—ç¬¦
    conversational_indicators = ["å—", "å‘¢", "å§", "å•Š", "å‘€", "å“¦", "å—¯", "âœ¨", "ğŸ’«", "ğŸ˜Š", "ğŸ˜„", "ï¼Ÿ", "ï¼"]
    punctuation_set = set(chinese_punctuation + "ï¼Œã€‚ï¼ï¼Ÿ!?.,;:~â€¦â€”-ã€ï¼›ï¼š'\"ï¼ˆï¼‰ã€ã€‘ã€Šã€‹Â·")

    sentence_enders = set("ã€‚ï¼ï¼Ÿ!?")

    extracted_content = []
    fields_to_check = []

    # éå† info ä¸­çš„æ‰€æœ‰å­—æ®µ
    for key, value in info.items():
        if not isinstance(value, (str, int, float)):
            continue

        value_str = str(value).strip()

        # è·³è¿‡ä»…ç”±é‡å¤æ ‡ç‚¹ç»„æˆçš„å†…å®¹ï¼ˆä¾‹å¦‚ "......"ã€"ï¼ï¼ï¼"ï¼‰
        compact_value = re.sub(r"\s+", "", value_str)
        if compact_value:
            first_char = compact_value[0]
            if all(ch == first_char for ch in compact_value) and first_char in punctuation_set:
                continue

        # è·³è¿‡ç©ºå€¼ã€çº¯æ•°å­—ã€çº¯IDï¼ˆé•¿åº¦çŸ­ä¸”æ— æ ‡ç‚¹ï¼‰
        if not value_str or len(value_str) < 10:
            continue

        # è·³è¿‡çº¯æ•°å­—æˆ–çº¯IDï¼ˆå¦‚å•†å“IDï¼‰
        if value_str.isdigit() or (len(value_str) < 10 and not any(c in value_str for c in chinese_punctuation + "ï¼Œã€‚ï¼ï¼Ÿ")):
            continue

        # åˆ¤æ–­æ˜¯å¦åŒ…å«å¯¹è¯ç‰¹å¾
        has_chinese_punct = any(c in value_str for c in chinese_punctuation)
        has_conversational = any(indicator in value_str for indicator in conversational_indicators)
        has_sentence_end = any(c in sentence_enders for c in value_str)
        has_chinese_chars = bool(re.search(r'[\u4e00-\u9fff]', value_str))

        # å¦‚æœåŒ…å«å¯¹è¯ç‰¹å¾ï¼Œæå–å‡ºæ¥
        if has_chinese_chars and (has_conversational or has_sentence_end):
            extracted_content.append(value_str)
            fields_to_check.append(key)

    # å¦‚æœæœ‰æå–åˆ°å†…å®¹ï¼Œåˆå¹¶åˆ° response
    if extracted_content:
        current_response = results.get("response", "").strip()

        # åˆå¹¶æå–çš„å†…å®¹ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼‰
        extracted_text = " ".join(extracted_content)

        # æ£€æŸ¥ response ä¸­æ˜¯å¦å·²ç»åŒ…å«æå–çš„å†…å®¹ï¼ˆé¿å…é‡å¤ï¼‰
        should_add = True
        if current_response:
            # æ£€æŸ¥æå–çš„å†…å®¹æ˜¯å¦å·²ç»åœ¨ response ä¸­å­˜åœ¨
            # ä½¿ç”¨ç®€å•çš„åŒ…å«æ£€æŸ¥ï¼Œå¦‚æœæå–å†…å®¹çš„ä¸»è¦éƒ¨åˆ†å·²ç»åœ¨ response ä¸­ï¼Œåˆ™ä¸æ·»åŠ 
            extracted_words = set(re.findall(r'[\u4e00-\u9fff]+', extracted_text))
            response_words = set(re.findall(r'[\u4e00-\u9fff]+', current_response))

            # å¦‚æœæå–å†…å®¹çš„ä¸»è¦è¯æ±‡å¤§éƒ¨åˆ†éƒ½åœ¨ response ä¸­ï¼Œåˆ™è®¤ä¸ºå·²å­˜åœ¨
            if extracted_words and len(extracted_words.intersection(response_words)) / len(extracted_words) > 0.7:
                should_add = False
                logger.info(f"[Extract Conversational Content] Content already exists in response, skipping. Fields: {fields_to_check}")

        if should_add:
            if current_response:
                # å°†æå–çš„å†…å®¹æ”¾åœ¨ response å‰é¢
                results["response"] = f"{extracted_text} {current_response}".strip()
            else:
                # å¦‚æœ response ä¸å­˜åœ¨ï¼Œç›´æ¥è®¾ç½®
                results["response"] = extracted_text

            # è®°å½•æ—¥å¿—
            logger.info(f"[Extract Conversational Content] Extracted from fields: {fields_to_check}")
            logger.info(f"[Extract Conversational Content] Merged content length: {len(extracted_text)} characters")
            logger.info(f"[Extract Conversational Content] Content placed before existing response")

    return results

def join_prompts(prompt: dict) -> str:
    """å°†å•ä¸ªæ¨¡å— prompt å­—å…¸æ‹¼æ¥ä¸ºè§„èŒƒæ–‡æœ¬ï¼š

    è¾“å…¥ç¤ºä¾‹ï¼š
    {
      "purpose": "æ ¹æ®ä¼šè¯çŠ¶æ€å‘ç”¨æˆ·æ¨èç‰Œé˜µ",
      "name": ["ç‰Œé˜µåç§°", "æ‰€éœ€ç‰Œæ•°", "response"],
      "expect": ["ç‰Œé˜µåç§°", "ç‰Œé˜µæ‰€éœ€ç‰Œæ•°", "ä¸€æ®µè‡ªç„¶å¯¹è¯æ¥å‘ŠçŸ¥å®¢æˆ·ç‰Œé˜µï¼Œéœ€è¦æŠ½å‡ å¼ ç‰Œï¼›å¹¶è¯·å®¢æˆ·åœ¨å†…å¿ƒèšç„¦å¾…è§£çš„é—®é¢˜ï¼Œä¾ç…§ç‰Œé˜µçš„é¡ºåºï¼Œä»1è‡³78ä¸­æŠ½å–æ‰€éœ€æ•°é‡çš„æ•°å­—"],
      "operation": ["1. è¾“å‡ºç‰Œé˜µåç§°", "2. è¾“å‡ºç‰Œé˜µæ‰€éœ€ç‰Œæ•°", "3. è¾“å‡ºä¸€æ®µè‡ªç„¶å¯¹è¯â€¦â€¦"]
    }

    è¾“å‡ºï¼š
    [ä»»åŠ¡]\n<purpose>\n\n[æ­¥éª¤]\n<æŒ‰è¡Œæ‹¼æ¥ operation>\n\n[ç»“æœ]\n<æŒ‰è¡Œç¼–å·æ‹¼æ¥ expect>\n\nã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘+ JSON ç»“æ„ï¼Œå…¶ä¸­ info ç”± name/expect æˆå¯¹æ˜ å°„ï¼Œè‹¥ name ä¸º 'response'ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ï¼Œåˆ™æ˜ å°„åˆ°é¡¶çº§ "response"ã€‚
    """
    purpose = str(prompt.get("purpose", "")).strip()
    names = prompt.get("name") or []
    expects = prompt.get("expect") or []
    operations = prompt.get("operation") or []

    # æ­¥éª¤
    steps_block = "\n".join(str(x) for x in operations)

    # ç»“æœï¼ˆç¼–å·ï¼‰
    result_lines = []
    for i, exp in enumerate(expects, start=1):
        result_lines.append(f"{i}. {str(exp)}")
    results_block = "\n".join(result_lines)

    # è¾“å‡ºæ ¼å¼è¦æ±‚ï¼šinfo ä¸ response çš„æ˜ å°„
    info_pairs = []
    response_value = None

    # æ”¶é›†æ‰€æœ‰åä¸º response çš„æœŸæœ›å€¼ï¼Œå¹¶å°†å…¶åˆå¹¶åˆ°é¡¶çº§ response
    response_values = []
    for idx, n in enumerate(names):
        key = str(n)
        val = str(expects[idx]) if idx < len(expects) else ""
        if key.strip().lower() == "response":
            # æ”¶é›†åˆ°åˆ—è¡¨ï¼Œç¨åç»Ÿä¸€åˆå¹¶ä¸ºé¡¶çº§ response
            if val:
                response_values.append(val)
        else:
            info_pairs.append((key, val))

    # å°†æ‰€æœ‰ response åˆå¹¶ä¸ºä¸€ä¸ªé¡¶çº§ responseï¼ˆä¿æŒé¡ºåºï¼‰
    if response_values:
        response_value = " ".join(response_values)

    # ç»„è£… JSON ç‰‡æ®µï¼ˆä»¥æ–‡æœ¬å½¢å¼è¿”å›ï¼Œä¿æŒä¸­æ–‡ä¸å¼•å·ï¼‰
    info_lines = []
    for k, v in info_pairs:
        info_lines.append(f'        "{k}": "{v}"')
    info_block = (",\n".join(info_lines)) if info_lines else ""

    # é¡¶çº§ response è¡Œï¼ˆå¯é€‰ï¼‰
    response_line = f'      "response": "{response_value}"' if response_value is not None else None

    parts = []
    parts.append("[ä»»åŠ¡]")
    parts.append(purpose)
    parts.append("")
    parts.append("[æ­¥éª¤]")
    parts.append(steps_block)
    parts.append("")
    parts.append("[ç»“æœ]")
    parts.append(results_block)
    parts.append("")
    parts.append("    ã€è¾“å‡ºæ ¼å¼è¦æ±‚}")
    parts.append("")
    parts.append("    è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹JSONç»“æ„ï¼š")
    parts.append("    {")
    parts.append("      \"info\": {")
    if info_block:
        parts.append(info_block)
    parts.append("      }")
    if response_line is not None:
        parts.append("      ,")
        parts.append(response_line)
    parts.append("    }")

    return "\n".join(parts)


def build_response_prompt_only(prompt: dict) -> str:
    """æ ¹æ®æ¨¡å— prompt ç”Ÿæˆä»…è¾“å‡º response çš„æç¤ºè¯ã€‚"""
    purpose = str(prompt.get("purpose", "")).strip()
    operations = prompt.get("operation") or []
    expects = prompt.get("expect") or []
    names = prompt.get("name") or []

    steps_block = "\n".join(str(x) for x in operations)

    response_keywords = ("å¯¹è¯", "å›å¤", "è‡ªç„¶è¯­è¨€", "ç¤¼è²Œ", "response")
    response_expectations = []
    for idx, exp in enumerate(expects):
        exp_str = str(exp)
        name_str = (str(names[idx]) if idx < len(names) else "").strip().lower()
        if name_str == "response":
            response_expectations.append(exp_str)
            continue
        if any(keyword in exp_str for keyword in response_keywords):
            response_expectations.append(exp_str)

    if not response_expectations:
        response_expectations = ["å‘é€å¯¹è¯å›å¤"]

    result_lines = [f"{i}. {text}" for i, text in enumerate(response_expectations, start=1)]
    response_block = "\n".join(result_lines)

    parts = [
        "[å£°æ˜]",
        "",
        "ä½ åªè´Ÿè´£è¾“å‡ºè‡ªç„¶è¯­è¨€å›å¤responseç”¨ä»¥å›å¤ç”¨æˆ·ï¼Œä¸å‚ä¸ä»»ä½•å…¶ä»–ä»»åŠ¡ã€‚",
        "",
        "[ä»»åŠ¡]",
        purpose,
        "",
        "[æ­¥éª¤]",
        steps_block,
        "",
        "[ç»“æœ]",
        response_block,
        "",
        # "    ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘",
        # "",
        # "    è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹JSONç»“æ„ï¼š",
        # "    {",
        # '      "response": "å‘é€å¯¹è¯å›å¤"',
        # "    }",
    ]

    return "\n".join(parts)


def build_info_prompt_only(prompt: dict) -> str:
    """æ ¹æ®æ¨¡å— prompt ç”Ÿæˆä»…è¾“å‡º info çš„æç¤ºè¯ã€‚"""
    purpose = str(prompt.get("purpose", "")).strip()
    operations = prompt.get("operation") or []
    expects = prompt.get("expect") or []
    names = prompt.get("name") or []

    steps_block = "\n".join(str(x) for x in operations)

    info_entries = []
    for idx, exp in enumerate(expects):
        name_str = (str(names[idx]) if idx < len(names) else "").strip()
        if name_str.lower() == "response":
            continue
        exp_str = str(exp)
        info_key = name_str if name_str else f"field_{idx + 1}"
        info_entries.append((info_key, exp_str))

    if not info_entries:
        info_entries = [("field_1", "ç»“æ„åŒ–å­—æ®µ")]

    result_lines = [f"{i}. {text}" for i, (_, text) in enumerate(info_entries, start=1)]
    results_block = "\n".join(result_lines)

    info_lines = [f'        "{key}": "{value}"' for key, value in info_entries]
    info_block = ",\n".join(info_lines)

    parts = [
        "[å£°æ˜]",
        "",
        "ä½ åªè´Ÿè´£æ ¹æ®ä¸Šä¸‹æ–‡ä¸Assistantæœ¬è½®å›å¤å†…å®¹ï¼Œè¾“å‡º info æ‰€éœ€çš„ç»“æ„åŒ–å­—æ®µï¼Œä¸ç”Ÿæˆä»»ä½•è‡ªç„¶è¯­è¨€å›å¤å†…å®¹ï¼Œä½†éœ€å‚ä¸ä»»ä½•é™¤ç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤ä»¥å¤–çš„ä»»åŠ¡ã€‚ä½ çš„ç»“æœéœ€æ¥æºäºä¸Šä¸‹æ–‡ä¸Assistantæœ¬è½®å›å¤å†…å®¹ã€‚",
        "",
        "[ä»»åŠ¡]",
        purpose,
        "",
        "[æ­¥éª¤]",
        steps_block,
        "",
        "[ç»“æœ]",
        results_block,
        "",
        "    ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘",
        "",
        "    è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹JSONç»“æ„ï¼š",
        "    {",
        '      "info": {',
        f"{info_block}",
        "      }",
        "    }",
    ]

    return "\n".join(parts)


def route_current_stage(
    conversation_id: str,
    session_id: str,
    user_id: str,
    user_input: str,
    bot_id: str,
    app_id: str,
    current_state: str,
    current_sub_stage: str,
):
    """è°ƒç”¨ Router å¹¶è§£æ stage/substage ç»“æœï¼Œè¿”å› router å“åº”ä¸æœ€ç»ˆè·¯ç”±å€¼ã€‚"""
    router_response = router.route_and_store(
        conversation_id,
        session_id,
        user_id,
        user_input,
        bot_id,
        app_id,
        current_state,
    )
    parsed = router_response.get("llm_output")
    logger.info("[Router] route_current_stage è¾“å‡º: %s", json.dumps(router_response, ensure_ascii=False, indent=2))

    routed_current_state = ""
    routed_current_sub_stage = ""
    if isinstance(parsed, dict) and "queries" in parsed and isinstance(parsed["queries"], list) and parsed["queries"]:
        first_query = parsed["queries"][0]
        if isinstance(first_query, dict):
            routed_current_state = first_query.get("stage", "")
            routed_current_sub_stage = first_query.get("substage", "")

    if not routed_current_state:
        routed_current_state = current_state
    if not routed_current_sub_stage:
        routed_current_sub_stage = current_sub_stage

    logger.info("[Router] route_current_stage ç»“æœ: state=%s, sub_stage=%s", routed_current_state, routed_current_sub_stage)
    return router_response, routed_current_state, routed_current_sub_stage


def _select_stage_module(route_state_prompt_map: Dict[str, List[dict]], stage: str, sub_stage: str) -> dict:
    """æ ¹æ®é˜¶æ®µå’Œå­é˜¶æ®µç¼–å·é€‰æ‹©å¯¹åº”çš„æ¨¡å—å­—å…¸ã€‚"""
    if not isinstance(route_state_prompt_map, dict):
        return {}
    modules = route_state_prompt_map.get(stage) or []
    if not isinstance(modules, list) or not modules:
        return {}
    module_idx = 0
    if isinstance(sub_stage, str) and "_" in sub_stage:
        num_part = sub_stage.split("_")[-1]
        if num_part.isdigit():
            module_idx = max(int(num_part) - 1, 0)
    if module_idx >= len(modules):
        module_idx = 0
    module = modules[module_idx]
    return module if isinstance(module, dict) else {}


def normalize_substage_name(state: str, sub_stage: str) -> str:
    """ç¡®ä¿è¿”å› {stage}_{xx} æ ¼å¼çš„å­é˜¶æ®µåç§°ã€‚"""
    if sub_stage and "_" in sub_stage:
        if sub_stage.count("_") >= 2:
            return sub_stage
        num_part = sub_stage.split("_")[-1]
        return f"{state}_{num_part}"
    return f"{state}_01"


def _generate_info_content(
    *,
    character_prompt: str,
    route_state_prompt_map: Dict[str, List[dict]],
    routed_current_state: str,
    routed_current_sub_stage: str,
    input_text: str,
    history_context: Any,
    session_state: Dict[str, Any],
    bot_llm_config: Dict[str, Any],
    input_label: str = "ç”¨æˆ·æœ¬è½®",
) -> Dict[str, Any]:
    """å†…éƒ¨å‡½æ•°ï¼šè°ƒç”¨ info LLM ç”Ÿæˆ info å†…å®¹ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰ã€‚
    
    å‚æ•°:
        input_text: è¾“å…¥æ–‡æœ¬ï¼ˆå¯ä»¥æ˜¯ user_input æˆ– response_contentï¼‰
        input_label: è¾“å…¥æ ‡ç­¾ï¼ˆç”¨äº prompt æ˜¾ç¤ºï¼‰
    
    è¿”å›:
        info_content å­—å…¸
    """
    stage_module = _select_stage_module(route_state_prompt_map, routed_current_state, routed_current_sub_stage)
    info_prompt = build_info_prompt_only(stage_module) if stage_module else ""
    prompt_parts = [segment for segment in (character_prompt, info_prompt) if segment]
    full_prompt = "\n\n".join(prompt_parts)

    llm_result = llm_generic(
        full_prompt=full_prompt,
        user_input=input_text,
        history_context=history_context,
        session_state=session_state,
        botLLMConfig=bot_llm_config,
        prompt_without_character=info_prompt,
        input_label=input_label,
    )

    if isinstance(llm_result, str):
        try:
            llm_result = json.loads(_cleanup_llm_json_str(llm_result))
        except json.JSONDecodeError:
            llm_result = {"info": {"value": llm_result}}

    info_content: Dict[str, Any] = {}
    if isinstance(llm_result, dict):
        info_field = llm_result.get("info")
        if isinstance(info_field, dict):
            info_content = info_field
        elif info_field is not None:
            info_content = {"value": info_field}
    else:
        info_content = {"value": llm_result}
    
    return info_content


def generate_info_payload(
    *,
    character_prompt: str,
    route_state_prompt_map: Dict[str, List[dict]],
    routed_current_state: str,
    routed_current_sub_stage: str,
    turn_uuid: str,
    conversation_id: str,
    session_id: str,
    user_id: str,
    user_input: str,
    history_context: Any,
    session_state: Dict[str, Any],
    bot_llm_config: Dict[str, Any],
) -> Dict[str, Any]:
    """è°ƒç”¨ info LLMï¼Œæ›´æ–° pending_turnï¼Œå¹¶è¿”å›åŒ…å« info çš„ payloadã€‚"""
    info_content = _generate_info_content(
        character_prompt=character_prompt,
        route_state_prompt_map=route_state_prompt_map,
        routed_current_state=routed_current_state,
        routed_current_sub_stage=routed_current_sub_stage,
        input_text=user_input,
        history_context=history_context,
        session_state=session_state,
        bot_llm_config=bot_llm_config,
        input_label="ç”¨æˆ·æœ¬è½®",
    )

    substage_col = normalize_substage_name(routed_current_state, routed_current_sub_stage)
    stage_payload = {substage_col: {"info": info_content}}
    try:
        db.update_pending_turn_state(
            turn_uuid=turn_uuid,
            routed_current_state=routed_current_state,
            routed_current_sub_stage=routed_current_sub_stage,
            stage_payload_draft=json.dumps(stage_payload, ensure_ascii=False),
        )
    except Exception as exc:
        logger.warning("[generate_info_payload] æ›´æ–° pending_turn info å¤±è´¥: %s", exc)

    return {
        "info": info_content,
        "turn_uuid": turn_uuid,
        "routed_current_state": routed_current_state,
        "routed_current_sub_stage": routed_current_sub_stage,
    }


def generate_product_analysis_payload(
    *,
    character_prompt: str,
    route_state_prompt_map: Dict[str, List[dict]],
    routed_current_state: str,
    routed_current_sub_stage: str,
    user_input: str,
    history_context: Any,
    session_state: Dict[str, Any],
    bot_llm_config: Dict[str, Any],
    turn_uuid: str,
    product_list_text: str,
    fn: Optional[Callable[[Dict[str, Any]], None]] = None,
) -> Dict[str, Any]:
    """è°ƒç”¨å•†å“åˆ†æ LLMï¼Œåˆ†ææ˜¯å¦éœ€è¦æ¨è/å”®å–å•†å“ï¼Œæ›´æ–° pending_turnï¼Œå¹¶è¿”å›ç»“æœã€‚

    å‚æ•°:
        character_prompt: è§’è‰²è®¾å®š prompt
        route_state_prompt_map: è·¯ç”±çŠ¶æ€ prompt æ˜ å°„ï¼Œç”¨äºè·å–å½“å‰é˜¶æ®µçš„ç›®æ ‡æç¤ºè¯
        routed_current_state: è·¯ç”±åçš„é˜¶æ®µ
        routed_current_sub_stage: è·¯ç”±åçš„å­é˜¶æ®µ
        user_input: ç”¨æˆ·è¾“å…¥
        history_context: å†å²å¯¹è¯ä¸Šä¸‹æ–‡
        session_state: ä¼šè¯çŠ¶æ€
        bot_llm_config: LLM é…ç½®
        turn_uuid: å›åˆ UUID
        product_list_text: å•†å“åˆ—è¡¨æ–‡æœ¬ï¼ˆå·²æ ¼å¼åŒ–ï¼‰
        fn: å¯é€‰çš„å›è°ƒå‡½æ•°ï¼Œç”¨äºæ¨é€äº‹ä»¶ç»™å‰ç«¯

    è¿”å›:
        åŒ…å« product_id_promoted / product_equity_promoted / product_id_sales / product_equity_sales å’Œ turn_uuid çš„å­—å…¸
    """
    # æ„å»ºå•†å“åˆ†æ prompt
    product_analysis_prompt = "\n".join([
        "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½é”€å”®åŠ©æ‰‹ï¼Œè´Ÿè´£æ ¹æ®å½“å‰ä»»åŠ¡å’Œå¯¹è¯åˆ¤æ–­æ˜¯å¦éœ€è¦æ¨é”€æˆ–å”®å–å•†å“ï¼Œæˆ–ä¸¤ç§çš†æœ‰ã€‚è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š",
        "",
        "è¾“å…¥ï¼š",
        "- é˜¶æ®µä»»åŠ¡ï¼šå½“å‰é”€å”®ç›®æ ‡",
        "- ä¸Šä¸‹æ–‡ï¼šå†å²å¯¹è¯ä¸ä¼šè¯ä¿¡æ¯ï¼ˆç”±ç³»ç»Ÿæä¾›ï¼‰",
        "- ç”¨æˆ·æœ¬è½®ï¼šç”¨æˆ·å½“å‰å›å¤",
        "- å•†å“åˆ—è¡¨ï¼šå¯ç”¨å•†å“ä¿¡æ¯ï¼ŒåŒ…å«å•†å“IDã€ä»‹ç»ã€æƒç›Šç­‰",
        "",
        "åˆ¤æ–­é€»è¾‘ï¼š",
        "1. æ¨é”€ï¼ˆproduct_id_promoted / product_equity_promotedï¼‰ï¼š",
        "   - å½“éœ€è¦ä¸»åŠ¨æ¨èå•†å“æˆ–æƒç›Šæ—¶ä½¿ç”¨ï¼Œä¾‹å¦‚ï¼š",
        "     * é˜¶æ®µä»»åŠ¡è¦æ±‚'æ¨é”€å•†å“'æˆ–'æ¨èå•†å“'",
        "     * ç”¨æˆ·è¯¢é—®å•†å“åŠŸèƒ½ã€ä»·æ ¼ã€ç‰¹ç‚¹ç­‰",
        "     * å†å²èŠå¤©ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºæƒ³äº†è§£æŸç±»å•†å“æˆ–è¦æ±‚æ¨èå•†å“",
        "",
        "2. å”®å–ï¼ˆproduct_id_sales / product_equity_salesï¼‰ï¼š",
        "   - å½“ç”¨æˆ·æ˜ç¡®è¡¨è¾¾è´­ä¹°æ„å›¾æ—¶ä½¿ç”¨ï¼Œä¾‹å¦‚ï¼š",
        "     * ç”¨æˆ·è¯´'æˆ‘æƒ³è´­ä¹°'ã€'æˆ‘è¦ä¹°'ã€'å¸®æˆ‘ä¸‹å•'ã€'è´­ä¹°XX'ã€'è®¢é˜…XX'ç­‰",
        "     * ç”¨æˆ·è¯´'ç»™æˆ‘å‘é“¾æ¥'ã€'å‘è´­ä¹°é“¾æ¥'ã€'æ€ä¹ˆä¹°'ç­‰è´­ä¹°ç›¸å…³è¯·æ±‚",
        "     * é˜¶æ®µä»»åŠ¡ä¸º'å®Œæˆé”€å”®'æˆ–'ä¿ƒæˆäº¤æ˜“'",
        "     * å†å²èŠå¤©å·²è¾¾æˆè´­ä¹°æ„å‘ï¼Œç”¨æˆ·ç¡®è®¤è¦è´­ä¹°",
        "   - é‡è¦ï¼šåªè¦ç”¨æˆ·æ˜ç¡®è¡¨è¾¾è´­ä¹°æ„å›¾ï¼Œå°±å¿…é¡»è®¾ç½® product_id_sales å’Œ product_equity_salesï¼Œå³ä½¿é˜¶æ®µä»»åŠ¡ä¸æ˜¯é”€å”®",
        "",
        "3. åŒæ—¶å­˜åœ¨ï¼š",
        "   - å¯ä»¥åŒæ—¶è®¾ç½®æ¨é”€å’Œå”®å–å­—æ®µï¼Œä¾‹å¦‚ï¼šç”¨æˆ·æƒ³è´­ä¹°Aå•†å“ï¼ŒåŒæ—¶æ¨èBå•†å“",
        "",
        "4. æ— è¡Œä¸ºï¼š",
        "   - è‹¥æ— éœ€æ¨é”€æˆ–å”®å–ï¼Œæ‰€æœ‰å­—æ®µå‡ä¿æŒç©ºå­—ç¬¦ä¸²",
        "",
        "æ³¨æ„äº‹é¡¹ï¼š",
        "- å•†å“IDä¸æƒç›Škeyå¿…é¡»æ¥è‡ªè¾“å…¥çš„å•†å“åˆ—è¡¨ï¼Œç¡®ä¿å‡†ç¡®æ€§",
        "- å¦‚æœæ¶‰åŠå¤šä¸ªå•†å“æˆ–æƒç›Šï¼Œå¯ä½¿ç”¨ JSON æ•°ç»„ï¼ˆå¦‚ [\"p1\", \"p2\"]ï¼‰",
        "- æƒç›Škeyéœ€æ ¹æ®ç”¨æˆ·éœ€æ±‚å¡«å†™ç›¸åº”çš„æƒç›Škey",
        "- ä¼˜å…ˆè¯†åˆ«è´­ä¹°æ„å›¾ï¼šå¦‚æœç”¨æˆ·æ˜ç¡®è¡¨è¾¾è´­ä¹°ï¼Œä¼˜å…ˆè®¾ç½® workflow å­—æ®µ",
        "",
        "è¾“å‡ºè¦æ±‚ï¼š",
        "- ä»…è¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–å†…å®¹",
        "- ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ï¼š",
        "{",
        '  "product_id_promoted": "å•†å“IDæˆ–ç©ºå­—ç¬¦ä¸²",',
        '  "product_equity_promoted": "æƒç›Škeyæˆ–ç©ºå­—ç¬¦ä¸²",',
        '  "product_id_sales": "å•†å“IDæˆ–ç©ºå­—ç¬¦ä¸²",',
        '  "product_equity_sales": "æƒç›Škeyæˆ–ç©ºå­—ç¬¦ä¸²"',
        "}",
        "",
        "æ ¹æ®å®é™…è¾“å…¥åˆ†æå¹¶è¾“å‡ºJSONã€‚",
    ])

    # å°†é˜¶æ®µâ€œä»»åŠ¡â€éƒ¨åˆ†æ‹¼æ¥è¿›å•†å“åˆ†æ prompt
    stage_module = _select_stage_module(route_state_prompt_map, routed_current_state, routed_current_sub_stage)
    stage_task_text = ""
    if isinstance(stage_module, dict):
        stage_purpose = str(stage_module.get("purpose", "")).strip()
        if stage_purpose:
            stage_task_text = f"ã€é˜¶æ®µä»»åŠ¡ã€‘ï¼š{stage_purpose}"

    product_list_block = ""
    if product_list_text and product_list_text.strip():
        product_list_block = "ã€å•†å“åˆ—è¡¨ã€‘\n" + product_list_text.strip()

    # ç»„è£…å®Œæ•´ prompt
    prompt_parts = [segment for segment in (stage_task_text, product_analysis_prompt, product_list_block) if segment]
    prompt_without_character = "\n\n".join(prompt_parts)
    full_prompt = prompt_without_character

    # ç”¨æˆ·è¾“å…¥ä¿æŒä»…åŒ…å«ç”¨æˆ·æ¶ˆæ¯
    user_input_with_products = f"ç”¨æˆ·æœ¬è½®ï¼š{user_input}"

    # è°ƒç”¨ LLM
    llm_result = llm_generic(
        full_prompt=full_prompt,
        user_input=user_input_with_products,
        history_context=history_context,
        session_state=session_state,
        botLLMConfig=bot_llm_config,
        prompt_without_character=full_prompt,
    )

    # è§£æ LLM ç»“æœ
    product_id_promoted = ""
    product_equity_promoted = ""
    product_id_sales = ""
    product_equity_sales = ""

    if isinstance(llm_result, str):
        try:
            llm_result = json.loads(_cleanup_llm_json_str(llm_result))
        except json.JSONDecodeError:
            logger.warning("[generate_product_analysis_payload] LLM è¿”å›ç»“æœä¸æ˜¯æœ‰æ•ˆ JSON: %s", llm_result)
            llm_result = {}

    if isinstance(llm_result, dict):
        # è§„èŒƒåŒ–å•†å“IDå’Œæƒç›ŠIDä¸ºå•ä¸ªå­—ç¬¦ä¸²ï¼ˆæ•°ç»„å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰
        product_id_promoted = _normalize_to_single_id(llm_result.get("product_id_promoted", ""))
        product_equity_promoted = _normalize_to_single_id(llm_result.get("product_equity_promoted", ""))
        product_id_sales = _normalize_to_single_id(llm_result.get("product_id_sales", ""))
        product_equity_sales = _normalize_to_single_id(llm_result.get("product_equity_sales", ""))

    # æ›´æ–° pending_turnï¼ˆå­˜å…¥å•†å“åˆ†æç»“æœï¼‰
    try:
        product_analysis_payload = {
            "product_id_promoted": product_id_promoted,
            "product_equity_promoted": product_equity_promoted,
            "product_id_sales": product_id_sales,
            "product_equity_sales": product_equity_sales,
        }
        db.update_pending_turn_state(
            turn_uuid=turn_uuid,
            routed_current_state=routed_current_state,
            routed_current_sub_stage=routed_current_sub_stage,
            stage_payload_draft=json.dumps(
                {f"{routed_current_sub_stage}.product_analysis": {"info": product_analysis_payload}},
                ensure_ascii=False
            ),
        )
    except Exception as exc:
        logger.warning("[generate_product_analysis_payload] æ›´æ–° pending_turn å•†å“åˆ†æç»“æœå¤±è´¥: %s", exc)

    result_payload = {
        "product_id_promoted": product_id_promoted,
        "product_equity_promoted": product_equity_promoted,
        "product_id_sales": product_id_sales,
        "product_equity_sales": product_equity_sales,
        "turn_uuid": turn_uuid,
    }

    # å¦‚æœæä¾›äº† fn å›è°ƒï¼Œç«‹å³æ¨é€å•†å“åˆ†æäº‹ä»¶
    if fn:
        try:
            fn({
                "event": "reply",
                "data": {
                    "info": {
                        "product_id_promoted": product_id_promoted,
                        "product_equity_promoted": product_equity_promoted,
                        "product_id_sales": product_id_sales,
                        "product_equity_sales": product_equity_sales,
                    },
                    "turn_uuid": turn_uuid,
                },
            })
        except Exception as exc:
            logger.warning("[generate_product_analysis_payload] æ¨é€å•†å“åˆ†æäº‹ä»¶å¤±è´¥: %s", exc)

    return result_payload


def build_prev_next_step_texts(
    *,
    routed_current_state: str,
    routed_current_sub_stage: str,
    route_state_prompt_map: Dict[str, List[dict]],
    stages_complete: Optional[Dict[str, bool]] = None,
) -> Tuple[str, str]:
    """æ„å»ºä¸Šä¸€æ­¥å’Œä¸‹ä¸€æ­¥ä»»åŠ¡çš„æç¤ºè¯æ–‡æœ¬ã€‚
    
    å‚æ•°:
        routed_current_state: è·¯ç”±åçš„é˜¶æ®µ
        routed_current_sub_stage: è·¯ç”±åçš„å­é˜¶æ®µ
        route_state_prompt_map: è·¯ç”±çŠ¶æ€ prompt æ˜ å°„
        stages_complete: æ‰€æœ‰é˜¶æ®µå®ŒæˆçŠ¶æ€å­—å…¸ï¼ˆå¯é€‰ï¼‰
    
    è¿”å›:
        (prev_step_text, next_step_text) å…ƒç»„
    """
    prev_step_text = ""
    next_step_text = ""
    
    if not stages_complete:
        return prev_step_text, next_step_text
    
    try:
        # è®¡ç®—å½“å‰å®Œæ•´ substage åç§°ï¼ˆå¦‚ cognition_01ï¼‰
        if routed_current_sub_stage and '_' in routed_current_sub_stage:
            if routed_current_sub_stage.count('_') >= 2:
                current_substage_full = routed_current_sub_stage
            else:
                num_part = routed_current_sub_stage.split('_')[-1]
                current_substage_full = f"{routed_current_state}_{num_part}"
        else:
            current_substage_full = f"{routed_current_state}_01"
        
        stages_list = list(stages_complete.keys()) if isinstance(stages_complete, dict) else []
        
        # ä¸Šä¸€æ­¥ä»»åŠ¡ï¼šå–å…¨å±€é¡ºåºä¸­å½“å‰å­é˜¶æ®µä¹‹å‰çš„ç¬¬ä¸€ä¸ªåˆæ³•å­é˜¶æ®µ
        try:
            prev_module = None
            if current_substage_full in stages_list:
                cur_idx = stages_list.index(current_substage_full)
                for j in range(cur_idx - 1, -1, -1):
                    substage_name = stages_list[j]
                    stage_name = substage_name.rsplit('_', 1)[0] if '_' in substage_name else substage_name
                    if stage_name in ("questions", "after_sales"):
                        continue
                    stage_modules = route_state_prompt_map.get(stage_name, [])
                    if stage_modules:
                        prev_module = stage_modules[0]
                        break
            if isinstance(prev_module, dict):
                prev_purpose = str(prev_module.get("purpose", "")).strip()
                if prev_purpose:
                    prev_step_text = "\n\n".join(["[ä¸Šä¸€æ­¥ä»»åŠ¡]", prev_purpose])
        except Exception:
            prev_step_text = ""

        # ä¸‹ä¸€æ­¥ä»»åŠ¡ï¼šä»å…¨å±€ stages_complete é¡ºåºä¸­é€‰å–"å½“å‰å­é˜¶æ®µä¹‹å"çš„ä¸‹ä¸€ä¸ªå­é˜¶æ®µ
        try:
            next_module = None
            if current_substage_full in stages_list:
                cur_idx = stages_list.index(current_substage_full)
                for j in range(cur_idx + 1, len(stages_list)):
                    substage_name = stages_list[j]
                    # è¿‡æ»¤ä¸å¯é€‰é˜¶æ®µ
                    stage_name = substage_name.rsplit('_', 1)[0] if '_' in substage_name else substage_name
                    if stage_name in ("questions", "after_sales"):
                        continue
                    stage_modules = route_state_prompt_map.get(stage_name, [])
                    if stage_modules:
                        next_module = stage_modules[0]
                        break
            # å– purpose å¹¶æ‹¼æ¥
            if isinstance(next_module, dict):
                next_purpose = str(next_module.get("purpose", "")).strip()
                if next_purpose:
                    next_step_text = "\n\n".join(["[ä¸‹ä¸€æ­¥ä»»åŠ¡]", next_purpose])
        except Exception:
            next_step_text = ""
    except Exception:
        # ä¸å½±å“ä¸»æµç¨‹
        prev_step_text = ""
        next_step_text = ""
    
    return prev_step_text, next_step_text


def generate_response_payload(
    *,
    character_prompt: str,
    route_state_prompt_map: Dict[str, List[dict]],
    routed_current_state: str,
    routed_current_sub_stage: str,
    turn_uuid: str,
    conversation_id: str,
    session_id: str,
    user_id: str,
    user_input: str,
    history_context: Any,
    session_state: Dict[str, Any],
    bot_llm_config: Dict[str, Any],
    product_analysis_result: Optional[Dict[str, Any]] = None,
    prev_step_text: str = "",
    next_step_text: str = "",
    marketing_context: str = "",
    formatted_products_text: Dict[str, Any],
    fn: Optional[Callable[[Dict[str, Any]], None]] = None,
) -> Dict[str, Any]:
    """è°ƒç”¨ response LLMï¼Œç”Ÿæˆè‡ªç„¶è¯­è¨€å›å¤ï¼Œæ›´æ–° pending_turnï¼Œå¹¶é€šè¿‡ fn æ¨é€äº‹ä»¶ã€‚

    å‚æ•°:
        character_prompt: è§’è‰²è®¾å®š prompt
        route_state_prompt_map: è·¯ç”±çŠ¶æ€ prompt æ˜ å°„
        routed_current_state: è·¯ç”±åçš„é˜¶æ®µ
        routed_current_sub_stage: è·¯ç”±åçš„å­é˜¶æ®µ
        turn_uuid: å›åˆ UUID
        conversation_id: ä¼šè¯ ID
        session_id: ä¼šè¯ ID
        user_id: ç”¨æˆ· ID
        user_input: ç”¨æˆ·è¾“å…¥
        history_context: å†å²å¯¹è¯ä¸Šä¸‹æ–‡
        session_state: ä¼šè¯çŠ¶æ€
        bot_llm_config: LLM é…ç½®
        product_analysis_result: å•†å“åˆ†æç»“æœï¼ˆå¯é€‰ï¼‰
        prev_step_text: ä¸Šä¸€æ­¥ä»»åŠ¡æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
        next_step_text: ä¸‹ä¸€æ­¥ä»»åŠ¡æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
        marketing_context: è¥é”€è¯æœ¯æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
        formatted_products_text: å•†å“åˆ—è¡¨æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
        fn: å›è°ƒå‡½æ•°ï¼Œç”¨äºæ¨é€äº‹ä»¶ç»™å‰ç«¯

    è¿”å›:
        åŒ…å« response å’Œ turn_uuid çš„å­—å…¸
    """
    stage_module = _select_stage_module(route_state_prompt_map, routed_current_state, routed_current_sub_stage)
    response_prompt = build_response_prompt_only(stage_module) if stage_module else ""
    # æ³¨æ„é¡ºåºï¼šå½“å‰é˜¶æ®µ -> ä¸Šä¸€æ­¥ä»»åŠ¡ -> ä¸‹ä¸€æ­¥ä»»åŠ¡
    system_context_parts: List[str] = []
    marketing_context_text = ""
    if isinstance(marketing_context, str) and marketing_context.strip():
        marketing_context_text = marketing_context.strip()
        system_context_parts.append("ã€è¥é”€è¯æœ¯ã€‘\n" + marketing_context_text)
    # ç§»é™¤å•†å“åˆ—è¡¨æ‹¼æ¥ - ä¸å†å°†å•†å“åˆ—è¡¨æ‹¼æ¥åˆ°å›å¤promptä¸­
    # formatted_block = ""
    # if isinstance(formatted_products_text, str) and formatted_products_text.strip():
    #     formatted_block = formatted_products_text.strip()
    #     if formatted_block.startswith("å•†å“åˆ—è¡¨"):
    #         system_context_parts.append(formatted_block)
    #     else:
    #         system_context_parts.append("ã€å•†å“çŸ¥è¯†ã€‘\n" + formatted_block)

    base_prompt_parts = [p for p in [character_prompt, response_prompt, prev_step_text, next_step_text] if p]

    # ç”¨æˆ·æœ¬è½®è¾“å…¥
    user_input_sections = [f"ç”¨æˆ·æœ¬è½®ï¼š{user_input}"]

    # ä»…æ‹¼æ¥ã€æ¨å¹¿å•†å“ä¿¡æ¯ã€‘ï¼Œä¸å†æ‹¼æ¥ã€å•†å“åˆ†æç»“æœã€‘
    if product_analysis_result:
        promo_details = product_analysis_result.get("promoted_product_details")
        if promo_details:
            system_context_parts.append(f"ã€Related products/å…³è”å•†å“ã€‘\n{promo_details}")
            logger.info(
                "[generate_response_payload] å·²é™„åŠ æ¨å¹¿å•†å“ä¿¡æ¯åˆ° system prompt",
            )
        # ä» product_analysis_result ä¸­è¯»å–çŸ¥è¯†åº“å†…å®¹ï¼ˆçº¯çŸ¥è¯†åº“æ–‡æœ¬ï¼Œä¸å«å•†å“å…¶ä»–ä¿¡æ¯ï¼‰
        knowledge_content = product_analysis_result.get("knowledgeContent")
        if isinstance(knowledge_content, str) and knowledge_content.strip():
            system_context_parts.append(f"ã€å•†å“çŸ¥è¯†ã€‘\n{knowledge_content.strip()}")
            logger.info(
                "[generate_response_payload] å·²é™„åŠ å•†å“çŸ¥è¯†åˆ° system promptï¼Œé•¿åº¦=%d",
                len(knowledge_content),
            )

    if marketing_context_text:
        logger.info(
            "[generate_response_payload] å·²é™„åŠ è¥é”€è¯æœ¯åˆ° system promptï¼Œé•¿åº¦=%d",
            len(marketing_context_text),
        )
    # ç§»é™¤å•†å“åˆ—è¡¨æ—¥å¿—
    # if formatted_block:
    #     logger.info(
    #         "[generate_response_payload] å·²é™„åŠ å•†å“åˆ—è¡¨åˆ° system promptï¼Œé•¿åº¦=%d",
    #         len(formatted_block),
    #     )

    context_prompt_part = "\n\n".join(system_context_parts) if system_context_parts else ""
    full_prompt_parts = list(base_prompt_parts)
    if context_prompt_part:
        full_prompt_parts.append(context_prompt_part)
    full_prompt = "\n\n".join(full_prompt_parts)

    user_input_for_llm = "\n\n".join(user_input_sections)

    llm_result = llm_generic(
        full_prompt=full_prompt,
        user_input=user_input_for_llm,
        history_context=history_context,
        session_state=session_state,
        botLLMConfig=bot_llm_config,
        prompt_without_character=full_prompt,
    )

    # è§£æ LLM ç»“æœ
    logger.info("[generate_response_payload] LLM åŸå§‹è¿”å›ç»“æœç±»å‹: %s", type(llm_result).__name__)
    if isinstance(llm_result, str):
        logger.info("[generate_response_payload] LLM åŸå§‹è¿”å›å­—ç¬¦ä¸²: %s", llm_result[:500] if len(llm_result) > 500 else llm_result)
    
    response_content = ""
    if isinstance(llm_result, str):
        try:
            llm_result = json.loads(_cleanup_llm_json_str(llm_result))
        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯ JSONï¼Œç›´æ¥ä½œä¸º response
            response_content = llm_result

    if isinstance(llm_result, dict):
        response_field = llm_result.get("response")
        if isinstance(response_field, str):
            response_content = response_field
        elif response_field is not None:
            response_content = str(response_field)

    # æ›´æ–° pending_turnï¼ˆå­˜å…¥ responseï¼‰
    substage_col = normalize_substage_name(routed_current_state, routed_current_sub_stage)
    stage_payload = {substage_col: {"response": response_content}}
    try:
        db.update_pending_turn_state(
            turn_uuid=turn_uuid,
            routed_current_state=routed_current_state,
            routed_current_sub_stage=routed_current_sub_stage,
            stage_payload_draft=json.dumps(stage_payload, ensure_ascii=False),
        )
    except Exception as exc:
        logger.warning("[generate_response_payload] æ›´æ–° pending_turn response å¤±è´¥: %s", exc)

    result_payload = {
        "response": response_content,
        "turn_uuid": turn_uuid,
        "routed_current_state": routed_current_state,
        "routed_current_sub_stage": routed_current_sub_stage,
    }

    # å¦‚æœæä¾›äº† fn å›è°ƒï¼Œç«‹å³æ¨é€ response äº‹ä»¶
    if fn:
        try:
            fn({
                "event": "reply",
                "data": {
                    "response": response_content,
                    "turn_uuid": turn_uuid,
                },
            })
        except Exception as exc:
            logger.warning("[generate_response_payload] æ¨é€ response äº‹ä»¶å¤±è´¥: %s", exc)

    return result_payload


def get_all_stages_and_substages(conversation_id: str, bot_config: Any) -> Dict[str, bool]:
    """ä» bot_config ä¸­æŒ‰é¡ºåºæå–æ‰€æœ‰ stage å’Œ substage çš„åç§°ï¼Œè¿”å›å­—å…¸è¡¨ç¤ºæ˜¯å¦å®Œæˆã€‚

    å‚æ•°:
        conversation_id: ä¼šè¯æ ‡è¯†ï¼ˆç”¨äºç¼“å­˜é”®ï¼‰
        bot_config: get_bot_config è¿”å›çš„é…ç½®å¯¹è±¡

    è¿”å›:
        Dict[str, bool]: æ ¼å¼ä¸º {"cognition_01": False, "interest_01": False, ...}
                        é”®ä¸º "{stage}_{index:02d}" æ ¼å¼ï¼Œå€¼ä¸ºæ˜¯å¦å®Œæˆçš„å¸ƒå°”å€¼ï¼ˆé»˜è®¤ä¸º Falseï¼‰

    æ³¨æ„:
        - ç»“æœæŒ‰ä¼šè¯ç¼“å­˜ï¼Œç¼“å­˜æœ‰æ•ˆæœŸ 90 å¤©
        - ç¼“å­˜é”®æ ¼å¼: "stages_substages:{conversation_id}"
    """
    cache_key = f"stages_substages:{conversation_id}"

    # å°è¯•ä»ç¼“å­˜è¯»å–
    cached = redis_get(cache_key)
    if cached:
        try:
            obj = json.loads(cached)
            # ç¡®ä¿è¿”å›çš„æ˜¯æ­£ç¡®çš„æ ¼å¼
            if isinstance(obj, dict):
                # è½¬æ¢å­—ç¬¦ä¸²é”®çš„å¸ƒå°”å€¼ä¸ºçœŸæ­£çš„å¸ƒå°”å€¼ï¼ˆredis è¿”å›çš„æ˜¯å­—ç¬¦ä¸²ï¼‰
                result = {}
                for k, v in obj.items():
                    if isinstance(v, bool):
                        result[k] = v
                    elif isinstance(v, str):
                        result[k] = v.lower() in ('true', '1', 'yes')
                    else:
                        result[k] = bool(v)
                return result
        except Exception:
            # ç¼“å­˜è§£æå¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œè®¡ç®—é€»è¾‘
            pass

    # è®¡ç®—æ‰€æœ‰ stage å’Œ substage
    structuredContent = bot_config.structuredContent

    # ä¼˜å…ˆä½¿ç”¨ routeStateStrategiesï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ routeStatePrompt
    route_state_map = structuredContent.get('routeStateStrategies') or structuredContent.get('routeStatePrompt')

    if not isinstance(route_state_map, dict):
        return {}

    result = {}

    # æŒ‰æŒ‡å®šé¡ºåºéå†é˜¶æ®µï¼›æœªåŒ…å«çš„é˜¶æ®µæŒ‰åŸé¡ºåºé™„åŠ åœ¨å
    desired_order = ["cognition", "interest", "decision_making", "compliance", "after_sales"]
    all_stage_names = list(route_state_map.keys())
    ordered_stage_names = [s for s in desired_order if s in route_state_map]
    # é™„åŠ å‰©ä½™æœªå‡ºç°åœ¨ desired_order ä¸­çš„é˜¶æ®µï¼Œä¿æŒåŸé¡ºåº
    ordered_stage_names.extend([s for s in all_stage_names if s not in desired_order])

    for stage_name in ordered_stage_names:
        modules = route_state_map.get(stage_name)
        if not isinstance(modules, list):
            continue

        # éå†æ¯ä¸ªæ¨¡å—ï¼Œç”Ÿæˆ substage åç§°
        for idx, module in enumerate(modules, start=1):
            substage_name = f"{stage_name}_{idx:02d}"
            result[substage_name] = False  # é»˜è®¤æœªå®Œæˆ

    # å†™å…¥ç¼“å­˜ï¼ˆ90 å¤©ï¼Œä¸ bot_config ç¼“å­˜æ—¶é•¿ä¸€è‡´ï¼‰
    try:
        redis_set(cache_key, json.dumps(result, ensure_ascii=False), expired=7_776_000)
    except Exception:
        # ç¼“å­˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
        pass

    return result

def set_all_stages_and_substages(conversation_id: str, substage_name: str, is_complete: bool, bot_config: Any = None) -> bool:
    """æ›´æ–° Redis ç¼“å­˜ä¸­æŒ‡å®š substage çš„å®ŒæˆçŠ¶æ€ã€‚

    å‚æ•°:
        conversation_id: ä¼šè¯æ ‡è¯†ï¼ˆç”¨äºç¼“å­˜é”®ï¼‰
        substage_name: è¦æ›´æ–°çš„ substage åç§°ï¼Œæ ¼å¼å¦‚ "cognition_01", "interest_02" ç­‰
        is_complete: å®ŒæˆçŠ¶æ€ï¼ˆTrue è¡¨ç¤ºå®Œæˆï¼ŒFalse è¡¨ç¤ºæœªå®Œæˆï¼‰
        bot_config: å¯é€‰çš„ bot_config å¯¹è±¡ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨ä¸”æä¾›æ­¤å‚æ•°ï¼Œä¼šå…ˆåˆå§‹åŒ–ç¼“å­˜

    è¿”å›:
        bool: æ˜¯å¦æ›´æ–°æˆåŠŸ

    æ³¨æ„:
        - å¦‚æœç¼“å­˜ä¸å­˜åœ¨ï¼Œä¸”æä¾›äº† bot_configï¼Œä¼šå…ˆè°ƒç”¨ get_all_stages_and_substages åˆå§‹åŒ–ç¼“å­˜
        - å¦‚æœç¼“å­˜ä¸å­˜åœ¨ä¸”æœªæä¾› bot_configï¼Œä¼šè¿”å› Falseï¼ˆæ›´æ–°å¤±è´¥ï¼‰
    """
    cache_key = f"stages_substages:{conversation_id}"

    # å°è¯•ä»ç¼“å­˜è¯»å–ç°æœ‰æ•°æ®
    cached = redis_get(cache_key)
    stages_dict = {}

    if cached:
        try:
            obj = json.loads(cached)
            if isinstance(obj, dict):
                # è½¬æ¢å­—ç¬¦ä¸²å¸ƒå°”å€¼ä¸ºçœŸæ­£çš„å¸ƒå°”å€¼
                for k, v in obj.items():
                    if isinstance(v, bool):
                        stages_dict[k] = v
                    elif isinstance(v, str):
                        stages_dict[k] = v.lower() in ('true', '1', 'yes')
                    else:
                        stages_dict[k] = bool(v)
        except Exception:
            # ç¼“å­˜è§£æå¤±è´¥ï¼Œå¦‚æœæä¾›äº† bot_config åˆ™åˆå§‹åŒ–
            pass

    # å¦‚æœç¼“å­˜ä¸å­˜åœ¨ä¸”æä¾›äº† bot_configï¼Œå…ˆåˆå§‹åŒ–ç¼“å­˜
    if not stages_dict and bot_config is not None:
        stages_dict = get_all_stages_and_substages(conversation_id, bot_config)

    # å¦‚æœä»ç„¶ä¸ºç©ºï¼Œè¯´æ˜æ— æ³•è·å–æ•°æ®ï¼Œè¿”å› False
    if not stages_dict:
        return False

    # æ£€æŸ¥ substage_name æ˜¯å¦å­˜åœ¨
    if substage_name not in stages_dict:
        # å¦‚æœä¸å­˜åœ¨ï¼Œå¯ä»¥é€‰æ‹©æ·»åŠ å®ƒï¼ˆä¸ºäº†å®¹é”™ï¼‰æˆ–è€…è¿”å› False
        # è¿™é‡Œé€‰æ‹©æ·»åŠ æ–°çš„ substage
        pass

    # æ›´æ–°å¯¹åº” substage çš„çŠ¶æ€
    stages_dict[substage_name] = is_complete

    # å†™å›ç¼“å­˜ï¼ˆä¿æŒ 90 å¤©æœ‰æ•ˆæœŸï¼‰
    try:
        redis_set(cache_key, json.dumps(stages_dict, ensure_ascii=False), expired=7_776_000)
        return True
    except Exception:
        return False

def _has_content(val) -> bool:
    if val is None:
        return False
    if isinstance(val, str):
        return val.strip() != ""
    if isinstance(val, (list, tuple, set)):
        return len(val) > 0
    if isinstance(val, dict):
        return len(val) > 0
    return True  # å…¶ä»–ç±»å‹æŒ‰æœ‰å€¼å¤„ç†

def add_conversation_id_uuid_and_cache(results: dict, conversation_id: str, session_id: str, user_id: str, turn_uuid: str) -> None:
    """ä¸º results æ·»åŠ  turn_uuid å¹¶å°† response ç¼“å­˜åˆ° Redisï¼ˆä½¿ç”¨ turn_uuid ä½œä¸ºé”®ï¼‰ã€‚

    å‚æ•°:
        results: åŒ…å« "response" å­—æ®µçš„å­—å…¸
        conversation_id: ä¼šè¯æ ‡è¯†
        session_id: ä¼šè¯æ ‡è¯†
        user_id: ç”¨æˆ·æ ‡è¯†
        turn_uuid: å›åˆ UUIDï¼ˆç”¨äºé…å¯¹ user å’Œ agent æ¶ˆæ¯ï¼‰

    æ³¨æ„:
        - å¦‚æœ results ä¸æ˜¯å­—å…¸æˆ–ä¸åŒ…å« "response" å­—æ®µï¼Œåˆ™ä¸æ‰§è¡Œä»»ä½•æ“ä½œ
        - ç¼“å­˜é”®æ ¼å¼ï¼šresponse:{turn_uuid}ï¼Œæœ‰æ•ˆæœŸ 24 å°æ—¶
        - ç¼“å­˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
    """
    if not isinstance(results, dict) or "response" not in results:
        return

    # åœ¨ results å¯¹è±¡ä¸­æ·»åŠ  turn_uuid å­—æ®µï¼ˆç”¨äºåç»­ store_response_by_uuid è°ƒç”¨ï¼‰
    results["turn_uuid"] = turn_uuid

    # å°† turn_uuid å’Œ response çš„æ˜ å°„å­˜å…¥ Redisï¼ˆä¸´æ—¶å­˜å‚¨ï¼Œç­‰å¾…å¤–éƒ¨è°ƒç”¨å­˜å‚¨ï¼‰
    # ç¼“å­˜é”®æ ¼å¼ï¼šresponse:{turn_uuid}ï¼Œæœ‰æ•ˆæœŸ 24 å°æ—¶
    cache_key = f"response:{turn_uuid}"
    response_data = {
        "response": results["response"],
        "conversation_id": conversation_id,
        "session_id": session_id,
        "user_id": user_id,
        "turn_uuid": turn_uuid
    }
    try:
        redis_set(cache_key, json.dumps(response_data, ensure_ascii=False), expired=86400)  # 24å°æ—¶
    except Exception:
        # ç¼“å­˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
        pass


def _extract_products_list(product_result: Any) -> List[Dict[str, Any]]:
    # è§£æè¾“å…¥æ•°æ®
    if isinstance(product_result, str):
        try:
            data = json.loads(product_result)
        except json.JSONDecodeError:
            return []
    else:
        data = product_result

    # æå– products åˆ—è¡¨ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
    products = []
    if isinstance(data, dict):
        # å¦‚æœåŒ…å« structuredContentï¼Œä»ä¸­æå–
        if "structuredContent" in data:
            structured = data.get("structuredContent", {})
            products = structured.get("products", [])
        # å¦‚æœç›´æ¥åŒ…å« products
        elif "products" in data:
            products = data.get("products", [])
        # å¦‚æœ structuredContent æ˜¯å¯¹è±¡å±æ€§
        elif hasattr(data, "structuredContent"):
            structured = getattr(data, "structuredContent", {})
            if isinstance(structured, dict):
                products = structured.get("products", [])
    elif isinstance(data, list):
        products = data
    else:
        # å°è¯•ä»å¯¹è±¡å±æ€§è·å–
        if hasattr(data, "products"):
            products = getattr(data, "products", [])
        elif hasattr(data, "structuredContent"):
            structured = getattr(data, "structuredContent", {})
            if isinstance(structured, dict):
                products = structured.get("products", [])
        else:
            return []
    return products


def format_product_list_for_llm(
    product_result: Any,
    exclude_equity_keys: Optional[List[str]] = None,
    *,
    include_product_id: bool = True,
    include_equity_key: bool = True,
    filter_product_ids: Optional[List[str]] = None,
    add_header: bool = True,
) -> str:
    """å°†å•†å“åˆ—è¡¨æ•°æ®æ ¼å¼åŒ–ä¸º LLM æ˜“è¯»çš„å­—ç¬¦ä¸²æ ¼å¼ã€‚

    å‚æ•°:
        product_result: å•†å“åˆ—è¡¨æ•°æ®
        exclude_equity_keys: éœ€è¦æ’é™¤çš„æƒç›Škeyåˆ—è¡¨
    """
    products = _extract_products_list(product_result)
    if not products:
        return "æš‚æ— å•†å“ä¿¡æ¯"

    # æ ¹æ®æƒç›Škeyè¿‡æ»¤å•†å“
    if exclude_equity_keys:
        filtered_products = []
        for item in products:
            product_equities = item.get("productEquities", [])
            # æ£€æŸ¥å•†å“æ˜¯å¦åŒ…å«éœ€è¦æ’é™¤çš„æƒç›Š
            has_excluded_equity = any(
                equity.get("productEquityKey") in exclude_equity_keys
                for equity in product_equities
            )
            if not has_excluded_equity:
                filtered_products.append(item)
        products = filtered_products

    # å¯é€‰ï¼šåªä¿ç•™æŒ‡å®šå•†å“ IDï¼ˆç”¨äºâ€œåªæ‹¼æ¨èå•†å“â€ç­‰åœºæ™¯ï¼‰
    if filter_product_ids:
        normalized_ids = {
            str(pid).strip() for pid in filter_product_ids if str(pid).strip()
        }
        if normalized_ids:
            filtered_products = []
            for item in products:
                product = item.get("product", {})
                pid = str(product.get("outerId", "")).strip()
                if pid in normalized_ids:
                    filtered_products.append(item)
            products = filtered_products

    if not products:
        return "æš‚æ— å•†å“ä¿¡æ¯"

    # å•†å“ç±»å‹æ˜ å°„
    type_map = {
        1: "å®ç‰©",
        2: "æœåŠ¡è®¢é˜…",
        3: "äººå·¥æœåŠ¡",
        4: "å•æ¬¡æœåŠ¡"
    }

    # æƒç›Šç±»å‹æ˜ å°„
    equity_type_map = {
        0: "ä¸é™æ¬¡",
        1: "æ¬¡æ•°"
    }

    formatted_lines: List[str] = []
    if add_header:
        formatted_lines.append("å•†å“åˆ—è¡¨ï¼š")
        formatted_lines.append("=" * 60)

    for idx, item in enumerate(products, 1):
        product = item.get("product", {})
        product_id = product.get("outerId", "")
        product_extra = item.get("productExtra", {})
        product_equities = item.get("productEquities", [])

        # åŸºæœ¬ä¿¡æ¯
        product_name = product.get("name", "")
        product_type_code = product.get("type", 0)
        product_type = type_map.get(product_type_code, f"æœªçŸ¥ç±»å‹({product_type_code})")
        description = product_extra.get("description", "")
        currency = product.get("currency", "")

        # ä»·æ ¼å¤„ç†
        price_range = product_extra.get("priceRangeString")
        if price_range and isinstance(price_range, list) and len(price_range) > 0:
            # æœ‰ä»·æ ¼èŒƒå›´
            if len(price_range) == 2:
                price_str = f"{price_range[0]} - {price_range[1]} {currency}"
            else:
                price_str = f"{price_range[0]} {currency}"
        else:
            # ä½¿ç”¨å•ä¸€ä»·æ ¼
            price = product.get("price", 0)
            price_str = f"{price / 100 if price else 0:.2f} {currency}" if currency else f"{price / 100 if price else 0:.2f}"

        # æœåŠ¡æ—¶é—´ï¼ˆä»…æœåŠ¡ç±»å‹æ˜¾ç¤ºï¼‰
        service_time = ""
        is_service = product_type_code in [2, 3, 4]  # æœåŠ¡è®¢é˜…ã€äººå·¥æœåŠ¡ã€å•æ¬¡æœåŠ¡
        if is_service:
            service_time_date = product_extra.get("serviceTimeDate")
            if service_time_date:
                if isinstance(service_time_date, list) and len(service_time_date) >= 2:
                    service_time = f"{service_time_date[0]} è‡³ {service_time_date[1]}"
                elif isinstance(service_time_date, list) and len(service_time_date) == 1:
                    service_time = str(service_time_date[0])
                else:
                    service_time = str(service_time_date)

        # æ ¼å¼åŒ–å•†å“ä¿¡æ¯
        formatted_lines.append(f"\nå•†å“ {idx}:")
        if include_product_id:
            formatted_lines.append(f"  å•†å“ID: {product_id}")
        formatted_lines.append(f"  å•†å“å: {product_name}")
        formatted_lines.append(f"  å•†å“ç±»å‹: {product_type}")
        if description:
            formatted_lines.append(f"  å•†å“ä»‹ç»: {description}")

        knowledge_summary = product_extra.get("knowledgeContent")
        if isinstance(knowledge_summary, str) and knowledge_summary.strip():
            formatted_lines.append("  å•†å“çŸ¥è¯†åº“è¦ç‚¹:")
            for line in knowledge_summary.strip().splitlines():
                formatted_lines.append(f"    {line.strip()}")
        formatted_lines.append(f"  ä»·æ ¼: {price_str}")

        # æœåŠ¡æ—¶é—´ï¼ˆä»…æœåŠ¡ç±»å‹ï¼‰
        if is_service and service_time:
            formatted_lines.append(f"  æœåŠ¡æ—¶é—´: {service_time}")

        # å•†å“æƒç›Šï¼ˆæ”¹ä¸ºç¼–å·åˆ—è¡¨ï¼š1. åç§° - æ¬¡æ•°ï¼Œå¯é€‰æ˜¯å¦æš´éœ²æƒç›ŠKeyï¼‰
        if product_equities:
            formatted_lines.append(f"  å•†å“æƒç›Š:")
            formatted_lines.append("")  # ç©ºè¡Œåˆ†éš”
            idx_counter = 1
            for equity in product_equities:
                equity_name = equity.get("name", "")
                equity_type_code = equity.get("type", 0)  # 0: ä¸é™æ¬¡, 1: æ¬¡æ•°
                equity_amount = equity.get("amount", 0)
                equity_key = equity.get("productEquityKey", "")
                if equity_name:
                    if include_equity_key and equity_key:
                        equity_prefix = f"{equity_name} (æƒç›ŠKey: {equity_key})"
                    else:
                        equity_prefix = equity_name

                    if equity_type_code == 0:
                        formatted_lines.append(f"    {idx_counter}. {equity_prefix} - ä¸é™æ¬¡")
                    else:
                        formatted_lines.append(f"    {idx_counter}. {equity_prefix} - {equity_amount}æ¬¡")
                    idx_counter += 1

        formatted_lines.append("-" * 60)

    return "\n".join(formatted_lines)


def build_promotion_product_snippet(product_result: Any, target_ids: List[str]) -> str:
    """
    æ ¹æ®å•†å“ ID åˆ—è¡¨æ„å»ºæ¨å¹¿å•†å“ä¿¡æ¯ç‰‡æ®µã€‚

    è¦æ±‚ï¼ˆç”¨äº response LLMï¼‰ï¼š
    - **æ ·å¼**ï¼šä¸ format_product_list_for_llm ä¸­çš„å•†å“å—ä¿æŒä¸€è‡´
    - **èŒƒå›´**ï¼šä»…åŒ…å«æ¨èçš„å•†å“ï¼ˆtarget_idsï¼‰
    - **éšç§**ï¼šä¸æš´éœ²å•†å“IDå’Œæƒç›ŠKey
    """
    if not target_ids:
        return ""

    return format_product_list_for_llm(
        product_result,
        exclude_equity_keys=None,
        include_product_id=False,
        include_equity_key=False,
        filter_product_ids=target_ids,
        add_header=False,
    )


# ===== Compliance helpers =====
def _get_compliance_modules(route_state_prompt_map: Any) -> list[Any]:
    if isinstance(route_state_prompt_map, dict):
        modules = route_state_prompt_map.get("compliance")
        if isinstance(modules, list):
            return modules
    return []


def find_compliance_module_index_by_product(route_state_prompt_map: Any, equity_key: Optional[str]) -> Optional[int]:
    """æ ¹æ® equity_keyï¼ˆå¦‚ product_equity_23_4ï¼‰åœ¨ compliance æ¨¡å—åˆ—è¡¨ä¸­æŸ¥æ‰¾å¯¹åº”çš„æ¨¡å—ç´¢å¼•ã€‚"""
    if not equity_key:
        return None
    modules = _get_compliance_modules(route_state_prompt_map)
    for idx, module in enumerate(modules):
        if isinstance(module, dict) and module.get("product") == equity_key:
            return idx
    return None


# æ³¨æ„ï¼šäº§å“ç¼“å­˜é€»è¾‘å·²è¿ç§»åˆ° bot_mcp.get_products_with_cache


def skip_completed_stage(routed_current_state: str, routed_current_sub_stage: str, stages_complete: Dict[str, bool], bot_config: Any, conversation_id: str, allowed_stages: list[str] = None) -> tuple[str, str]:
    """å¦‚æœè·¯ç”±åˆ°çš„é˜¶æ®µå·²å®Œæˆï¼Œåˆ™è·³åˆ°ä¸‹ä¸€ä¸ªæœªå®Œæˆçš„é˜¶æ®µã€‚

    å‚æ•°:
        routed_current_state: è·¯ç”±åˆ°çš„å½“å‰é˜¶æ®µï¼ˆå¦‚ "cognition"ï¼‰
        routed_current_sub_stage: è·¯ç”±åˆ°çš„å½“å‰å­é˜¶æ®µï¼ˆå¦‚ "cognition_01"ï¼‰
        stages_complete: æ‰€æœ‰é˜¶æ®µçš„å®ŒæˆçŠ¶æ€å­—å…¸
        allowed_stages: éœ€è¦ä½¿ç”¨è¯¥æœºåˆ¶çš„é˜¶æ®µåˆ—è¡¨ï¼ˆå¦‚ ["cognition", "interest"]ï¼‰
        bot_config: bot é…ç½®å¯¹è±¡
        conversation_id: ä¼šè¯æ ‡è¯†ï¼ˆç”¨äºåˆ·æ–° stages_completeï¼‰

    è¿”å›:
        tuple[str, str]: (æ›´æ–°åçš„ routed_current_state, routed_current_sub_stage)
    """
    # å¦‚æœ allowed_stages ä¸º Noneï¼Œä½¿ç”¨é»˜è®¤å€¼
    if allowed_stages is None:
        allowed_stages = ["cognition", "interest"]

    # å¦‚æœå½“å‰é˜¶æ®µä¸åœ¨å…è®¸åˆ—è¡¨ä¸­ï¼Œç›´æ¥è¿”å›åŸè·¯ç”±ç»“æœ
    if routed_current_state not in allowed_stages:
        return routed_current_state, routed_current_sub_stage

    # ç¡®ä¿ stages_complete æ˜¯æœ€æ–°çš„ï¼ˆå¦‚æœä¸ºç©ºåˆ™é‡æ–°è·å–ï¼‰
    if not stages_complete:
        stages_complete = get_all_stages_and_substages(conversation_id, bot_config)

    # æ„å»ºå®Œæ•´çš„ substage åç§°ï¼ˆå¦‚ "cognition_01"ï¼‰
    if routed_current_sub_stage and '_' in routed_current_sub_stage:
        # å¦‚æœå·²ç»æ˜¯å®Œæ•´æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
        if routed_current_sub_stage.count('_') >= 2:
            routed_substage_full = routed_current_sub_stage
        else:
            # æå–æ•°å­—éƒ¨åˆ†å¹¶ç»„åˆ
            num_part = routed_current_sub_stage.split('_')[-1]
            routed_substage_full = f"{routed_current_state}_{num_part}"
    else:
        # å¦‚æœæ²¡æœ‰ substageï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
        routed_substage_full = f"{routed_current_state}_01"

    # æ£€æŸ¥è·¯ç”±åˆ°çš„é˜¶æ®µæ˜¯å¦å·²å®Œæˆ
    if routed_substage_full in stages_complete and stages_complete.get(routed_substage_full, False):
        # å·²å®Œæˆï¼Œå¯»æ‰¾ä¸‹ä¸€ä¸ªæœªå®Œæˆçš„é˜¶æ®µ
        stages_list = list(stages_complete.keys())

        # æ‰¾åˆ°å½“å‰è·¯ç”±é˜¶æ®µçš„ç´¢å¼•
        if routed_substage_full in stages_list:
            current_idx = stages_list.index(routed_substage_full)
            # ä»å½“å‰ä½ç½®å¾€åæ‰¾ç¬¬ä¸€ä¸ªæœªå®Œæˆçš„é˜¶æ®µ
            found_next = False
            for idx in range(current_idx + 1, len(stages_list)):
                next_substage = stages_list[idx]
                # æ£€æŸ¥è¯¥é˜¶æ®µæ˜¯å¦ä¹Ÿéœ€è¦åœ¨ allowed_stages ä¸­
                next_stage_name = next_substage.rsplit('_', 1)[0] if '_' in next_substage else next_substage
                # å¦‚æœä¸‹ä¸€ä¸ªé˜¶æ®µä¸åœ¨å…è®¸åˆ—è¡¨ä¸­ï¼Œè·³è¿‡ï¼ˆä¸è·³è½¬åˆ°ä¸å…è®¸çš„é˜¶æ®µï¼‰
                if next_stage_name not in allowed_stages:
                    continue
                if not stages_complete.get(next_substage, False):
                    # æ‰¾åˆ°æœªå®Œæˆçš„é˜¶æ®µï¼Œæ›´æ–°è·¯ç”±ç»“æœ
                    routed_substage_full = next_substage
                    routed_current_state = next_stage_name
                    routed_current_sub_stage = next_substage
                    found_next = True
                    break

            # å¦‚æœæ²¡æ‰¾åˆ°åç»­æœªå®Œæˆçš„é˜¶æ®µï¼ˆå¯èƒ½æ‰€æœ‰åç»­é˜¶æ®µéƒ½å·²å®Œæˆæˆ–ä¸åœ¨å…è®¸åˆ—è¡¨ä¸­ï¼‰ï¼Œåˆ™ä¿æŒåŸè·¯ç”±ç»“æœ
            if not found_next:
                # ä¿æŒåŸè·¯ç”±ç»“æœ
                pass
        # å¦‚æœè·¯ç”±åˆ°çš„é˜¶æ®µä¸åœ¨åˆ—è¡¨ä¸­ï¼Œä¿æŒåŸè·¯ç”±ç»“æœ

    # æ›´æ–°è·¯ç”±ç»“æœï¼ˆç¡®ä¿æ ¼å¼ä¸€è‡´ï¼‰
    if routed_substage_full and '_' in routed_substage_full:
        routed_current_state = routed_substage_full.rsplit('_', 1)[0]
        routed_current_sub_stage = routed_substage_full

    return routed_current_state, routed_current_sub_stage


def validate_query_result(query: dict) -> bool:
    """
    è§„åˆ™ï¼š
    - è‹¥å­˜åœ¨ results.substage_resultsï¼ˆä¸”ä¸º dictï¼‰ï¼šæ£€æŸ¥è¯¥ dict çš„æ‰€æœ‰ valueï¼Œä»»ä¸€ä¸ºç©º â†’ Falseï¼›å¦åˆ™ True
    - å¦åˆ™ï¼šæ£€æŸ¥ resultsï¼ˆdictï¼‰çš„æ‰€æœ‰ valueï¼Œä»»ä¸€ä¸ºç©º â†’ Falseï¼›å¦åˆ™ True
    """
    results = query.get("results")
    if not isinstance(results, dict):
        return False

    substage_results = results.get("substage_results")
    if isinstance(substage_results, dict):
        for v in substage_results.values():
            if not _has_content(v):
                return False
        return True

    # æ—  substage_resultsï¼Œæ£€æŸ¥ results å†…æ‰€æœ‰å€¼
    for v in results.values():
        if not _has_content(v):
            return False
    return True

# @mcp.tool(description="Main response procedure: process user input, route, optionally skip decision_making based on equity, and return JSON.")
# def main_response_procedure(
#     session_id: str,
#     user_id: str,
#     bot_id: str,
#     app_id: str,
#     user_input: Optional[str] = None,
#     equity: Optional[Union[str, Dict[str, Any]]] = None
# ) -> str:
#     """
#     ä¸»æµç¨‹ï¼šç”¨æˆ·è¾“å…¥ -> åˆ†è§£ -> å“åº”
#     """
#     # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…ä»…ä¸ºäº†ä½¿ç”¨ join_prompts ç­‰å‡½æ•°è€Œè§¦å‘ LLM å®¢æˆ·ç«¯åˆå§‹åŒ–
#     # get_conversation_with_cache ä¼šåˆ›å»º conversationï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰ï¼Œæ‰€ä»¥ conversation_id æ€»æ˜¯å­˜åœ¨
#     conversation_json = db.get_conversation_with_cache(user_id, session_id)

#     # è§£æ conversation JSONï¼Œæå– conversation_id
#     conversation_id = ""
#     try:
#         conv_data = json.loads(conversation_json)
#         if isinstance(conv_data, dict) and "id" in conv_data:
#             conversation_id = str(conv_data["id"])
#     except (json.JSONDecodeError, TypeError, KeyError):
#         # è§£æå¤±è´¥ï¼Œç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼ˆget_conversation_with_cache æ€»æ˜¯ä¼šåˆ›å»º conversationï¼‰
#         # ä½†ä¸ºäº†ä»£ç å¥å£®æ€§ï¼Œä¿ç•™é”™è¯¯å¤„ç†
#         conversation_id = ""

#     # ä»æ•°æ®åº“è¯»å– next_stage å’Œ next_sub_stageï¼ˆé€šè¿‡ get_latest_session_state_payloadï¼‰
#     # æ³¨æ„ï¼šå³ä½¿æœ‰ conversation_idï¼Œsession_states è¡¨ä¸­ä¹Ÿå¯èƒ½æ²¡æœ‰è®°å½•ï¼ˆé¦–æ¬¡ä½¿ç”¨åœºæ™¯ï¼‰
#     # get_latest_session_state_payload åœ¨æ— è®°å½•æ—¶è¿”å› "{}"
#     session_state_json = db.get_latest_session_state_payload(conversation_id, session_id, user_id)

#     # å¤„ç† session_state_json ä¸ºç©ºæˆ–æ— æ•ˆçš„æƒ…å†µ
#     # å¯èƒ½çš„æƒ…å†µï¼š
#     # 1. conversation_id ä¸ºç©ºï¼Œsession_state_json ä¸º ""ï¼ˆç©ºå­—ç¬¦ä¸²ï¼‰
#     # 2. conversation_id æœ‰å€¼ä½† session_states è¡¨ä¸­æ²¡æœ‰è®°å½•ï¼Œè¿”å› "{}"ï¼ˆç©ºå­—å…¸ JSONï¼‰
#     # 3. session_states è¡¨æœ‰è®°å½•ï¼Œè¿”å›åŒ…å«æ•°æ®çš„ JSON
#     session_state = {}
#     if session_state_json:
#         try:
#             parsed = json.loads(session_state_json)
#             if isinstance(parsed, dict):
#                 session_state = parsed
#         except (json.JSONDecodeError, TypeError):
#             # JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨ç©ºå­—å…¸
#             session_state = {}

#     # ä» session_state è¯»å– next_stage å’Œ next_substageï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
#     # å¦‚æœ session_states è¡¨ä¸­æ²¡æœ‰è®°å½•ï¼ˆé¦–æ¬¡ä½¿ç”¨ï¼‰ï¼Œä½¿ç”¨é»˜è®¤åˆå§‹å€¼
#     next_stage = session_state.get("next_stage") or "cognition"
#     next_substage = session_state.get("next_sub_stage") or "cognition_01"

#     # ä½¿ç”¨è¯»å–çš„å€¼ä½œä¸º current_state å’Œ current_sub_stageï¼ˆç”¨äºè·¯ç”±ç­‰é€»è¾‘ï¼‰
#     current_state = next_stage
#     current_sub_stage = next_substage

#     #å®¢æˆ·é˜¶æ®µä¸€ï¼š è®¤çŸ¥ - æ–°conversation_id
#     #if current_state == "cognition": #ç”¨æˆ·ä¸è¾“å…¥ç›®çš„åªå›å¤ï¼Œåˆ™è¿›å…¥è·¯ç”±
#         #session_choise = router.route_and_store(conversation_id, session_id, user_id, user_input, table = "chat_messages", state_table = "session_states")
#     # è·å–å†å²å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼ˆè¿”å› JSON å­—ç¬¦ä¸²æ ¼å¼ï¼Œå¦‚ "[]" æˆ– "[{...}]"ï¼‰
#     history_context = db.list_chat_messages(conversation_id, session_id, user_id)
#     # è§£æ equity å‚æ•°ï¼ˆå½¢å¦‚ {"info": {"å•†å“A.æƒç›Š1": 1, "å•†å“A.æƒç›Š2": 0}}ï¼‰
#     equity_info = {}
#     if equity:
#         if isinstance(equity, str):
#             try:
#                 equity_obj = json.loads(equity)
#             except json.JSONDecodeError:
#                 equity_obj = {}
#         else:
#             equity_obj = equity
#         if isinstance(equity_obj, dict):
#             info_part = equity_obj.get("info")
#             if isinstance(info_part, dict):
#                 equity_info = info_part
#             else:
#                 # å…¼å®¹ç›´æ¥ä¼ å…¥ info å­—å…¸çš„æƒ…å†µï¼ˆæ— å¤–å±‚ {"info": ...}ï¼‰
#                 candidate_keys = [
#                     k for k in equity_obj.keys()
#                     if isinstance(k, str) and ("." in k or "product_equity" in k)
#                 ]
#                 numeric_values = {
#                     k: v for k, v in equity_obj.items()
#                     if isinstance(v, (int, float))
#                 }
#                 if candidate_keys and numeric_values:
#                     equity_info = numeric_values
#     products_cached = get_products_with_cache(conversation_id, outer_id=bot_id, app_id=app_id)  # å¼€å¤´è·å–å•†å“åˆ—è¡¨å¹¶ä½¿ç”¨ç¼“å­˜ï¼ˆ90å¤©ï¼‰
#     bot_config = get_bot_config(conversation_id, bot_id, app_id)
#     structuredContent = bot_config.structuredContent
#     # å…¼å®¹ç¼ºå¤±æˆ–ç±»å‹ä¸ç¬¦çš„æƒ…å†µï¼Œé¿å… KeyError/ç±»å‹é”™è¯¯
#     route_state_prompt_map = structuredContent.get('routeStateStrategies') if isinstance(structuredContent, dict) else None
#     if not isinstance(route_state_prompt_map, dict):
#         route_state_prompt_map = {}
#         if isinstance(structuredContent, dict):
#             structuredContent['routeStateStrategies'] = route_state_prompt_map

#     # # ç¡®ä¿ 'questions' é˜¶æ®µå­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æ·»åŠ é»˜è®¤é…ç½®
#     # if 'questions' not in route_state_prompt_map:
#     #     route_state_prompt_map['questions'] = [{
#     #         "purpose": "å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼Œæ ¹æ®æŸ¥è¯¢æ˜¯å¦ä¸ä¸šåŠ¡ç›¸å…³ï¼ˆå¦‚æœåŠ¡ã€äº§å“ç­‰ï¼‰ç”Ÿæˆå›ç­”æˆ–å§”å©‰æ‹’ç»å›å¤ï¼Œå¹¶ç¡®ä¿å›å¤è‡ªç„¶ä¸”ä¸è¶…è¿‡100å­—ã€‚",
#     #         "name": ["response"],
#     #         "expect": ["è‡ªç„¶å›å¤ç”¨æˆ·çš„å†…å®¹"],
#     #         "operation": [
#     #             "1. æ¥æ”¶å¹¶åˆ†æç”¨æˆ·æŸ¥è¯¢å†…å®¹",
#     #             "2. åˆ¤æ–­æŸ¥è¯¢æ˜¯å¦ä¸ä¸šåŠ¡ç›¸å…³",
#     #             "3. å¦‚æœç›¸å…³ï¼Œæ£€ç´¢ä¸šåŠ¡ä¿¡æ¯å¹¶ç”Ÿæˆå›ç­”",
#     #             "4. å¦‚æœä¸ç›¸å…³ï¼Œç”Ÿæˆå§”å©‰æ‹’ç»æ¶ˆæ¯",
#     #             "5. ä¼˜åŒ–å›å¤ç¡®ä¿è‡ªç„¶æµç•…ä¸”ä¸è¶…è¿‡100å­—"
#     #         ]
#     #     }]

#     character_prompt = structuredContent['character']
#     stages_complete = get_all_stages_and_substages(conversation_id, bot_config)
#     # botLLMConfig å…œåº•ï¼šå¦‚æœ key ä¸å­˜åœ¨æˆ–å€¼ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨é»˜è®¤çš„ qwen é…ç½®
#     botLLMConfig = structuredContent.get('botLLMConfig')
#     if not botLLMConfig or not isinstance(botLLMConfig, dict):
#         botLLMConfig = DEFAULT_BOT_LLM_CONFIG.copy()
#     # if purpose:
#     #     #å‚¨å­˜dummyç”¨æˆ·è¾“å…¥
#     #     dt = datetime.now(timezone.utc).astimezone().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
#     #     inserted = db.store_chat_message(session_id=session_id, user_id=user_id, conversation_id=conversation_id, content="ç”¨æˆ·ç›®çš„ï¼š" + purpose, role="user", dt=dt)
#     #     msg = json.loads(inserted)
#     #     message_id = msg["id"]
#     #     #stateå‚¨å­˜ç›®çš„
#     #     stage_payload = {"cognition_01": {"info": {"purpose": purpose}}}
#     #     db.store_session_state(message_id=message_id, conversation_id=conversation_id, session_id=session_id, user_id=user_id, current_state="cognition", stage_payload_json=json.dumps(stage_payload, ensure_ascii=False), dt=dt, table="session_states")
#     #     #çŸ¥è¯†åº“åŒ¹é…ç‰Œé˜µ/mcpè·å–ç‰Œé˜µ?

#     #     #è·å–Promptç»„è£…ï¼ˆä½¿ç”¨ join_promptsï¼‰
#     #     cog_module = route_state_prompt_map["cognition"][0]
#     #     cognition_prompt = join_prompts(cog_module)
#     #     full_prompt = "\n\n".join([character_prompt, cognition_prompt])

#     #     # è®°å½• stage_promptï¼ˆpurpose åˆ†æ”¯ï¼‰
#     #     logger.info(f"[Stage Prompt] conversation_id={conversation_id}, session_id={session_id}, user_id={user_id}")
#     #     logger.info(f"[Stage Prompt] purpose={purpose}, current_state=cognition, current_sub_stage=cognition_01")
#     #     logger.info(f"[Stage Prompt] stage_prompt length={len(cognition_prompt)} characters")
#     #     logger.info(f"[Stage Prompt] stage_prompt content:\n{cognition_prompt}")

#     #     #LLMå°è¯•è¿›ä¸€æ­¥è¿½é—®å®¢æˆ·å…·ä½“é—®é¢˜
#     #     results = llm_generic(full_prompt = full_prompt, user_input = "ç”¨æˆ·å åœç±»åˆ«ï¼š" + purpose, history_context = history_context, session_state = session_state, botLLMConfig=botLLMConfig)

#     #     # è§£æ resultsï¼ˆå¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²ï¼‰
#     #     if isinstance(results, str):
#     #         try:
#     #             results = json.loads(results)
#     #         except json.JSONDecodeError:
#     #             # å¦‚æœä¸æ˜¯ JSONï¼Œä¿æŒåŸæ ·
#     #             pass

#     #     # ä¸º results æ·»åŠ  turn_uuid å¹¶ç¼“å­˜ responseï¼ˆpurpose åˆ†æ”¯æš‚æ—¶ä¿ç•™åŸé€»è¾‘ï¼‰
#     #     # : purpose åˆ†æ”¯ä¹Ÿéœ€è¦æ”¹ä¸ºä½¿ç”¨ turn_uuid æœºåˆ¶
#     #     turn_uuid_purpose = str(uuid.uuid4())
#     #     add_conversation_id_uuid_and_cache(results, conversation_id, session_id, user_id, turn_uuid_purpose)

#     #     # æ£€æŸ¥ results çš„æ¯ä¸€é¡¹æ˜¯å¦éƒ½ä¸ä¸ºç©ºæˆ–ç©ºå­—ç¬¦ä¸²
#     #     if isinstance(results, dict):
#     #         all_filled = True
#     #         for key, value in results.items():
#     #             # è·³è¿‡ turn_uuid å­—æ®µ
#     #             if key == "turn_uuid":
#     #                 continue
#     #             # æ£€æŸ¥å€¼æ˜¯å¦ä¸ºç©ºæˆ–ç©ºå­—ç¬¦ä¸²
#     #             if value is None or (isinstance(value, str) and value.strip() == ""):
#     #                 all_filled = False
#     #                 break
#     #             # å¦‚æœæ˜¯å­—å…¸ï¼Œæ£€æŸ¥å­—å…¸å†…çš„å€¼
#     #             if isinstance(value, dict):
#     #                 for v in value.values():
#     #                     if v is None or (isinstance(v, str) and v.strip() == ""):
#     #                         all_filled = False
#     #                         break
#     #                 if not all_filled:
#     #                     break

#     #         # å¦‚æœæ‰€æœ‰å­—æ®µéƒ½éç©ºï¼Œè®¾ç½®å½“å‰é˜¶æ®µä¸ºå®Œæˆï¼Œå¹¶è®¾ç½®ä¸‹ä¸€é˜¶æ®µ
#     #         if all_filled:
#     #             # å½“å‰é˜¶æ®µçš„ substageï¼ˆpurpose åˆ†æ”¯å¯¹åº” cognition_01ï¼‰
#     #             current_substage = "cognition_01"

#     #             # è®¾ç½®å½“å‰é˜¶æ®µä¸ºå®Œæˆ
#     #             set_all_stages_and_substages(conversation_id, current_substage, True, bot_config)

#     #             # è·å–æ‰€æœ‰ stagesï¼Œæ‰¾åˆ°ä¸‹ä¸€ä¸ª
#     #             stages_complete = get_all_stages_and_substages(conversation_id, bot_config)
#     #             stages_list = list(stages_complete.keys())

#     #             # æ‰¾åˆ°å½“å‰ substage çš„ç´¢å¼•
#     #             if current_substage in stages_list:
#     #                 current_idx = stages_list.index(current_substage)
#     #                 # è·å–ä¸‹ä¸€ä¸ª substage
#     #                 if current_idx + 1 < len(stages_list):
#     #                     next_substage = stages_list[current_idx + 1]
#     #                     # æå– next_stageï¼ˆæ•°å­—ä¹‹å‰çš„è‹±æ–‡éƒ¨åˆ†ï¼‰
#     #                     next_stage = next_substage.rsplit('_', 1)[0] if '_' in next_substage else next_substage
#     #                 else:
#     #                     # å·²ç»æ˜¯æœ€åä¸€ä¸ªï¼Œä¿æŒå½“å‰
#     #                     next_stage = current_substage.rsplit('_', 1)[0] if '_' in current_substage else current_substage
#     #                     next_substage = current_substage
#     #             else:
#     #                 # å¦‚æœæ‰¾ä¸åˆ°å½“å‰ substageï¼Œé»˜è®¤è®¾ç½®
#     #                 next_stage = "cognition"
#     #                 next_substage = "cognition_01"
#     #         else:
#     #             # æœ‰å­—æ®µä¸ºç©ºï¼Œä¿æŒå½“å‰é˜¶æ®µ
#     #             next_stage = "cognition"
#     #             next_substage = "cognition_01"

#     #     # æ£€æŸ¥ stages_complete çš„æœ€åä¸€é¡¹æ˜¯å¦ä¸º Trueï¼ˆæ‰€æœ‰é˜¶æ®µéƒ½å®Œæˆï¼‰
#     #     stages_list = list(stages_complete.keys())
#     #     if stages_list and stages_complete.get(stages_list[-1], False):
#     #         # æ‰€æœ‰é˜¶æ®µéƒ½å®Œæˆï¼Œç»“æŸå½“å‰ä¼šè¯å¹¶åˆ›å»ºæ–°ä¼šè¯
#     #         db.end_conversation_and_create(user_id=user_id, session_id=session_id)
#     #         # è¿”å›åˆ°æœ€å¼€å§‹
#     #         next_stage = "cognition"
#     #         next_substage = "cognition_01"

#     #     # æ›´æ–°æ•°æ®åº“ä¸­çš„ next_stage å’Œ next_sub_stageï¼ˆåªæ›´æ–°è¿™ä¸¤ä¸ªå­—æ®µï¼Œå…¶ä»–å­—æ®µç»§æ‰¿æœ€æ–°ä¸€æ¡ï¼‰
#     #     latest_state = json.loads(db.get_latest_session_state_payload(conversation_id, session_id, user_id))
#     #     if latest_state and "id" in latest_state:
#     #         with db._connect() as conn:
#     #             with conn.cursor() as cur:
#     #                 cur.execute(
#     #                     'UPDATE "session_states" SET next_stage = %s, next_substage = %s WHERE id = %s',
#     #                     [next_stage, next_substage, latest_state["id"]]
#     #                 )
#     #             conn.commit()

#     #     # è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²ï¼ˆMCP tool éœ€è¦è¿”å›å­—ç¬¦ä¸²ï¼Œä¸å†åŒ…å« next_stage å’Œ next_substageï¼‰
#     #     result_dict = results if isinstance(results, dict) else {"response": results}
#     #     return json.dumps(result_dict, ensure_ascii=False)
#     if user_input: #ç”¨æˆ·ä¸è¾“å…¥ç›®çš„åªå›å¤ï¼Œåˆ™è¿›å…¥è·¯ç”±
#         # å…¥å£å¤„ï¼šç”Ÿæˆ UUID å¹¶å†™å…¥ pending_turns
#         dt_user = str(int(datetime.now(timezone.utc).timestamp()))
#         turn_uuid = str(uuid.uuid4())
#         user_message_uuid = str(uuid.uuid4())

#         # å†™å…¥ pending_turns åŸºæœ¬ä¿¡æ¯
#         db.store_pending_turn(
#             turn_uuid=turn_uuid,
#             user_message_uuid=user_message_uuid,
#             conversation_id=conversation_id,
#             session_id=session_id,
#             user_id=user_id,
#             dt_user=dt_user,
#             user_content=user_input,
#             bot_id=bot_id,
#             app_id=app_id
#         )

#         # åŒæ—¶ç¼“å­˜åˆ° Redisï¼ˆå†—ä½™ï¼‰
#         try:
#             pending_cache_key = f"pending:{turn_uuid}"
#             pending_cache_data = {
#                 "turn_uuid": turn_uuid,
#                 "user_message_uuid": user_message_uuid,
#                 "conversation_id": conversation_id,
#                 "session_id": session_id,
#                 "user_id": user_id,
#                 "dt_user": dt_user,
#                 "user_content": user_input,
#                 "bot_id": bot_id,
#                 "app_id": app_id
#             }
#             redis_set(pending_cache_key, json.dumps(pending_cache_data, ensure_ascii=False), expired=86400)  # 24å°æ—¶
#         except Exception:
#             pass

#         # è®°å½•è¾“å…¥ç»™ router çš„ current_state
#         logger.info(f"[Router Input] ========== è¾“å…¥ç»™ Router çš„çŠ¶æ€ ==========")
#         logger.info(f"[Router Input] conversation_id={conversation_id}, session_id={session_id}, user_id={user_id}")
#         logger.info(f"[Router Input] current_state={current_state}, current_sub_stage={current_sub_stage}")
#         logger.info(f"[Router Input] user_input: {user_input}")
#         logger.info(f"[Router Input] ==========================================")

#         router_response = router.route_and_store(conversation_id, session_id, user_id, user_input, bot_id, app_id, current_state)
#         parsed = router_response.get("llm_output")

#         # è®°å½• router å“åº”
#         logger.info(f"[Router Response] conversation_id={conversation_id}, session_id={session_id}, user_id={user_id}")
#         logger.info(f"[Router Response] router_response: {json.dumps(router_response, ensure_ascii=False, indent=2)}")

#         # è®¡ç®— current_state / current_sub_stage ä»¥åŠåŠ¨æ€ stage åˆ—ï¼ˆæ”¯æŒå¤šæ¨¡å—å†™å…¥ï¼‰
#         # route_and_store è¿”å›çš„ llm_output æ ¼å¼ä¸º {"queries": [{"stage": "...", "substage": "..."}]}
#         routed_current_state = ""
#         routed_current_sub_stage = ""

#         if isinstance(parsed, dict) and "queries" in parsed and isinstance(parsed["queries"], list) and parsed["queries"]:
#             # å–ç¬¬ä¸€ä¸ª query çš„ stage å’Œ substage
#             first_query = parsed["queries"][0]
#             if isinstance(first_query, dict):
#                 routed_current_state = first_query.get("stage", "")
#                 routed_current_sub_stage = first_query.get("substage", "")

#         # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
#         if not routed_current_state:
#             routed_current_state = current_state
#         if not routed_current_sub_stage:
#             routed_current_sub_stage = current_sub_stage

#         # å¦‚æœè·¯ç”±åˆ° complianceï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”å­é˜¶æ®µçš„æƒç›Šå‰©ä½™
#         def _handle_compliance_no_equity_flow(current_state_hint: str, substage_hint: str) -> str:
#             """å½“æ²¡æœ‰å‰©ä½™æƒç›Šæ—¶ï¼Œæ‰§è¡Œæ”¶å°¾æµç¨‹å¹¶è¿”å›ç»“æŸè¯æœ¯ã€‚"""
#             nonlocal stages_complete

#             if substage_hint and '_' in substage_hint:
#                 if substage_hint.count('_') >= 2:
#                     compliance_substage = substage_hint
#                 else:
#                     num_part = substage_hint.split('_')[-1]
#                     compliance_substage = f"{current_state_hint}_{num_part}"
#             else:
#                 compliance_substage = "compliance_01"

#             try:
#                 set_all_stages_and_substages(conversation_id, compliance_substage, True, bot_config)
#             except Exception:
#                 pass

#             try:
#                 stage_payload = {compliance_substage: {"info": {"status": "no_equity_remaining"}}}
#                 db.update_pending_turn_state(
#                     turn_uuid=turn_uuid,
#                     routed_current_state="compliance",
#                     routed_current_sub_stage=compliance_substage,
#                     stage_payload_draft=json.dumps(stage_payload, ensure_ascii=False)
#                 )
#                 db.update_pending_turn_state(
#                     turn_uuid=turn_uuid,
#                     next_stage="compliance",
#                     next_substage=compliance_substage
#                 )
#             except Exception:
#                 pass

#             try:
#                 db.end_conversation_and_create(user_id=user_id, session_id=session_id)
#             except Exception:
#                 pass

#             no_equity_prompt = "\n".join([
#                 "[ä»»åŠ¡]",
#                 "å½“å‰è®¢é˜…æƒç›Šå·²ç»ä½¿ç”¨å®Œæ¯•ã€‚è¯·ä»¥äº²åˆ‡ã€æ„Ÿè°¢çš„è¯­æ°”ï¼Œå‘ç”¨æˆ·è¯´æ˜æƒç›Šå·²ç»“æ¸…ï¼ŒçœŸè¯šè‡´è°¢è¿™æ®µé™ªä¼´ï¼Œå¹¶é‚€è¯·å¯¹æ–¹æ—¥åå¦‚æœ‰éœ€è¦éšæ—¶å†æ¥äº¤æµæˆ–ç»­è®¢æœåŠ¡ã€‚",
#                 "",
#                 "[è¡¥å……è¦æ±‚]",
#                 "1. ä¿æŒè§’è‰²è®¾å®šï¼Œè¯­æ°”æ¸©æš–ã€æŸ”å’Œã€‚",
#                 "2. ä¸æåŠç³»ç»Ÿæˆ–æŠ€æœ¯ç»†èŠ‚ï¼Œåªè°ˆæœåŠ¡ä½“éªŒã€‚",
#                 "3. é¼“åŠ±ç”¨æˆ·åœ¨éœ€è¦æ—¶ç»§ç»­æé—®æˆ–é€‰æ‹©æ–°çš„æœåŠ¡ã€‚"
#             ])
#             farewell_prompt = "\n\n".join([character_prompt, no_equity_prompt])
#             try:
#                 farewell_raw = llm_generic(
#                     full_prompt=farewell_prompt,
#                     user_input="",
#                     history_context=history_context,
#                     session_state=session_state,
#                     botLLMConfig=botLLMConfig
#                 )
#             except Exception:
#                 farewell_raw = ""

#             farewell_text = ""
#             if isinstance(farewell_raw, dict):
#                 farewell_text = str(farewell_raw.get("response") or "").strip()
#             elif isinstance(farewell_raw, str):
#                 try:
#                     parsed_farewell = json.loads(farewell_raw)
#                     if isinstance(parsed_farewell, dict):
#                         farewell_text = str(parsed_farewell.get("response") or "").strip()
#                     else:
#                         farewell_text = farewell_raw.strip()
#                 except (json.JSONDecodeError, TypeError):
#                     farewell_text = farewell_raw.strip()

#             if not farewell_text:
#                 farewell_text = "æœ¬æ¬¡è®¢é˜…æƒç›Šå·²å…¨éƒ¨ä½¿ç”¨å®Œæ¯•ï¼ŒèŠèŠå°±å…ˆåˆ°è¿™é‡Œã€‚è‹¥éœ€è¦ç»§ç»­æœåŠ¡ï¼Œæ¬¢è¿éšæ—¶å†æ¥ã€‚"

#             results = {
#                 "response": farewell_text,
#                 "info": {"status": "no_equity_remaining"}
#             }
#             add_conversation_id_uuid_and_cache(results, conversation_id, session_id, user_id, turn_uuid)
#             return json.dumps(results, ensure_ascii=False)

#         if routed_current_state == "compliance":
#             # è§£æå­é˜¶æ®µå·ï¼ˆå¦‚ "compliance_02" â†’ idx=1ï¼‰
#             target_idx = None
#             if routed_current_sub_stage and isinstance(routed_current_sub_stage, str) and "_" in routed_current_sub_stage:
#                 try:
#                     num_part = routed_current_sub_stage.split("_")[-1]
#                     target_idx = int(num_part) - 1  # compliance_01 â†’ 0, compliance_02 â†’ 1
#                 except (ValueError, IndexError):
#                     target_idx = None

#             compliance_modules = _get_compliance_modules(route_state_prompt_map)

#             # ä¼˜å…ˆï¼šæ ¹æ®å½“å‰ substage æ‰€å¯¹åº”æ¨¡å—çš„ product å­—æ®µæŸ¥æ‰¾ equity
#             equity_key = None
#             if (
#                 target_idx is not None
#                 and 0 <= target_idx < len(compliance_modules)
#                 and isinstance(equity_info, dict)
#             ):
#                 module = compliance_modules[target_idx]
#                 if isinstance(module, dict):
#                     module_product = module.get("product")
#                     amount = equity_info.get(module_product) if module_product else None
#                     if isinstance(amount, (int, float)) and amount > 0:
#                         equity_key = module_product

#             # å…œåº•ï¼šéå†æ‰€æœ‰ equity keyï¼Œæ‰¾åˆ°ä¸æ¨¡å— product å¯¹åº”ä¸”ä»æœ‰å‰©ä½™æ¬¡æ•°çš„ç¬¬ä¸€æ¡
#             if not equity_key and isinstance(equity_info, dict):
#                 for key, amount in equity_info.items():
#                     if not isinstance(amount, (int, float)) or amount <= 0:
#                         continue
#                     module_idx = find_compliance_module_index_by_product(route_state_prompt_map, key)
#                     if module_idx is not None:
#                         equity_key = key
#                         routed_current_sub_stage = f"compliance_{module_idx + 1:02d}"
#                         break

#             # å¦‚æœæ‰¾åˆ°æœ‰æ•ˆçš„ equity_keyï¼Œç›´æ¥è°ƒç”¨ service_compliance_response å¹¶è¿”å›
#             if equity_key:
#                 try:
#                     return service_compliance_response(
#                         session_id=session_id,
#                         user_id=user_id,
#                         bot_id=bot_id,
#                         app_id=app_id,
#                         turn_uuid=turn_uuid,
#                         equity_key=equity_key
#                     )
#                 except Exception as _e:
#                     return json.dumps({
#                         "error": f"failed to invoke service_compliance_response: {str(_e)}",
#                         "turn_uuid": turn_uuid
#                     }, ensure_ascii=False)
#             else:
#                 return _handle_compliance_no_equity_flow(routed_current_state, routed_current_sub_stage)

#         # åœ¨è¿›å…¥ decision_making ä¹‹å‰ï¼šè‹¥ equity.info ä»»ä¸€é¡¹é 0ï¼Œåˆ™è·³è¿‡ decision_makingï¼Œç›´æ¥è¿›å…¥ complianceï¼Œ
#         # åŒæ—¶å°† decision_making è§†ä¸ºå·²å®Œæˆï¼ˆæ ‡è®°é¦–ä¸ª decision_making å­é˜¶æ®µä¸ºå®Œæˆï¼‰
#         should_skip_to_compliance = False
#         equity_selections = []
#         if equity_info:
#             for v in equity_info.values():
#                 # åªè¦æœ‰ä»»æ„ä¸€ä¸ªå€¼ä¸ºéé›¶æ•°å­—ï¼Œåˆ™è§¦å‘è·³è¿‡
#                 if isinstance(v, (int, float)) and v != 0:
#                     should_skip_to_compliance = True
#                     break
#             # æ”¶é›†éé›¶æƒç›Šé¡¹ï¼Œä½œä¸ºä»…ç”¨äºé€ä¼ çš„ä¸´æ—¶æ•°æ®ï¼ˆä¸å…¥ session_state / ä¸è¿›å…¥ LLM ä¸Šä¸‹æ–‡ï¼‰
#             for k, v in equity_info.items():
#                 if isinstance(v, (int, float)) and v != 0:
#                     equity_selections.append({
#                         "key": k,
#                         "amount": v
#                     })
#         if should_skip_to_compliance:
#             # ä»…å½“æœ¬è½®è·¯ç”±åˆ°äº† decision_making æ—¶æ‰åˆ¤æ–­å¹¶è·³è¿‡
#             if routed_current_state == "decision_making":
#                 # æ ‡è®° decision_making é˜¶æ®µå®Œæˆï¼ˆæ‰€æœ‰ decision_making_* å­é˜¶æ®µï¼‰
#                 if stages_complete:
#                     for key in list(stages_complete.keys()):
#                         if isinstance(key, str) and key.startswith("decision_making_"):
#                             try:
#                                 set_all_stages_and_substages(conversation_id, key, True, bot_config)
#                             except Exception:
#                                 # å®¹é”™ï¼Œä¸é˜»æ–­ä¸»æµç¨‹
#                                 pass
#                 # è·³åˆ° compliance
#                 routed_current_state = "compliance"
#                 routed_current_sub_stage = "compliance_01"
#                 # å¼ºåˆ¶è·¯ç”±è‡³å±¥çº¦ï¼šç›´æ¥è°ƒç”¨ service_compliance_response å¹¶è¿”å›ï¼Œä¸å†åœ¨æœ¬æµç¨‹å†…è°ƒç”¨ LLM
#                 try:
#                     # é€‰æ‹©ä¸€ä¸ªç”¨äºåŒ¹é…ç­–ç•¥çš„ equity_keyï¼ˆéé›¶çš„ç¬¬ä¸€æ¡ï¼‰
#                     equity_key = None
#                     if equity_selections:
#                         for _it in equity_selections:
#                             if isinstance(_it, dict) and isinstance(_it.get("amount"), (int, float)) and _it.get("amount") != 0:
#                                 equity_key = _it.get("key")
#                                 if isinstance(equity_key, str) and equity_key:
#                                     break
#                     return service_compliance_response(
#                         session_id=session_id,
#                         user_id=user_id,
#                         bot_id=bot_id,
#                         app_id=app_id,
#                         turn_uuid=turn_uuid,
#                         equity_key=equity_key
#                     )
#                 except Exception as _e:
#                     return json.dumps({
#                         "error": f"failed to invoke service_compliance_response: {str(_e)}",
#                         "turn_uuid": turn_uuid
#                     }, ensure_ascii=False)

#         # æ£€æŸ¥è·¯ç”±åˆ°çš„é˜¶æ®µæ˜¯å¦å·²å®Œæˆï¼Œå¦‚æœå·²å®Œæˆåˆ™è·³åˆ°ä¸‹ä¸€ä¸ªæœªå®Œæˆçš„é˜¶æ®µ
#         # åªæœ‰ cognition å’Œ interest é˜¶æ®µä½¿ç”¨æ­¤æœºåˆ¶ï¼ˆé»˜è®¤ï¼‰
#         # routed_current_state, routed_current_sub_stage = skip_completed_stage(
#         #     routed_current_state=routed_current_state,
#         #     routed_current_sub_stage=routed_current_sub_stage,
#         #     stages_complete=stages_complete,
#         #     bot_config=bot_config,
#         #     conversation_id=conversation_id
#         # )

#         # è‹¥è·¯ç”±ç»“æœä¸º complianceï¼Œåˆ™ç›´æ¥æ‰“æ–­å½“å‰æµç¨‹ï¼Œè°ƒç”¨å±¥çº¦æœåŠ¡å¹¶è¿”å›
#         if routed_current_state == "compliance" and not routed_current_sub_stage:
#             # åŸºäºä¼ å…¥çš„ equity ä¿¡æ¯é€‰æ‹©ä¸€ä¸ªç”¨äºç­–ç•¥åŒ¹é…çš„ keyï¼ˆéé›¶çš„ç¬¬ä¸€æ¡ï¼‰ï¼›æ— åˆ™ä¼  None
#             equity_key = None
#             equity_has_remaining = False
#             if equity_info:
#                 for _k, _v in equity_info.items():
#                     if isinstance(_v, (int, float)) and _v != 0:
#                         equity_key = _k
#                         equity_has_remaining = True
#                         break
#             if not equity_has_remaining:
#                 return _handle_compliance_no_equity_flow(routed_current_state, routed_current_sub_stage)
#             try:
#                 return service_compliance_response(
#                     session_id=session_id,
#                     user_id=user_id,
#                     bot_id=bot_id,
#                     app_id=app_id,
#                     turn_uuid=turn_uuid,
#                     equity_key=equity_key
#                 )
#             except Exception as _e:
#                 return json.dumps({
#                     "error": f"failed to invoke service_compliance_response: {str(_e)}",
#                     "turn_uuid": turn_uuid
#                 }, ensure_ascii=False)

#         #è·å–Promptç»„è£…ï¼ˆä½¿ç”¨ join_promptsï¼‰
#         # ä» substage ä¸­æå–ç¼–å·ï¼ˆä¾‹å¦‚ "cognition_01" -> 01 -> ç´¢å¼• 0ï¼‰
#         if routed_current_sub_stage and '_' in routed_current_sub_stage:
#             # æå–æ•°å­—éƒ¨åˆ†ï¼ˆä¾‹å¦‚ä» "cognition_01" æå– "01"ï¼‰
#             num_part = routed_current_sub_stage.split('_')[-1]
#             # è½¬æ¢ä¸ºç´¢å¼•ï¼ˆä» 1 å¼€å§‹ï¼Œæ‰€ä»¥è¦å‡ 1ï¼‰
#             module_idx = int(num_part) - 1
#         else:
#             # å¦‚æœæ²¡æœ‰ substage æˆ–æ ¼å¼ä¸å¯¹ï¼Œé»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å—
#             module_idx = 0

#         # è·å–å¯¹åº” stage çš„æ¨¡å—åˆ—è¡¨ï¼Œç„¶åè·å–å¯¹åº”ç´¢å¼•çš„æ¨¡å—
#         modules = route_state_prompt_map.get(routed_current_state, [])
#         if modules and module_idx < len(modules):
#             cog_module = modules[module_idx]
#         else:
#             # å¦‚æœç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å—
#             if modules:
#                 cog_module = modules[0]
#             else:
#                 # å¦‚æœè·å–ç»“æœä¸ºç©ºï¼Œå…œåº•ä½¿ç”¨ questions_01
#                 questions_modules = route_state_prompt_map.get('questions', [])
#                 if questions_modules:
#                     cog_module = questions_modules[0]
#                     logger.warning(f"[å…œåº•] æœªæ‰¾åˆ°é˜¶æ®µ '{routed_current_state}' çš„æ¨¡å—ï¼Œä½¿ç”¨ questions_01 ä½œä¸ºå…œåº•")
#                 else:
#                     cog_module = {}
#                     logger.error(f"[é”™è¯¯] æœªæ‰¾åˆ°é˜¶æ®µ '{routed_current_state}' çš„æ¨¡å—ï¼Œä¸” questions æ¨¡å—ä¹Ÿä¸å­˜åœ¨")

#         stage_prompt = join_prompts(cog_module)
#         # è¿½åŠ ä¸Šä¸€æ­¥/ä¸‹ä¸€æ­¥ä»»åŠ¡ purposeï¼ˆè‹¥å¯æ¨æ–­ï¼‰
#         prev_step_text = ""
#         next_step_text = ""
#         try:
#             # è®¡ç®—å½“å‰å®Œæ•´ substage åç§°ï¼ˆå¦‚ cognition_01ï¼‰
#             if routed_current_sub_stage and '_' in routed_current_sub_stage:
#                 if routed_current_sub_stage.count('_') >= 2:
#                     current_substage_full = routed_current_sub_stage
#                 else:
#                     num_part = routed_current_sub_stage.split('_')[-1]
#                     current_substage_full = f"{routed_current_state}_{num_part}"
#             else:
#                 current_substage_full = f"{routed_current_state}_01"
#             stages_list = list(stages_complete.keys()) if isinstance(stages_complete, dict) else []
#             # ä¸Šä¸€æ­¥ä»»åŠ¡ï¼šå–å…¨å±€é¡ºåºä¸­å½“å‰å­é˜¶æ®µä¹‹å‰çš„ç¬¬ä¸€ä¸ªåˆæ³•å­é˜¶æ®µ
#             try:
#                 prev_module = None
#                 if current_substage_full in stages_list:
#                     cur_idx = stages_list.index(current_substage_full)
#                     for j in range(cur_idx - 1, -1, -1):
#                         substage_name = stages_list[j]
#                         stage_name = substage_name.rsplit('_', 1)[0] if '_' in substage_name else substage_name
#                         if stage_name in ("questions", "after_sales"):
#                             continue
#                         stage_modules = route_state_prompt_map.get(stage_name, [])
#                         if stage_modules:
#                             prev_module = stage_modules[0]
#                             break
#                 if isinstance(prev_module, dict):
#                     prev_purpose = str(prev_module.get("purpose", "")).strip()
#                     if prev_purpose:
#                         prev_step_text = "\n\n".join(["[ä¸Šä¸€æ­¥ä»»åŠ¡]", prev_purpose])
#             except Exception:
#                 prev_step_text = ""

#             # ä»å…¨å±€ stages_complete é¡ºåºä¸­é€‰å–"å½“å‰å­é˜¶æ®µä¹‹å"çš„ä¸‹ä¸€ä¸ªå­é˜¶æ®µ
#             # åœ¨ stages_complete é¡ºåºä¸­æ‰¾åˆ°ä¸‹ä¸€ä¸ªæœªå¿…å®Œæˆçš„å­é˜¶æ®µï¼ŒæŒ‘ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å—
#             next_module = None
#             if current_substage_full in stages_list:
#                 cur_idx = stages_list.index(current_substage_full)
#                 for j in range(cur_idx + 1, len(stages_list)):
#                     substage_name = stages_list[j]
#                     # è¿‡æ»¤ä¸å¯é€‰é˜¶æ®µ
#                     stage_name = substage_name.rsplit('_', 1)[0] if '_' in substage_name else substage_name
#                     if stage_name in ("questions", "after_sales"):
#                         continue
#                     stage_modules = route_state_prompt_map.get(stage_name, [])
#                     if stage_modules:
#                         next_module = stage_modules[0]
#                         break
#             # å– purpose å¹¶æ‹¼æ¥
#             if isinstance(next_module, dict):
#                 next_purpose = str(next_module.get("purpose", "")).strip()
#                 if next_purpose:
#                     next_step_text = "\n\n".join(["[ä¸‹ä¸€æ­¥ä»»åŠ¡]", next_purpose])
#         except Exception:
#             # ä¸å½±å“ä¸»æµç¨‹
#             prev_step_text = ""
#             next_step_text = ""
#         # æ³¨æ„é¡ºåºï¼šå½“å‰é˜¶æ®µ -> ä¸Šä¸€æ­¥ä»»åŠ¡ -> ä¸‹ä¸€æ­¥ä»»åŠ¡
#         full_prompt = "\n\n".join([p for p in [character_prompt, stage_prompt, prev_step_text, next_step_text] if p])

#         # è®°å½• stage_prompt
#         logger.info(f"[Stage Prompt] conversation_id={conversation_id}, session_id={session_id}, user_id={user_id}")
#         logger.info(f"[Stage Prompt] routed_current_state={routed_current_state}, routed_current_sub_stage={routed_current_sub_stage}")
#         logger.info(f"[Stage Prompt] stage_prompt length={len(stage_prompt)} characters")
#         logger.info(f"[Stage Prompt] stage_prompt content:\n{stage_prompt}")
#         if prev_step_text and prev_step_text.strip() != "[ä¸Šä¸€æ­¥ä»»åŠ¡]":
#             logger.info(f"[Prev Step] length={len(prev_step_text)} characters")
#             logger.info(f"[Prev Step] content:\n{prev_step_text}")
#         # ä»…åœ¨åŒ…å«æœ‰æ•ˆ purpose æ—¶æ‰“å°"ä¸‹ä¸€æ­¥ä»»åŠ¡"ï¼Œé¿å…åªæ‰“å°æ ‡é¢˜
#         if next_step_text and next_step_text.strip() != "[ä¸‹ä¸€æ­¥ä»»åŠ¡]":
#             logger.info(f"[Next Step] length={len(next_step_text)} characters")
#             logger.info(f"[Next Step] content:\n{next_step_text}")
#         # åŸæ ·è¾“å‡ºï¼šfull_prompt å»æ‰ character_prompt çš„éƒ¨åˆ†ï¼ˆä»…åŒ…å« stage_prompt ä¸ä¸‹ä¸€æ­¥ä»»åŠ¡ï¼‰
#         full_prompt_wo_character = "\n\n".join([p for p in [stage_prompt, prev_step_text, next_step_text] if p])
#         logger.info(f"[Full Prompt Without Character]\n{full_prompt_wo_character}")

#         # æ£€æŸ¥ stage_prompt æ˜¯å¦æåˆ°å•†å“åˆ—è¡¨ï¼Œæˆ–æ˜¯ decision_making é˜¶æ®µï¼Œè‹¥æ˜¯åˆ™æ‹¼æ¥å¼€å¤´è·å–çš„å•†å“åˆ—è¡¨
#         user_input_for_llm = user_input
#         if "å•†å“åˆ—è¡¨" in stage_prompt or routed_current_state == "decision_making":
#             if products_cached:
#                 product_lists_str = format_product_list_for_llm(products_cached)
#                 user_input_for_llm = (
#                     f"ç”¨æˆ·æœ¬è½®è¾“å…¥ï¼š{user_input}\n\n"
#                     f"ã€å•†å“åˆ—è¡¨ä¾›å‚è€ƒã€‘\n{product_lists_str}"
#                 )

#         # è°ƒç”¨ LLM ç”Ÿæˆå“åº”
#         results = llm_generic(full_prompt=full_prompt, user_input=user_input_for_llm, history_context=history_context, session_state=session_state, botLLMConfig=botLLMConfig)

#         # è§£æ resultsï¼ˆå¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²ï¼‰
#         if isinstance(results, str):
#             try:
#                 results = json.loads(results)
#             except json.JSONDecodeError:
#                 # å¦‚æœä¸æ˜¯ JSONï¼Œä¿æŒåŸæ ·
#                 pass

#         # åå¤„ç†ï¼šä» info ä¸­æå–å¯¹è¯å†…å®¹å¹¶åˆå¹¶åˆ° response
#         if isinstance(results, dict):
#             results = extract_conversational_content_from_info(results)
#         elif isinstance(results, str):
#             # å¦‚æœ results æ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
#             results = {"response": results}

#         # ä¸º results æ·»åŠ  turn_uuid å¹¶ç¼“å­˜ response
#         # ç¡®ä¿ results æ˜¯å­—å…¸ä¸”åŒ…å« response å­—æ®µ
#         if isinstance(results, dict):
#             if "response" not in results:
#                 # å¦‚æœæ²¡æœ‰ response å­—æ®µï¼Œå°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æˆ–è®¾ç½®é»˜è®¤å€¼
#                 results["response"] = str(results) if results else ""
#             add_conversation_id_uuid_and_cache(results, conversation_id, session_id, user_id, turn_uuid)

#         # è®°å½•åŒ…å« turn_uuid çš„æœ€ç»ˆ results
#         logger.info(f"[LLM Results] ========== LLM è¿”å›çš„å®Œæ•´ç»“æœï¼ˆå« turn_uuidï¼‰==========")
#         logger.info(f"[LLM Results] conversation_id={conversation_id}, session_id={session_id}, user_id={user_id}")
#         logger.info(f"[LLM Results] routed_current_state={routed_current_state}, routed_current_sub_stage={routed_current_sub_stage}")
#         logger.info(f"[LLM Results] turn_uuid={results.get('turn_uuid') if isinstance(results, dict) else 'N/A'}")
#         logger.info(f"[LLM Results] results: {json.dumps(results, ensure_ascii=False, indent=2)}")
#         logger.info(f"[LLM Results] ==========================================")

#         # å¦‚æœ results åŒ…å« info å­—æ®µï¼Œæ›´æ–° pending_turns çš„çŠ¶æ€ä¿¡æ¯
#         if isinstance(results, dict) and "info" in results:
#             # æ„å»º substage åç§°ï¼ˆå¦‚ "cognition_01"ï¼‰
#             if routed_current_sub_stage and '_' in routed_current_sub_stage:
#                 # å¦‚æœå·²ç»æ˜¯å®Œæ•´æ ¼å¼ï¼ˆå¦‚ "cognition_01"ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
#                 if routed_current_sub_stage.count('_') >= 2:
#                     substage_col = routed_current_sub_stage
#                 else:
#                     # æå–æ•°å­—éƒ¨åˆ†å¹¶ç»„åˆ
#                     num_part = routed_current_sub_stage.split('_')[-1]
#                     substage_col = f"{routed_current_state}_{num_part}"
#             else:
#                 # å¦‚æœæ²¡æœ‰ substageï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
#                 substage_col = f"{routed_current_state}_01"

#             # æ„å»º stage_payload æ ¼å¼ï¼š{"cognition_01": {"info": {...}}}
#             stage_payload = {substage_col: {"info": results["info"]}}

#             # æ ‡æ³¨ä½ç½®ï¼šæ›´æ–° pending_turns çš„çŠ¶æ€ä¿¡æ¯ï¼ˆä¸å†ç›´æ¥å†™å…¥ session_statesï¼‰
#             db.update_pending_turn_state(
#                 turn_uuid=turn_uuid,
#                 routed_current_state=routed_current_state,
#                 routed_current_sub_stage=routed_current_sub_stage if routed_current_sub_stage else f"{routed_current_state}_01",
#                 stage_payload_draft=json.dumps(stage_payload, ensure_ascii=False)
#             )

#         # åˆå§‹åŒ– next_stage å’Œ next_substageï¼ˆé»˜è®¤ä¿æŒå½“å‰é˜¶æ®µï¼‰
#         next_stage = routed_current_state
#         next_substage = routed_current_sub_stage if routed_current_sub_stage else f"{routed_current_state}_01"

#         # æ£€æŸ¥ results çš„æ¯ä¸€é¡¹æ˜¯å¦éƒ½ä¸ä¸ºç©ºæˆ–ç©ºå­—ç¬¦ä¸²
#         if isinstance(results, dict):
#             all_filled = True
#             for key, value in results.items():
#                 # è·³è¿‡ turn_uuid å­—æ®µ
#                 if key == "turn_uuid":
#                     continue
#                 # æ£€æŸ¥å€¼æ˜¯å¦ä¸ºç©ºæˆ–ç©ºå­—ç¬¦ä¸²
#                 if value is None or (isinstance(value, str) and value.strip() == ""):
#                     all_filled = False
#                     break
#                 # å¦‚æœæ˜¯å­—å…¸ï¼Œæ£€æŸ¥å­—å…¸å†…çš„å€¼
#                 if isinstance(value, dict):
#                     for v in value.values():
#                         if v is None or (isinstance(v, str) and v.strip() == ""):
#                             all_filled = False
#                             break
#                     if not all_filled:
#                         break

#             # å¦‚æœæ‰€æœ‰å­—æ®µéƒ½éç©ºï¼Œè®¾ç½®å½“å‰é˜¶æ®µä¸ºå®Œæˆï¼Œå¹¶è®¾ç½®ä¸‹ä¸€é˜¶æ®µ
#             if all_filled and routed_current_sub_stage:
#                 # æ„å»ºå½“å‰é˜¶æ®µçš„ substage åç§°
#                 # å¦‚æœ routed_current_sub_stage å·²ç»æ˜¯å®Œæ•´æ ¼å¼ï¼ˆå¦‚ "interest_02"ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
#                 # å¦åˆ™ç»„åˆæˆå®Œæ•´æ ¼å¼
#                 if '_' in routed_current_sub_stage and routed_current_sub_stage.count('_') >= 2:
#                     # å·²ç»æ˜¯å®Œæ•´æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
#                     current_substage = routed_current_sub_stage
#                 else:
#                     # ä» routed_current_state å’Œ routed_current_sub_stage æ„å»º
#                     # æå–æ•°å­—éƒ¨åˆ†ï¼ˆå¦‚æœæœ‰ï¼‰
#                     if '_' in routed_current_sub_stage:
#                         num_part = routed_current_sub_stage.split('_')[-1]
#                         current_substage = f"{routed_current_state}_{num_part}"
#                     else:
#                         # å¦‚æœæ²¡æœ‰æ•°å­—éƒ¨åˆ†ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
#                         current_substage = f"{routed_current_state}_01"

#                 # è®¾ç½®å½“å‰é˜¶æ®µä¸ºå®Œæˆ
#                 set_all_stages_and_substages(conversation_id, current_substage, True, bot_config)

#                 # è·å–æ‰€æœ‰ stagesï¼Œæ‰¾åˆ°ä¸‹ä¸€ä¸ª
#                 stages_complete = get_all_stages_and_substages(conversation_id, bot_config)
#                 stages_list = list(stages_complete.keys())

#                 # æ‰¾åˆ°å½“å‰ substage çš„ç´¢å¼•
#                 if current_substage in stages_list:
#                     current_idx = stages_list.index(current_substage)
#                     # è·å–ä¸‹ä¸€ä¸ª substage
#                     if current_idx + 1 < len(stages_list):
#                         next_substage = stages_list[current_idx + 1]
#                         # æå– next_stageï¼ˆæ•°å­—ä¹‹å‰çš„è‹±æ–‡éƒ¨åˆ†ï¼‰
#                         next_stage = next_substage.rsplit('_', 1)[0] if '_' in next_substage else next_substage
#                     else:
#                         # å·²ç»æ˜¯æœ€åä¸€ä¸ªï¼Œä¿æŒå½“å‰
#                         next_stage = current_substage.rsplit('_', 1)[0] if '_' in current_substage else current_substage
#                         next_substage = current_substage

#         # æ£€æŸ¥ stages_complete çš„æœ€åä¸€é¡¹æ˜¯å¦ä¸º Trueï¼ˆæ‰€æœ‰é˜¶æ®µéƒ½å®Œæˆï¼‰
#         stages_list = list(stages_complete.keys())
#         if stages_list and stages_complete.get(stages_list[-2], False): #-2ä¸ºcompliance
#             # æ‰€æœ‰é˜¶æ®µéƒ½å®Œæˆï¼Œç»“æŸå½“å‰ä¼šè¯å¹¶åˆ›å»ºæ–°ä¼šè¯
#             db.end_conversation_and_create(user_id=user_id, session_id=session_id)
#             # è¿”å›åˆ°æœ€å¼€å§‹
#             next_stage = "cognition"
#             next_substage = "cognition_01"

#         # æ›´æ–° pending_turns çš„ next_stage å’Œ next_substage
#         db.update_pending_turn_state(
#             turn_uuid=turn_uuid,
#             next_stage=next_stage,
#             next_substage=next_substage
#         )

#         # è®°å½•æœ€åè®¾å®šçš„ next_stage å’Œ next_substage
#         logger.info(f"[Final Next Stage] ========== æœ€ç»ˆè®¾å®šçš„ä¸‹ä¸€é˜¶æ®µ ==========")
#         logger.info(f"[Final Next Stage] conversation_id={conversation_id}, session_id={session_id}, user_id={user_id}")
#         logger.info(f"[Final Next Stage] next_stage={next_stage}, next_substage={next_substage}")
#         logger.info(f"[Final Next Stage] ==========================================")

#         # ä¸å†æ›´æ–° session_states çš„ next_stage/next_substageï¼Œç­‰ store_response_by_uuid æ—¶ç»Ÿä¸€å¤„ç†
#         # latest_state = json.loads(db.get_latest_session_state_payload(conversation_id, session_id, user_id))
#         # if latest_state and "id" in latest_state:
#         #     with db._connect() as conn:
#         #         with conn.cursor() as cur:
#         #             cur.execute(
#         #                 'UPDATE "session_states" SET next_stage = %s, next_substage = %s WHERE id = %s',
#         #                 [next_stage, next_substage, latest_state["id"]]
#         #             )
#         #         conn.commit()

#         # è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²ï¼ˆMCP tool éœ€è¦è¿”å›å­—ç¬¦ä¸²ï¼Œä¸å†åŒ…å« next_stage å’Œ next_substageï¼‰
#         if isinstance(results, dict):
#             result_dict = results
#         else:
#             # å¦‚æœ results ä¸æ˜¯å­—å…¸ï¼Œåˆ›å»ºæ–°å­—å…¸å¹¶ç¡®ä¿åŒ…å« turn_uuid
#             result_dict = {"response": results}
#             if "turn_uuid" not in result_dict:
#                 result_dict["turn_uuid"] = turn_uuid
#         # ç¡®ä¿ result_dict åŒ…å« turn_uuidï¼ˆé˜²æ­¢é—æ¼ï¼‰
#         if "turn_uuid" not in result_dict:
#             result_dict["turn_uuid"] = turn_uuid
#         return json.dumps(result_dict, ensure_ascii=False)
#     else:
#         # æ—¢æ²¡æœ‰ purpose ä¹Ÿæ²¡æœ‰ user_inputï¼Œè¿”å›é”™è¯¯
#         return json.dumps({
#             "error": "Either 'purpose' or 'user_input' must be provided"
#         }, ensure_ascii=False)


@mcp.tool(description="Store response to chat_messages by turn_uuid. Retrieves response from Redis cache and stores both user and agent messages, plus session_state.")
def store_response_by_uuid(turn_uuid: str, table: str = "chat_messages") -> str:
    """æ ¹æ® turn_uuid ç»Ÿä¸€å…¥åº“ï¼šå°† user æ¶ˆæ¯ã€agent æ¶ˆæ¯å’Œ session_state ä¸€å¹¶å­˜å‚¨ã€‚

    å‚æ•°:
        turn_uuid: å›åˆ UUIDï¼ˆä» main_response_procedure è¿”å›ç»“æœä¸­è·å–ï¼‰
        table: è¡¨åï¼Œé»˜è®¤ "chat_messages"

    è¿”å›:
        JSON å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ {"success": true, "user_message_id": 1001, "agent_message_id": 1002, "session_state_id": 1003}
        å¦‚æœ turn_uuid å¯¹åº”çš„æ•°æ®ä¸å­˜åœ¨ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯

    æµç¨‹:
        1. ä» pending_turns è¯»å–ç”¨æˆ·æ¶ˆæ¯æ•°æ®
        2. ä» Redis è¯»å– response:{turn_uuid} å¯¹åº”çš„æ•°æ®
        3. ç”Ÿæˆ agent_message_uuid
        4. ç»Ÿä¸€å…¥åº“ï¼šchat_messagesï¼ˆuser + agentï¼‰ã€session_states
        5. æ ‡è®° pending_turn ä¸º done
    """
    # ä» pending_turns è¯»å–ç”¨æˆ·æ¶ˆæ¯æ•°æ®
    pending_data_json = db.get_pending_turn(turn_uuid)
    if not pending_data_json or pending_data_json == "{}":
        return json.dumps({
            "error": "Pending turn not found for the given turn_uuid",
            "turn_uuid": turn_uuid
        }, ensure_ascii=False)

    try:
        pending_data = json.loads(pending_data_json)
    except json.JSONDecodeError:
        return json.dumps({
            "error": "Invalid pending turn data format",
            "turn_uuid": turn_uuid
        }, ensure_ascii=False)

    # ä» Redis ç¼“å­˜ä¸­æŸ¥æ‰¾å¯¹åº”çš„ response
    cache_key = f"response:{turn_uuid}"
    cached_data = redis_get(cache_key)

    if not cached_data:
        return json.dumps({
            "error": "Response not found for the given turn_uuid",
            "turn_uuid": turn_uuid
        }, ensure_ascii=False)

    try:
        response_data = json.loads(cached_data)
        if not isinstance(response_data, dict):
            return json.dumps({
                "error": "Invalid response data format",
                "turn_uuid": turn_uuid
            }, ensure_ascii=False)

        response_content = response_data.get("response", "")
        if not response_content:
            return json.dumps({
                "error": "Response content is empty",
                "turn_uuid": turn_uuid
            }, ensure_ascii=False)

        # æå– pending_turns ä¸­çš„æ•°æ®
        user_message_uuid = pending_data.get("user_message_uuid")
        conversation_id = pending_data.get("conversation_id")
        session_id = pending_data.get("session_id")
        user_id = pending_data.get("user_id")
        dt_user = pending_data.get("dt_user")
        user_content = pending_data.get("user_content")
        routed_current_state = pending_data.get("routed_current_state")
        routed_current_sub_stage = pending_data.get("routed_current_sub_stage")
        stage_payload_draft = pending_data.get("stage_payload_draft")
        next_stage = pending_data.get("next_stage")
        next_substage = pending_data.get("next_substage")

        # ä»products_draftä¸­æå–å•†å“ä¿¡æ¯
        product_sales = []
        product_promote = []
        products_draft = pending_data.get("products_draft")
        if products_draft:
            try:
                products_data = json.loads(products_draft) if isinstance(products_draft, str) else products_draft
                if isinstance(products_data, dict):
                    # ç¡®ä¿è¿”å›æœ‰æ•ˆçš„åˆ—è¡¨
                    product_id_sales = products_data.get("product_id_sales")
                    product_id_promoted = products_data.get("product_id_promoted")

                    if product_id_sales is not None:
                        if isinstance(product_id_sales, list):
                            product_sales = product_id_sales
                        elif isinstance(product_id_sales, str) and product_id_sales.strip():
                            product_sales = [product_id_sales]
                        else:
                            product_sales = []

                    if product_id_promoted is not None:
                        if isinstance(product_id_promoted, list):
                            product_promote = product_id_promoted
                        elif isinstance(product_id_promoted, str) and product_id_promoted.strip():
                            product_promote = [product_id_promoted]
                        else:
                            product_promote = []

            except (json.JSONDecodeError, TypeError):
                product_sales = []
                product_promote = []

        # å¦‚æœæœªè·å–åˆ°å•†å“ä¿¡æ¯ï¼Œå°è¯•æ²¿ç”¨åŒä¸€ conversation/session/user çš„æœ€è¿‘ä¸€æ¡å•†å“å€¼
        if not product_sales and not product_promote:
            def _normalize_products(raw):
                if isinstance(raw, list):
                    return raw
                if isinstance(raw, str):
                    try:
                        parsed = json.loads(raw)
                        if isinstance(parsed, list):
                            return parsed
                    except Exception:
                        return []
                return []

            try:
                latest_products_raw = db.get_latest_message_products(conversation_id, session_id, user_id)
                latest_products = json.loads(latest_products_raw) if isinstance(latest_products_raw, str) else latest_products_raw
                if isinstance(latest_products, dict):
                    product_sales = _normalize_products(latest_products.get("product_sales"))
                    product_promote = _normalize_products(latest_products.get("product_promote"))
            except Exception as exc:  # noqa: BLE001
                logger.warning("[store_response_by_uuid] è·å–æœ€è¿‘å•†å“ä¿¡æ¯å¤±è´¥ turn_uuid=%s: %s", turn_uuid, exc)
                product_sales = product_sales or []
                product_promote = product_promote or []

        if not all([user_message_uuid, conversation_id, session_id, user_id, dt_user, user_content]):
            return json.dumps({
                "error": "Incomplete pending turn data",
                "turn_uuid": turn_uuid
            }, ensure_ascii=False)

        # ç”Ÿæˆ agent_message_uuid
        agent_message_uuid = str(uuid.uuid4())

        # ç”Ÿæˆ dt_responseï¼ˆå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å½“å‰æ—¶é—´ï¼‰
        dt_response = datetime.now(timezone.utc).astimezone().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]

        # é¢„å…ˆè·å–å†å²ä¸Šä¸‹æ–‡ï¼Œä¾› info ä¸æˆäº¤æ„æ„¿è¯„åˆ†å…±ç”¨
        history_context: List[Dict[str, Any]] = []
        history_context_raw = db.list_chat_messages(conversation_id, session_id, user_id, limit=30)
        if history_context_raw:
            try:
                history_context = json.loads(history_context_raw) if isinstance(history_context_raw, str) else history_context_raw
                if not isinstance(history_context, list):
                    history_context = []
            except (json.JSONDecodeError, TypeError):
                history_context = []

        # 0. å¼‚æ­¥ç”Ÿæˆ infoï¼ˆåœ¨å­˜å‚¨æ¶ˆæ¯çš„åŒæ—¶è¿›è¡Œï¼‰
        info_future: Optional[Future] = None
        bot_id = pending_data.get("bot_id")
        app_id = pending_data.get("app_id")
        
        # æ£€æŸ¥ bot_id å’Œ app_id æ˜¯å¦å­˜åœ¨
        if not bot_id or not app_id:
            logger.warning(
                "[store_response_by_uuid] pending_data ä¸­ç¼ºå°‘ bot_id æˆ– app_idï¼Œè·³è¿‡ info ç”Ÿæˆã€‚"
                "bot_id=%s, app_id=%s, pending_data_keys=%s",
                bot_id,
                app_id,
                list(pending_data.keys()) if isinstance(pending_data, dict) else "N/A"
            )
        
        if routed_current_state and bot_id and app_id:
            try:
                # æå‰è·å– bot é…ç½®ï¼ˆç”¨äºå¼‚æ­¥ä»»åŠ¡ï¼‰
                bot_config = get_bot_config(conversation_id, bot_id, app_id)
                structured_content = getattr(bot_config, "structuredContent", {}) or {}
                if not isinstance(structured_content, dict):
                    structured_content = {}
                
                route_state_prompt_map = structured_content.get('routeStateStrategies')
                if not isinstance(route_state_prompt_map, dict):
                    route_state_prompt_map = {}
                
                character_prompt = structured_content.get('character', '')
                bot_llm_config = structured_content.get('botLLMConfig')
                if not bot_llm_config or not isinstance(bot_llm_config, dict):
                    bot_llm_config = DEFAULT_BOT_LLM_CONFIG.copy()
                
                # history_context è½¬æ¢ç»™ infoï¼šrole agent -> assistant
                history_context_for_info: List[Dict[str, Any]] = []
                for item in history_context:
                    if isinstance(item, dict):
                        copied = dict(item)
                        if copied.get("role") == "agent":
                            copied["role"] = "assistant"
                        history_context_for_info.append(copied)
                
                # è·å– session_stateï¼ˆç”¨äºå¼‚æ­¥ä»»åŠ¡ï¼‰
                session_state_json = db.get_latest_session_state_payload(conversation_id, session_id, user_id)
                session_state_for_info: Dict[str, Any] = {}
                if session_state_json:
                    try:
                        parsed_state = json.loads(session_state_json)
                        if isinstance(parsed_state, dict):
                            session_state_for_info = parsed_state
                    except (json.JSONDecodeError, TypeError):
                        session_state_for_info = {}
                
                # æäº¤å¼‚æ­¥ä»»åŠ¡ç”Ÿæˆ info
                info_future = _INFO_EXECUTOR.submit(
                    _generate_info_content,
                    character_prompt=character_prompt,
                    route_state_prompt_map=route_state_prompt_map,
                    routed_current_state=routed_current_state,
                    routed_current_sub_stage=routed_current_sub_stage,
                    input_text=response_content,
                    history_context=history_context_for_info,
                    session_state=session_state_for_info,
                    bot_llm_config=bot_llm_config,
                    input_label="Assistant æœ¬è½®å›å¤å†…å®¹",
                )
                logger.info(
                    "[store_response_by_uuid] å·²æäº¤å¼‚æ­¥ info ç”Ÿæˆä»»åŠ¡ï¼Œ"
                    "turn_uuid=%s, conversation_id=%s, state=%s, sub_stage=%s",
                    turn_uuid,
                    conversation_id,
                    routed_current_state,
                    routed_current_sub_stage
                )
            except Exception as exc:
                logger.warning("[store_response_by_uuid] å‡†å¤‡å¼‚æ­¥ info ç”Ÿæˆå¤±è´¥: %s", exc)
                info_future = None
        
        # 1. å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯åˆ° chat_messages
        user_msg_result = db.store_chat_message(
            session_id=session_id,
            user_id=user_id,
            conversation_id=conversation_id,
            content=user_content,
            role="user",
            table=table,
            dt=dt_user,
            uuid_id=user_message_uuid,
            turn_uuid=turn_uuid
        )
        user_msg_data = json.loads(user_msg_result)
        user_message_id = user_msg_data.get("id")

        # 1.1 å¼‚æ­¥è®¡ç®—æˆäº¤æ„æ„¿åˆ†ï¼ˆåŸºäºæœ€æ–°ç”¨æˆ·æ¶ˆæ¯ï¼‰

        def _calculate_and_store_intent_score(history_messages: List[Dict[str, Any]]) -> None:
            try:
                if not isinstance(history_messages, list):
                    logger.warning("[store_response_by_uuid] history_messages éåˆ—è¡¨ï¼Œè·³è¿‡æˆäº¤æ„æ„¿è®¡ç®—ã€‚turn_uuid=%s", turn_uuid)
                    return
                score_value = generate_conversation_scores(
                    conversation_id=conversation_id,
                    session_id=session_id,
                    user_id=user_id,
                    messages=history_messages
                )
                db.store_total_score(
                    message_id=user_message_id,
                    conversation_id=conversation_id,
                    session_id=session_id,
                    user_id=user_id,
                    total_score=score_value,
                    uuid_id=user_message_uuid,
                    dt=dt_user
                )
                logger.info(
                    "[store_response_by_uuid] æˆäº¤æ„æ„¿åˆ†è®¡ç®—å¹¶å†™å…¥æˆåŠŸ turn_uuid=%s, score=%.2f, message_id=%s",
                    turn_uuid,
                    score_value,
                    user_message_id
                )
            except Exception as exc:
                logger.warning("[store_response_by_uuid] æˆäº¤æ„æ„¿åˆ†è®¡ç®—å¤±è´¥ turn_uuid=%s: %s", turn_uuid, exc, exc_info=True)

        try:
            history_for_score: List[Dict[str, Any]] = [dict(item) for item in history_context if isinstance(item, dict)]
            history_for_score.append({
                "id": user_message_id,
                "uuid_id": user_message_uuid,
                "datetime": dt_user,
                "role": "user",
                "content": user_content
            })
            _SCORE_EXECUTOR.submit(_calculate_and_store_intent_score, history_for_score)
        except Exception as exc:
            logger.warning("[store_response_by_uuid] æäº¤æˆäº¤æ„æ„¿åˆ†å¼‚æ­¥ä»»åŠ¡å¤±è´¥ turn_uuid=%s: %s", turn_uuid, exc, exc_info=True)

        # 2. å­˜å‚¨ agent æ¶ˆæ¯åˆ° chat_messages
        agent_msg_result = db.store_chat_message(
            session_id=session_id,
            user_id=user_id,
            conversation_id=conversation_id,
            content=response_content,
            role="agent",
            table=table,
            dt=dt_response,
            uuid_id=agent_message_uuid,
            turn_uuid=turn_uuid
        )
        agent_msg_data = json.loads(agent_msg_result)
        agent_message_id = agent_msg_data.get("id")

        # 2.1 æ›´æ–° agent æ¶ˆæ¯çš„å•†å“å­—æ®µ
        if product_sales is not None or product_promote is not None:
            db.update_chat_message_products(
                message_id=agent_message_id,
                product_sales=product_sales,
                product_promote=product_promote,
                table=table
            )

        # 3. ç­‰å¾…å¼‚æ­¥ info ç”Ÿæˆå®Œæˆï¼ˆå¦‚æœå·²æäº¤ï¼‰
        info_content: Dict[str, Any] = {}
        if info_future:
            try:
                info_content = info_future.result()  # ç­‰å¾…å¼‚æ­¥ä»»åŠ¡å®Œæˆ
                logger.info(
                    "[store_response_by_uuid] å¼‚æ­¥ info ç”ŸæˆæˆåŠŸï¼Œ"
                    "turn_uuid=%sinfo_content=%s",
                    turn_uuid,
                    json.dumps(info_content, ensure_ascii=False) if info_content else "{}"
                )
            except Exception as exc:
                logger.warning(
                    "[store_response_by_uuid] å¼‚æ­¥ info ç”Ÿæˆå¤±è´¥ï¼Œturn_uuid=%s: %s",
                    turn_uuid,
                    exc,
                    exc_info=True
                )
                info_content = {}
        
        # 4. å­˜å‚¨ session_stateï¼ˆä»…å­˜å‚¨ infoï¼Œä¸åŒ…å« responseï¼‰
        session_state_id = None
        stage_payload: Dict[str, Any] = {}
        
        if routed_current_state and info_content:
            # æ— è®º stage_payload_draft ä¸­æœ‰ä»€ä¹ˆï¼Œæˆ‘ä»¬åªå…³å¿ƒæ„å»ºåŒ…å« info çš„ payload
            # å¿½ç•¥ draft ä¸­çš„ response å†…å®¹
            substage_col = normalize_substage_name(routed_current_state, routed_current_sub_stage)
            stage_payload = {substage_col: {"info": info_content}}
            
            logger.info(
                "[store_response_by_uuid] æ„å»ºä»…åŒ…å« info çš„ stage_payloadï¼Œ"
                "turn_uuid=%s, substage=%s",
                turn_uuid,
                substage_col
            )
        else:
            # å¦‚æœæ²¡æœ‰ infoï¼Œå°è¯•ä» draft ä¸­æå– infoï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦åˆ™ä¸ºç©º
            if stage_payload_draft:
                try:
                    draft_payload = json.loads(stage_payload_draft) if isinstance(stage_payload_draft, str) else stage_payload_draft
                    if isinstance(draft_payload, dict):
                        # éå† draftï¼Œåªä¿ç•™ info å­—æ®µ
                        for key, value in draft_payload.items():
                            if isinstance(value, dict) and "info" in value:
                                stage_payload[key] = {"info": value["info"]}
                except json.JSONDecodeError:
                    pass
            
            if not stage_payload and info_content:
                 logger.warning(
                    "[store_response_by_uuid] ç”Ÿæˆäº† info ä½†æ— æ³•å­˜å‚¨ï¼ˆç¼ºå°‘ routed_current_stateï¼‰ï¼Œ"
                    "turn_uuid=%s, info_content=%s",
                    turn_uuid,
                    json.dumps(info_content, ensure_ascii=False)
                )

        session_state_result = db.store_session_state(
            message_id=user_message_id,  # ä½¿ç”¨ user_message_idï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
            conversation_id=conversation_id,
            session_id=session_id,
            user_id=user_id,
            current_state=routed_current_state,
            current_sub_stage=routed_current_sub_stage if routed_current_sub_stage else f"{routed_current_state}_01",
            stage_payload_json=json.dumps(stage_payload, ensure_ascii=False),
            dt=dt_user,
            table="session_states",
            uuid_id=user_message_uuid,
            turn_uuid=turn_uuid,
            next_stage=next_stage,
            next_substage=next_substage
        )
        session_state_data = json.loads(session_state_result)
        session_state_id = session_state_data.get("id")

        # 5. æ ‡è®° pending_turn ä¸º done
        db.mark_pending_turn_done(turn_uuid)

        # 6. æ¸…ç† Redis ç¼“å­˜
        try:
            redis_set(cache_key, "", expired=1)  # ç«‹å³è¿‡æœŸ
            redis_set(f"pending:{turn_uuid}", "", expired=1)  # ç«‹å³è¿‡æœŸ
        except Exception:
            pass

        return json.dumps({
            "success": True,
            "message": "å­˜å‚¨æˆåŠŸ",
            "turn_uuid": turn_uuid,
            "user_message_id": user_message_id,
            "user_message_uuid": user_message_uuid,
            "agent_message_id": agent_message_id,
            "agent_message_uuid": agent_message_uuid,
            "session_state_id": session_state_id
        }, ensure_ascii=False)

    except json.JSONDecodeError:
        return json.dumps({
            "error": "Failed to parse response data from cache",
            "turn_uuid": turn_uuid
        }, ensure_ascii=False)
    except Exception as e:
        return json.dumps({
            "error": f"Failed to store response: {str(e)}",
            "turn_uuid": turn_uuid
        }, ensure_ascii=False)


@mcp.tool(description="Service compliance response: output compliance service content based on session context.")
def service_compliance_response(session_id: str, user_id: str, bot_id: str, app_id: str, turn_uuid: str, equity_key: str = None) -> str:
    """å±¥çº¦æœåŠ¡å“åº”ï¼šæ ¹æ®ç”¨æˆ·è¾“å…¥å’Œä¼šè¯ä¸Šä¸‹æ–‡è¾“å‡ºå±¥çº¦æœåŠ¡å†…å®¹ã€‚

    å‚æ•°:
        session_id: ä¼šè¯æ ‡è¯†
        user_id: ç”¨æˆ·æ ‡è¯†
        bot_id: æœºå™¨äººæ ‡è¯†
        app_id: åº”ç”¨æ ‡è¯†
        turn_uuid: å›åˆ UUIDï¼ˆç”±è°ƒç”¨æ–¹ç”Ÿæˆï¼Œç”¨äºå®šä½ä¸Šä¸‹æ–‡ï¼‰

    è¿”å›:
        JSON å­—ç¬¦ä¸²ï¼ŒåŒ…å«å±¥çº¦æœåŠ¡å†…å®¹å’Œ turn_uuid
    """
    if not turn_uuid:
        return json.dumps({"error": "turn_uuid is required"}, ensure_ascii=False)

    # è·å– conversation_id
    conversation_json = db.get_conversation_with_cache(user_id, session_id)
    conversation_id = ""
    try:
        conv_data = json.loads(conversation_json)
        if isinstance(conv_data, dict) and "id" in conv_data:
            conversation_id = str(conv_data["id"])
    except (json.JSONDecodeError, TypeError, KeyError):
        conversation_id = ""

    # è·å– bot é…ç½®
    bot_config = get_bot_config(conversation_id, bot_id, app_id)
    structuredContent = bot_config.structuredContent

    # å…¥å£å¤„ï¼šç”Ÿæˆæ—¶é—´æˆ³å¹¶å†™å…¥ pending_turns
    dt_user = datetime.now(timezone.utc).astimezone().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
    user_message_uuid = str(uuid.uuid4())

    # å†™å…¥ pending_turns åŸºæœ¬ä¿¡æ¯
    db.store_pending_turn(
        turn_uuid=turn_uuid,
        user_message_uuid=user_message_uuid,
        conversation_id=conversation_id,
        session_id=session_id,
        user_id=user_id,
        dt_user=dt_user,
        user_content="",
        bot_id=bot_id,
        app_id=app_id
    )

    # åŒæ—¶ç¼“å­˜åˆ° Redisï¼ˆå†—ä½™ï¼‰
    try:
        pending_cache_key = f"pending:{turn_uuid}"
        pending_cache_data = {
            "turn_uuid": turn_uuid,
            "user_message_uuid": user_message_uuid,
            "conversation_id": conversation_id,
            "session_id": session_id,
            "user_id": user_id,
            "dt_user": dt_user,
            "user_content": "",
            "bot_id": bot_id,
            "app_id": app_id
        }
        redis_set(pending_cache_key, json.dumps(pending_cache_data, ensure_ascii=False), expired=86400)  # 24å°æ—¶
    except Exception:
        pass

    # è·å– compliance é˜¶æ®µçš„ prompt
    route_state_prompt_map = structuredContent.get('routeStateStrategies') if isinstance(structuredContent, dict) else None
    if not isinstance(route_state_prompt_map, dict):
        route_state_prompt_map = {}

    # è·å– character prompt
    character_prompt = structuredContent.get('character', '')

    # è®¾ç½® compliance é˜¶æ®µä¿¡æ¯
    routed_current_state = "compliance"
    routed_current_sub_stage = "compliance_01"  # å°†åœ¨é€‰æ‹©æ¨¡å—åæ ¹æ®ç´¢å¼•è¦†ç›–

    # è·å– compliance é˜¶æ®µçš„æ¨¡å—ï¼Œå¹¶åŸºäº equity_key ç›´æ¥åŒ¹é… product å­—æ®µç¡®å®šæ¨¡å—ç´¢å¼•
    compliance_modules = route_state_prompt_map.get('compliance', []) if isinstance(route_state_prompt_map, dict) else []
    selected_idx = 0
    matching_idx = find_compliance_module_index_by_product(route_state_prompt_map, equity_key)
    if matching_idx is not None:
        selected_idx = matching_idx
    compliance_module = compliance_modules[selected_idx] if compliance_modules else {}
    # æ ¹æ®é€‰æ‹©çš„ç´¢å¼•ç¡®å®šå…·ä½“ substageï¼ˆä¾‹å¦‚ 0 -> compliance_01ï¼‰
    routed_current_sub_stage = f"compliance_{selected_idx + 1:02d}"
    # if not compliance_modules:
    #     # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨é»˜è®¤çš„ compliance prompt
    #     compliance_module = {
    #         "purpose": "æ ¹æ®ç”¨æˆ·éœ€æ±‚å’Œä¼šè¯çŠ¶æ€ï¼Œè¾“å‡ºå±¥çº¦æœåŠ¡å†…å®¹ï¼ŒåŒ…æ‹¬æœåŠ¡è¯´æ˜ã€ä½¿ç”¨æ–¹å¼ã€æ³¨æ„äº‹é¡¹ç­‰ã€‚",
    #         "name": ["response"],
    #         "expect": ["å±¥çº¦æœåŠ¡å†…å®¹çš„è¯¦ç»†è¯´æ˜"],
    #         "operation": [
    #             "1. åˆ†æç”¨æˆ·éœ€æ±‚å’Œå½“å‰ä¼šè¯çŠ¶æ€",
    #             "2. æå–ç›¸å…³çš„æœåŠ¡ä¿¡æ¯",
    #             "3. ç”Ÿæˆè¯¦ç»†çš„å±¥çº¦æœåŠ¡å†…å®¹è¯´æ˜",
    #             "4. ç¡®ä¿å†…å®¹æ¸…æ™°ã€å®Œæ•´ã€æ˜“äºç†è§£"
    #         ]
    #     }
    # else:
    #     compliance_module = compliance_modules[0]
    #     # å¦‚æœæœ‰å¤šä¸ªæ¨¡å—ï¼Œå¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©ï¼Œè¿™é‡Œä½¿ç”¨ç¬¬ä¸€ä¸ª
    #     # å¦‚æœæ¨¡å—æœ‰ç¼–å·ï¼Œå¯ä»¥æå– substage ç¼–å·
    #     if len(compliance_modules) > 1:
    #         # å¯ä»¥æ ¹æ®ä¸šåŠ¡é€»è¾‘é€‰æ‹©æ¨¡å—ï¼Œè¿™é‡Œé»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ª
    #         pass

    # ç»„è£… prompt
    compliance_prompt = join_prompts(compliance_module)
    full_prompt = "\n\n".join([character_prompt, compliance_prompt])

    # botLLMConfig å…œåº•
    botLLMConfig = structuredContent.get('botLLMConfig')
    if not botLLMConfig or not isinstance(botLLMConfig, dict):
        botLLMConfig = DEFAULT_BOT_LLM_CONFIG.copy()

    # ä»¥ turn_uuid ä¸ºèŠ‚ç‚¹ï¼Œè·å–è¯¥æ—¶é—´ç‚¹ä¹‹å‰çš„å†å²ä¸Šä¸‹æ–‡
    history_context = db.list_chat_messages_before_turn(
        conversation_id=conversation_id,
        session_id=session_id,
        user_id=user_id,
        dt_upper=dt_user,
        limit=50
    )
    session_state_json = db.get_latest_session_state_before_turn(
        conversation_id=conversation_id,
        session_id=session_id,
        user_id=user_id,
        dt_upper=dt_user
    )
    session_state = {}
    if session_state_json:
        try:
            parsed = json.loads(session_state_json)
            if isinstance(parsed, dict):
                session_state = parsed
        except (json.JSONDecodeError, TypeError):
            session_state = {}

    # å°†æœ¬è½® pending çš„ç”¨æˆ·è¾“å…¥æ‹¼åˆ°å†å²æœ«å°¾ï¼ˆä»…ç”¨äºä¸Šä¸‹æ–‡ï¼‰ï¼Œå¹¶åšå»é‡
    try:
        pending_json = db.get_pending_turn(turn_uuid)
        if pending_json:
            pending_obj = json.loads(pending_json)
            if isinstance(pending_obj, dict):
                pending_content = (pending_obj.get("user_content") or "").strip()
                pending_dt = pending_obj.get("dt_user")
                if pending_content:
                    hist = json.loads(history_context) if isinstance(history_context, str) else history_context
                    if isinstance(hist, list):
                        append_needed = True
                        if len(hist) > 0 and isinstance(hist[-1], dict):
                            last = hist[-1]
                            last_role = last.get("role")
                            last_content = (last.get("content") or "").strip()
                            if last_role == "user" and last_content == pending_content:
                                append_needed = False
                        if append_needed:
                            hist.append({
                                "id": None,
                                "datetime": pending_dt or "",
                                "role": "user",
                                "content": pending_content
                            })
                        history_context = json.dumps(hist, ensure_ascii=False)
    except Exception:
        # ä¸å½±å“ä¸»æµç¨‹
        pass

    # è°ƒç”¨ LLM ç”Ÿæˆå±¥çº¦æœåŠ¡å†…å®¹
    results = llm_generic(
        full_prompt=full_prompt,
        user_input="",
        history_context=history_context,
        session_state=session_state,
        botLLMConfig=botLLMConfig
    )

    # è§£æ resultsï¼ˆå¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²ï¼‰
    if isinstance(results, str):
        try:
            results = json.loads(results)
        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯ JSONï¼Œä¿æŒåŸæ ·
            pass

    # åå¤„ç†ï¼šä» info ä¸­æå–å¯¹è¯å†…å®¹å¹¶åˆå¹¶åˆ° response
    if isinstance(results, dict):
        results = extract_conversational_content_from_info(results)

    # ä¸º results æ·»åŠ  turn_uuid å¹¶ç¼“å­˜ response
    add_conversation_id_uuid_and_cache(results, conversation_id, session_id, user_id, turn_uuid)

    # å¦‚æœ results åŒ…å« info å­—æ®µï¼Œæ›´æ–° pending_turns çš„çŠ¶æ€ä¿¡æ¯
    if isinstance(results, dict) and "info" in results:
        # æ„å»º substage åç§°ï¼ˆå¦‚ "compliance_01"ï¼‰
        substage_col = routed_current_sub_stage

        # æ„å»º stage_payload æ ¼å¼ï¼š{"compliance_01": {"info": {...}}}
        stage_payload = {substage_col: {"info": results["info"]}}

        # æ›´æ–° pending_turns çš„çŠ¶æ€ä¿¡æ¯
        db.update_pending_turn_state(
            turn_uuid=turn_uuid,
            routed_current_state=routed_current_state,
            routed_current_sub_stage=routed_current_sub_stage,
            stage_payload_draft=json.dumps(stage_payload, ensure_ascii=False)
        )

    # è®¾ç½® next_stage å’Œ next_substageï¼šä½¿ç”¨ equity_key å¯¹åº”çš„æ¨¡å—ç´¢å¼•ç¡®å®šçš„ substage
    next_stage = routed_current_state
    next_substage = routed_current_sub_stage

    # æ›´æ–° pending_turns çš„ next_stage å’Œ next_substage
    db.update_pending_turn_state(
        turn_uuid=turn_uuid,
        next_stage=next_stage,
        next_substage=next_substage
    )

    # è®°å½•æœ€åè®¾å®šçš„ next_stage å’Œ next_substageï¼ˆservice_compliance_responseï¼‰
    logger.info(f"[Final Next Stage - Compliance] conversation_id={conversation_id}, session_id={session_id}, user_id={user_id}")
    logger.info(f"[Final Next Stage - Compliance] next_stage={next_stage}, next_substage={next_substage}")

    # è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²è¿”å›ï¼ˆåŒ…å« turn_uuidï¼‰
    result_dict = results if isinstance(results, dict) else {"response": results}
    result_dict["turn_uuid"] = turn_uuid

    # åœ¨ info ä¸­æ‰‹åŠ¨æ·»åŠ  equity_used å­—æ®µ
    if "info" not in result_dict:
        result_dict["info"] = {}
    if not isinstance(result_dict["info"], dict):
        result_dict["info"] = {}
    result_dict["info"]["equity_used"] = equity_key if equity_key else ""

    return json.dumps(result_dict, ensure_ascii=False)


@mcp.tool(description="Calculate follow-up strategy: determine optimal follow-up timestamp (ISO format) based on conversation history and timing. Returns timestamp string directly.")
def calculate_follow_up_timestamp(
    app_id: str,
    bot_id: str,
    session_id: str,
    user_id: str,
    user_last_timestamp: int,
    agent_last_timestamp: int,
    current_timestamp: int,
) -> str:
    """è¿½å•ç­–ç•¥ï¼šæ ¹æ®ä¼šè¯å†å²å’Œæ—¶é—´ä¿¡æ¯è®¡ç®—åˆé€‚çš„è¿½é—®æ—¶æœºã€‚

    å‚æ•°:
        app_id: åº”ç”¨æ ‡è¯†
        bot_id: æœºå™¨äººæ ‡è¯†
        session_id: ä¼šè¯æ ‡è¯†
        user_id: ç”¨æˆ·æ ‡è¯†
        user_last_timestamp: ç”¨æˆ·æœ€åå›å¤æ—¶é—´æˆ³ï¼ˆUnix ç§’çº§ï¼Œintï¼‰
        agent_last_timestamp: Agent æœ€åå›å¤æ—¶é—´æˆ³ï¼ˆUnix ç§’çº§ï¼Œintï¼‰
        current_timestamp: å½“å‰æ—¶é—´æˆ³ï¼ˆUnix ç§’çº§ï¼Œintï¼‰

    è¿”å›:
        æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼ˆUnix ç§’çº§ï¼Œå­—ç¬¦ä¸²å½¢å¼ï¼‰ï¼Œä¾‹å¦‚ï¼š"1732427400"
        ç¡®ä¿è¿”å›çš„æ—¶é—´æˆ³ >= current_timestamp

    æµç¨‹:
        1. æ ¹æ® session_id å’Œ user_id è·å–æœ€æ–° conversation_id å’Œå†å²å¯¹è¯
        2. æ ¹æ® app_id å’Œ bot_id è·å– LLM é…ç½®ï¼ˆä¼˜å…ˆ Redisï¼‰
        3. è°ƒç”¨ LLM åˆ†æå†å²å¯¹è¯å’Œæ—¶é—´ä¿¡æ¯ï¼Œç»™å‡ºåˆé€‚çš„è¿½é—®æ—¶æœº
        4. ç¡®ä¿è¿”å›çš„æ—¶é—´æˆ³ >= current_timestamp
        5. å…œåº•é€»è¾‘ï¼šå¦‚æœ LLM è¿”å›æ ¼å¼é”™è¯¯æˆ–æ—¶é—´æˆ³æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥ï¼ˆå½“å‰æ—¶é—´ + 15 åˆ†é’Ÿï¼‰
    """
    def _parse_timestamp(ts_value: int) -> datetime:
        """è§£æç§’çº§ Unix æ—¶é—´æˆ³ï¼ˆä»…é™æ•´æ•°ï¼‰ã€‚"""
        return datetime.fromtimestamp(ts_value, tz=timezone.utc)

    try:
        # è§£ææ—¶é—´æˆ³
        user_last_dt = _parse_timestamp(user_last_timestamp)
        agent_last_dt = _parse_timestamp(agent_last_timestamp)
        current_dt = _parse_timestamp(current_timestamp)

        # è·å– conversation_id
        conversation_json = db.get_conversation_with_cache(user_id, session_id)
        conversation_id = ""
        try:
            conv_data = json.loads(conversation_json)
            if isinstance(conv_data, dict) and "id" in conv_data:
                conversation_id = str(conv_data["id"])
        except (json.JSONDecodeError, TypeError, KeyError):
            conversation_id = ""

        if not conversation_id:
            return json.dumps({
                "error": "Conversation not found",
                "follow_up_timestamp": str(int(current_dt.timestamp())),
            }, ensure_ascii=False)

        # è·å–å†å²å¯¹è¯ï¼ˆæœ€è¿‘ 20 æ¡ï¼‰ï¼Œå¹¶æ ‡å‡†åŒ–è§’è‰²
        history_context_str = db.list_chat_messages(conversation_id, session_id, user_id, limit=20)
        raw_history: List[Dict[str, Any]] = []
        if history_context_str:
            try:
                parsed_history = json.loads(history_context_str)
                if isinstance(parsed_history, list):
                    raw_history = parsed_history
            except (json.JSONDecodeError, TypeError):
                raw_history = []

        history_context: List[Dict[str, Any]] = []
        for item in raw_history:
            if not isinstance(item, dict):
                continue
            role = str(item.get("role", "")).strip().lower()
            if role == "agent":
                role = "assistant"
            elif role not in {"assistant", "system", "user", "tool", "function"}:
                role = "user"
            history_context.append({
                "role": role,
                "content": item.get("content", ""),
            })

        # è·å– bot LLM é…ç½®ï¼ˆä¼˜å…ˆ Redisï¼‰
        bot_config = get_bot_config(conversation_id, bot_id, app_id)
        structured_content = bot_config.structuredContent
        bot_llm_config = structured_content.get('botLLMConfig')
        if not bot_llm_config or not isinstance(bot_llm_config, dict):
            bot_llm_config = DEFAULT_BOT_LLM_CONFIG.copy()

        # è®¡ç®—æ—¶é—´å·®ï¼ˆç§’ï¼‰
        user_silence_seconds = (current_dt - user_last_dt).total_seconds()
        agent_silence_seconds = (current_dt - agent_last_dt).total_seconds()

        # æ„å»º promptï¼ˆå†å²å¯¹è¯é€šè¿‡ history_context ä¼ å…¥ï¼Œä¸åœ¨ prompt ä¸­æ‹¼æ¥ï¼‰
        follow_up_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è¿½å•ç­–ç•¥åŠ©æ‰‹ï¼Œéœ€è¦æ ¹æ®ä¼šè¯å†å²å’Œæ—¶é—´ä¿¡æ¯ï¼Œåˆ¤æ–­åˆé€‚çš„è¿½é—®æ—¶æœºã€‚

ã€ä»»åŠ¡ã€‘
è¯·ç»“åˆå†å²å¯¹è¯ä¸Šä¸‹æ–‡å’Œæ—¶é—´ä¿¡æ¯ï¼Œåˆ¤æ–­åˆé€‚çš„è¿½é—®æ—¶æœºã€‚è€ƒè™‘å› ç´ ï¼š
1. Agent æœ€åå›å¤å†…å®¹ï¼šå¦‚æœ Agent æå‡ºäº†é—®é¢˜æˆ–ç­‰å¾…ç”¨æˆ·å›å¤ï¼Œå¯é€‚å½“æå‰è¿½é—®
2. ä¼šè¯é˜¶æ®µï¼šæ ¹æ®å¯¹è¯å†…å®¹åˆ¤æ–­ä¼šè¯å¤„äºå“ªä¸ªé˜¶æ®µï¼ˆåˆæ¬¡æ¥è§¦ã€æ·±å…¥æ²Ÿé€šã€æˆäº¤é˜¶æ®µç­‰ï¼‰
3. ç”¨æˆ·å‚ä¸åº¦ï¼šæ ¹æ®å†å²å¯¹è¯åˆ¤æ–­ç”¨æˆ·å‚ä¸åº¦ï¼Œå‚ä¸åº¦é«˜å¯é€‚å½“æå‰è¿½é—®

ã€è¾“å‡ºè¦æ±‚ã€‘
è¯·ç›´æ¥è¾“å‡ºæœŸæœ›æ‰§è¡Œè¿½å•çš„æ—¶é—´æˆ³ï¼ˆISO æ ¼å¼ï¼Œå¿…é¡» >= å½“å‰æ—¶é—´ï¼‰ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚
æ—¶é—´æˆ³æ ¼å¼ç¤ºä¾‹ï¼š{current_dt.isoformat()}

è¯·æ ¹æ®å®é™…æƒ…å†µç›´æ¥è¾“å‡ºæ—¶é—´æˆ³ã€‚"""

        # æ„å»ºç”¨æˆ·è¾“å…¥ï¼ˆåŒ…å«æ—¶é—´ä¿¡æ¯ï¼Œå†å²å¯¹è¯é€šè¿‡ history_context ä¼ å…¥ï¼‰
        user_input_with_timing = f"""è¯·æ ¹æ®ä»¥ä¸‹æ—¶é—´ä¿¡æ¯å’Œå†å²å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œåˆ¤æ–­åˆé€‚çš„è¿½é—®æ—¶æœºï¼š

- ç”¨æˆ·æœ€åå›å¤æ—¶é—´: {user_last_dt.isoformat()}
- Agent æœ€åå›å¤æ—¶é—´: {agent_last_dt.isoformat()}
- å½“å‰æ—¶é—´: {current_dt.isoformat()}
- ç”¨æˆ·å·²æ²‰é»˜æ—¶é•¿: {user_silence_seconds:.0f} ç§’ï¼ˆçº¦ {user_silence_seconds / 60:.1f} åˆ†é’Ÿï¼‰
- Agent å·²æ²‰é»˜æ—¶é•¿: {agent_silence_seconds:.0f} ç§’ï¼ˆçº¦ {agent_silence_seconds / 60:.1f} åˆ†é’Ÿï¼‰

è¯·ç»“åˆå†å²å¯¹è¯å†…å®¹ï¼Œç›´æ¥è¾“å‡ºæ—¶é—´æˆ³ï¼ˆISO æ ¼å¼ï¼‰ã€‚"""

        # è°ƒç”¨ LLMï¼ˆå†å²å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡ä¼ å…¥ï¼‰
        llm_result = llm_generic(
            full_prompt=follow_up_prompt,
            user_input=user_input_with_timing,
            history_context=history_context,
            session_state={},
            botLLMConfig=bot_llm_config,
            prompt_without_character=follow_up_prompt,
        )

        # è§£æ LLM ç»“æœï¼ˆç›´æ¥æå–æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼‰
        follow_up_ts_str = ""
        if isinstance(llm_result, str):
            # æ¸…ç†å¯èƒ½çš„ JSON åŒ…è£¹æˆ–å¤šä½™æ–‡æœ¬
            cleaned = _cleanup_llm_json_str(llm_result).strip()
            # å°è¯•æå–æ—¶é—´æˆ³ï¼ˆå¯èƒ½æ˜¯ ISO æ ¼å¼å­—ç¬¦ä¸²ï¼‰
            # ç§»é™¤å¯èƒ½çš„å¼•å·
            cleaned = cleaned.strip('"').strip("'").strip()
            # å°è¯•ä» JSON ä¸­æå–ï¼ˆå…¼å®¹ LLM å¯èƒ½ä»è¿”å› JSON çš„æƒ…å†µï¼‰
            try:
                parsed = json.loads(cleaned)
                if isinstance(parsed, dict):
                    follow_up_ts_str = parsed.get("follow_up_timestamp", "") or parsed.get("timestamp", "")
                elif isinstance(parsed, str):
                    follow_up_ts_str = parsed
            except json.JSONDecodeError:
                # ä¸æ˜¯ JSONï¼Œç›´æ¥ä½¿ç”¨æ¸…ç†åçš„å­—ç¬¦ä¸²
                follow_up_ts_str = cleaned
        elif isinstance(llm_result, dict):
            follow_up_ts_str = llm_result.get("follow_up_timestamp", "") or llm_result.get("timestamp", "")

        # è§£æå¹¶éªŒè¯æ—¶é—´æˆ³
        follow_up_dt = None
        try:
            if follow_up_ts_str:
                follow_up_dt = _parse_timestamp(follow_up_ts_str)
        except (ValueError, TypeError):
            follow_up_dt = None

        # å…œåº•é€»è¾‘ï¼šå¦‚æœè§£æå¤±è´¥æˆ–ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥
        if follow_up_dt is None:
            # ä½¿ç”¨é»˜è®¤ç­–ç•¥ï¼šå½“å‰æ—¶é—´ + 15 åˆ†é’Ÿ
            follow_up_dt = current_dt + timedelta(minutes=15)
            logger.warning(
                "[calculate_follow_up_timestamp] LLM è¿”å›æ—¶é—´æˆ³æ ¼å¼é”™è¯¯æˆ–ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥ï¼ˆå½“å‰æ—¶é—´ + 15 åˆ†é’Ÿï¼‰ã€‚åŸå§‹è¿”å›: %s",
                llm_result[:200] if isinstance(llm_result, str) else str(llm_result)[:200]
            )

        # ç¡®ä¿æ—¶é—´æˆ³ >= current_timestamp
        if follow_up_dt < current_dt:
            # å¦‚æœå°äºå½“å‰æ—¶é—´ï¼Œä½¿ç”¨å½“å‰æ—¶é—´ + 5 åˆ†é’Ÿä½œä¸ºæœ€å°é—´éš”
            follow_up_dt = current_dt + timedelta(minutes=5)
            logger.warning(
                "[calculate_follow_up_timestamp] LLM è¿”å›æ—¶é—´æˆ³æ—©äºå½“å‰æ—¶é—´ï¼Œè°ƒæ•´è‡³å½“å‰æ—¶é—´å 5 åˆ†é’Ÿ"
            )

        # è¿”å›ç§’çº§ Unix æ—¶é—´æˆ³
        return str(int(follow_up_dt.timestamp()))

    except Exception as e:
        logger.error(f"[calculate_follow_up_timestamp] æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œè¿”å›å½“å‰æ—¶é—´ + 15 åˆ†é’Ÿä½œä¸ºé»˜è®¤å€¼ï¼ˆç¡®ä¿è¾“å‡ºä¸ºæ—¶é—´æˆ³æ ¼å¼ï¼‰
        try:
            current_dt = _parse_timestamp(current_timestamp)
            default_dt = current_dt + timedelta(minutes=15)
            return str(int(default_dt.timestamp()))
        except Exception:
            try:
                fallback_dt = datetime.now(timezone.utc) + timedelta(minutes=15)
                return str(int(fallback_dt.timestamp()))
            except Exception:
                return str(int(datetime.now(timezone.utc).timestamp()))


@mcp.tool(description="Generate follow-up reply: produce proactive follow-up response (ISO prompt) and return response text with turn_uuid.")
def generate_follow_up_response(
    app_id: str,
    bot_id: str,
    session_id: str,
    user_id: str,
    tenant_outer_id: Optional[str] = None,
) -> str:
    """è°ƒç”¨ LLM ç”Ÿæˆè¿½å•å›å¤ï¼Œè¿”å› response ä¸ turn_uuidï¼ˆJSON å­—ç¬¦ä¸²ï¼‰ã€‚

    - è‡ªåŠ¨è·å– conversation_idã€ä¼šè¯ä¸Šä¸‹æ–‡ä¸ bot é…ç½®
    - è‹¥æä¾› tenant_outer_id ä¸”é…ç½®äº† datasetIdï¼Œåˆ™æ£€ç´¢è¥é”€è¯æœ¯
    - ç»“æœä»…è¿”å› {"response": "...", "turn_uuid": "..."}ï¼Œä¾›å¤–éƒ¨è°ƒç”¨ store_response_by_uuid
    """
    try:
        conversation_json = db.get_conversation_with_cache(user_id, session_id)
        conversation_id = ""
        if conversation_json:
            try:
                conv_obj = json.loads(conversation_json)
                if isinstance(conv_obj, dict) and "id" in conv_obj:
                    conversation_id = str(conv_obj["id"])
            except (json.JSONDecodeError, TypeError, KeyError):
                conversation_id = ""
        if not conversation_id:
            return json.dumps({
                "error": "conversation_id not found",
            }, ensure_ascii=False)

        session_state_json = db.get_latest_session_state_payload(conversation_id, session_id, user_id)
        session_state: Dict[str, Any] = {}
        if session_state_json:
            try:
                parsed_state = json.loads(session_state_json)
                if isinstance(parsed_state, dict):
                    session_state = parsed_state
            except (json.JSONDecodeError, TypeError):
                session_state = {}

        routed_current_state = (
            session_state.get("next_stage")
            or session_state.get("current_state")
            or "decision_making"
        )
        routed_current_sub_stage = (
            session_state.get("next_sub_stage")
            or session_state.get("current_sub_stage")
            or f"{routed_current_state}_01"
        )

        history_context_str = db.list_chat_messages(conversation_id, session_id, user_id, limit=30)
        raw_history: List[Dict[str, Any]] = []
        if history_context_str:
            try:
                parsed_history = json.loads(history_context_str)
                if isinstance(parsed_history, list):
                    raw_history = parsed_history
            except (json.JSONDecodeError, TypeError):
                raw_history = []

        history_context: List[Dict[str, Any]] = []
        for item in raw_history:
            if not isinstance(item, dict):
                continue
            role = str(item.get("role", "")).strip().lower()
            if role == "agent":
                role = "assistant"
            elif role == "assistant":
                role = "assistant"
            elif role == "system":
                role = "system"
            else:
                role = "user"
            history_context.append({
                "role": role,
                "content": item.get("content", ""),
            })

        latest_user_message = ""
        for item in reversed(history_context):
            if isinstance(item, dict) and item.get("role") == "user":
                latest_user_message = str(item.get("content", "")).strip()
                if latest_user_message:
                    break

        bot_config = get_bot_config(conversation_id, bot_id, app_id)
        structured_content = getattr(bot_config, "structuredContent", {}) or {}
        if not isinstance(structured_content, dict):
            structured_content = {}
        character_prompt = structured_content.get("character", "")
        route_state_prompt_map = structured_content.get("routeStateStrategies")
        if not isinstance(route_state_prompt_map, dict):
            route_state_prompt_map = {}
        bot_llm_config = structured_content.get("botLLMConfig")
        if not isinstance(bot_llm_config, dict):
            bot_llm_config = DEFAULT_BOT_LLM_CONFIG.copy()

        marketing_snippet = ""
        dataset_id = str(structured_content.get("datasetId", "") or "").strip()
        if tenant_outer_id and dataset_id:
            query_text = latest_user_message or "è¿½å•è¥é”€è¯æœ¯"
            try:
                dataset_raw = retrieve_dataset(
                    tenant_outer_id=str(tenant_outer_id),
                    app_id=app_id,
                    dataset_id=dataset_id,
                    query=query_text,
                )
                marketing_snippet = extract_dataset_snippets(dataset_raw)
                if marketing_snippet:
                    logger.info("[generate_follow_up_response] è¥é”€è¯æœ¯æ£€ç´¢æˆåŠŸï¼Œé•¿åº¦=%d", len(marketing_snippet))
            except Exception as exc:  # noqa: BLE001
                logger.warning("[generate_follow_up_response] è¥é”€è¯æœ¯æ£€ç´¢å¤±è´¥: %s", exc)

        dt_user = datetime.now(timezone.utc).astimezone().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
        turn_uuid = str(uuid.uuid4())
        user_message_uuid = str(uuid.uuid4())

        db.store_pending_turn(
            turn_uuid=turn_uuid,
            user_message_uuid=user_message_uuid,
            conversation_id=conversation_id,
            session_id=session_id,
            user_id=user_id,
            dt_user=dt_user,
            user_content="",
            bot_id=bot_id,
            app_id=app_id,
        )
        try:
            pending_cache_key = f"pending:{turn_uuid}"
            pending_cache_data = {
                "turn_uuid": turn_uuid,
                "user_message_uuid": user_message_uuid,
                "conversation_id": conversation_id,
                "session_id": session_id,
                "user_id": user_id,
                "dt_user": dt_user,
                "user_content": "",
                "bot_id": bot_id,
                "app_id": app_id,
            }
            redis_set(pending_cache_key, json.dumps(pending_cache_data, ensure_ascii=False), expired=86400)
        except Exception:
            pass

        follow_up_brief = "\n".join([
            "[è¿½å•ä»»åŠ¡]",
            "ç”¨æˆ·é˜¶æ®µæš‚æœªç»“æŸï¼Œè¯·ä»¥æ¸©æš–ã€çœŸè¯šä¸”ä¸è¿‡åº¦æ‰“æ‰°çš„å£å»è¿›è¡Œè¿½å•ï¼Œé¼“åŠ±ç”¨æˆ·å›å¤ã€‚",
            "éœ€è¦ï¼š",
            "1. ç®€çŸ­å›é¡¾ç”¨æˆ·å…³æ³¨ç‚¹æˆ–ç—›ç‚¹ï¼›",
            "2. ç»™å‡ºæ–°çš„ä»·å€¼ç‚¹æˆ–é™æ—¶æƒç›Šæç¤ºï¼›",
            "3. å¼•å¯¼ç”¨æˆ·ç»™å‡ºä¸‹ä¸€æ­¥ï¼ˆä¾‹å¦‚ç¡®è®¤ã€æé—®æˆ–é¢„çº¦æ—¶é—´ï¼‰ã€‚",
        ])

        system_parts = [character_prompt, follow_up_brief]
        if marketing_snippet:
            system_parts.append("ã€çŸ¥è¯†åº“ã€‘\n" + marketing_snippet)
        stage_module = _select_stage_module(route_state_prompt_map, routed_current_state, routed_current_sub_stage)
        if isinstance(stage_module, dict):
            mission = stage_module.get("purpose")
            if mission:
                system_parts.append("ã€é˜¶æ®µç›®æ ‡ã€‘\n" + str(mission))

        system_prompt = "\n\n".join([part for part in system_parts if part])

        user_input_payload = "\n".join([
            "ã€æœ€æ–°ç”¨æˆ·æ¶ˆæ¯ã€‘",
            latest_user_message or "ç”¨æˆ·æœªç•™ä¸‹é¢å¤–ä¿¡æ¯ï¼Œè¯·ä»å†å²ä¸Šä¸‹æ–‡æç‚¼è¦ç‚¹ã€‚",
            "",
            "ã€å›å¤è¦æ±‚ã€‘",
            "- ä»¥å…³æ€€å¼€åœºï¼Œä½“ç°ä½ ä»ç„¶è®°å¾—ç”¨æˆ·çš„è¯‰æ±‚ï¼›",
            "- å¦‚æœé€‚ç”¨ï¼Œå¯æåŠè¥é”€è¯æœ¯è¦ç‚¹ï¼›",
            "- ç»“å°¾æå‡ºå…·ä½“é‚€è¯·æˆ–å¯æ‰§è¡Œçš„ä¸‹ä¸€æ­¥ã€‚",
        ])

        llm_result = llm_generic(
            full_prompt=system_prompt,
            user_input=user_input_payload,
            history_context=history_context,
            session_state=session_state,
            botLLMConfig=bot_llm_config,
            prompt_without_character=system_prompt,
        )

        response_text = ""
        if isinstance(llm_result, str):
            try:
                parsed_result = json.loads(_cleanup_llm_json_str(llm_result))
                if isinstance(parsed_result, dict):
                    response_text = str(parsed_result.get("response") or parsed_result.get("text") or "")
                else:
                    response_text = str(parsed_result)
            except json.JSONDecodeError:
                response_text = llm_result.strip()
        elif isinstance(llm_result, dict):
            response_value = llm_result.get("response") or llm_result.get("text")
            if isinstance(response_value, str):
                response_text = response_value.strip()
            else:
                response_text = str(response_value or "").strip()

        if not response_text:
            response_text = "æƒ³è·Ÿä½ ç¡®è®¤ä¸€ä¸‹ï¼Œä¹‹å‰æåˆ°çš„æœåŠ¡è¿˜æœ‰ä»»ä½•ç–‘é—®æˆ–éœ€è¦å¸®åŠ©çš„åœ°æ–¹å—ï¼Ÿæˆ‘åœ¨è¿™é‡Œç­‰ä½ ï¼Œéšæ—¶å¯ä»¥ç»§ç»­ã€‚"

        info_payload = {"type": "follow_up", "auto": True}
        response_payload = {
            "response": response_text,
            "info": info_payload,
        }

        add_conversation_id_uuid_and_cache(
            response_payload,
            conversation_id=conversation_id,
            session_id=session_id,
            user_id=user_id,
            turn_uuid=turn_uuid,
        )

        substage_col = normalize_substage_name(routed_current_state, routed_current_sub_stage)
        stage_payload = {substage_col: {"info": info_payload, "response": response_text}}
        try:
            db.update_pending_turn_state(
                turn_uuid=turn_uuid,
                routed_current_state=routed_current_state,
                routed_current_sub_stage=routed_current_sub_stage,
                stage_payload_draft=json.dumps(stage_payload, ensure_ascii=False),
            )
            db.update_pending_turn_state(
                turn_uuid=turn_uuid,
                next_stage=routed_current_state,
                next_substage=routed_current_sub_stage or substage_col,
            )
        except Exception as exc:  # noqa: BLE001
            logger.warning("[generate_follow_up_response] æ›´æ–° pending_turn çŠ¶æ€å¤±è´¥: %s", exc)

        return json.dumps({
            "response": response_text,
            "turn_uuid": turn_uuid,
        }, ensure_ascii=False)

    except Exception as e:  # noqa: BLE001
        logger.error("[generate_follow_up_response] æ‰§è¡Œå¤±è´¥: %s", e, exc_info=True)
        return json.dumps({
            "error": str(e),
        }, ensure_ascii=False)


if __name__ == "__main__":
    mcp.run(transport="sse")



